{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6ac7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:29.889657Z",
     "iopub.status.busy": "2023-01-14T19:25:29.889328Z",
     "iopub.status.idle": "2023-01-14T19:25:30.978841Z",
     "shell.execute_reply": "2023-01-14T19:25:30.978297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arma/anaconda3/envs/teachopencadd/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingclfressor\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b2ece9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:30.981700Z",
     "iopub.status.busy": "2023-01-14T19:25:30.981224Z",
     "iopub.status.idle": "2023-01-14T19:25:30.984489Z",
     "shell.execute_reply": "2023-01-14T19:25:30.983975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "levels_up = 3\n",
    "HDAC6= HERE.parents[levels_up-1]/'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3db03b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:30.988399Z",
     "iopub.status.busy": "2023-01-14T19:25:30.987966Z",
     "iopub.status.idle": "2023-01-14T19:25:31.073178Z",
     "shell.execute_reply": "2023-01-14T19:25:31.072678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>fp_MACCS</th>\n",
       "      <th>fp_Morgan3</th>\n",
       "      <th>fp_MorganF</th>\n",
       "      <th>fp_MAP4</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>n_rot</th>\n",
       "      <th>n_heavy</th>\n",
       "      <th>n_hba</th>\n",
       "      <th>n_hbd</th>\n",
       "      <th>logp</th>\n",
       "      <th>num_ar</th>\n",
       "      <th>num_sa</th>\n",
       "      <th>num_alip</th>\n",
       "      <th>pchembl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL3799183</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1488606, 5343410, 8033062, 15183094, 1042149,...</td>\n",
       "      <td>382.072035</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.50360</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL3770936</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5976924, 3913535, 8033062, 2817337, 33707642,...</td>\n",
       "      <td>335.163377</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.79650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL2337862</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[11028593, 3913535, 13317291, 17455853, 103354...</td>\n",
       "      <td>327.115381</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.61819</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL4088663</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5976924, 4714340, 3732398, 4909488, 1081229, ...</td>\n",
       "      <td>307.095691</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.60610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL2336043</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2987766, 7057043, 7998790, 6116087, 3203638, ...</td>\n",
       "      <td>507.273321</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.01780</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  molecule_chembl_id                                           fp_MACCS  \\\n",
       "0      CHEMBL3799183  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      CHEMBL3770936  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      CHEMBL2337862  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      CHEMBL4088663  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      CHEMBL2336043  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          fp_Morgan3  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          fp_MorganF  \\\n",
       "0  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             fp_MAP4  molecular_weight  n_rot  \\\n",
       "0  [1488606, 5343410, 8033062, 15183094, 1042149,...        382.072035    5.0   \n",
       "1  [5976924, 3913535, 8033062, 2817337, 33707642,...        335.163377    3.0   \n",
       "2  [11028593, 3913535, 13317291, 17455853, 103354...        327.115381    4.0   \n",
       "3  [5976924, 4714340, 3732398, 4909488, 1081229, ...        307.095691    3.0   \n",
       "4  [2987766, 7057043, 7998790, 6116087, 3203638, ...        507.273321   14.0   \n",
       "\n",
       "   n_heavy  n_hba  n_hbd     logp  num_ar  num_sa  num_alip  pchembl  \n",
       "0     27.0    4.0    3.0  4.50360     3.0     0.0       0.0     6.82  \n",
       "1     25.0    4.0    2.0  2.79650     3.0     0.0       1.0     7.82  \n",
       "2     23.0    7.0    1.0  2.61819     3.0     0.0       0.0     5.99  \n",
       "3     23.0    4.0    3.0  2.60610     3.0     0.0       0.0     6.58  \n",
       "4     37.0    5.0    4.0  5.01780     3.0     0.0       0.0     6.18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(HDAC6/\"HDAC6_2971compounds_1024B.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3d2d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.075277Z",
     "iopub.status.busy": "2023-01-14T19:25:31.075060Z",
     "iopub.status.idle": "2023-01-14T19:25:31.091315Z",
     "shell.execute_reply": "2023-01-14T19:25:31.090880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pActivity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL4082520</td>\n",
       "      <td>CN1C(=O)C2CN(Cc3c2c2cc(OCc4ccccc4)ccc2n3Cc2ccc...</td>\n",
       "      <td>10.10</td>\n",
       "      <td>Single points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL4098975</td>\n",
       "      <td>O=C(CCCCCCC(=O)Nc1ccc(NCCCn2cc(-c3ncnc4[nH]ccc...</td>\n",
       "      <td>9.85</td>\n",
       "      <td>hDAC6-selective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4100534</td>\n",
       "      <td>COc1ccc2c(c1)c1c(n2Cc2ccc(C(=O)NO)cc2)CN2CC1C(...</td>\n",
       "      <td>9.82</td>\n",
       "      <td>Single points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL4101480</td>\n",
       "      <td>COc1ccc2c(c1)c1c(n2Cc2ccc(C(=O)NO)cc2)CN2CC1C(...</td>\n",
       "      <td>9.80</td>\n",
       "      <td>Single points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL3912061</td>\n",
       "      <td>CS(=O)(=O)NCCc1cn(Cc2ccc(C(=O)NO)cc2)c2ccccc12</td>\n",
       "      <td>9.77</td>\n",
       "      <td>hDAC6-selective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>CHEMBL1798006</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)C1CCNCC1)C(=O)N1Cc2cc(OC...</td>\n",
       "      <td>6.77</td>\n",
       "      <td>Single points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>CHEMBL470843</td>\n",
       "      <td>O=C(/C=C/c1ccc(-c2cc(CN3CCOCC3)on2)cc1)NO</td>\n",
       "      <td>6.76</td>\n",
       "      <td>Semi-selective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>CHEMBL1798004</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@@H]1CCCN1)C(=O)N1Cc2c...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>Single points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>CHEMBL3215861</td>\n",
       "      <td>CCCCc1nc2cc(/C=C/C(=O)NO)ccc2n1CCN(CC)CC</td>\n",
       "      <td>6.61</td>\n",
       "      <td>Dual-binder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>CHEMBL3233708</td>\n",
       "      <td>O=C(/C=C/c1ccc(OC[C@H](Cc2c[nH]c3ccccc23)NCc2c...</td>\n",
       "      <td>6.53</td>\n",
       "      <td>Non-binder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     molecule_chembl_id                                             smiles  \\\n",
       "0         CHEMBL4082520  CN1C(=O)C2CN(Cc3c2c2cc(OCc4ccccc4)ccc2n3Cc2ccc...   \n",
       "1         CHEMBL4098975  O=C(CCCCCCC(=O)Nc1ccc(NCCCn2cc(-c3ncnc4[nH]ccc...   \n",
       "2         CHEMBL4100534  COc1ccc2c(c1)c1c(n2Cc2ccc(C(=O)NO)cc2)CN2CC1C(...   \n",
       "3         CHEMBL4101480  COc1ccc2c(c1)c1c(n2Cc2ccc(C(=O)NO)cc2)CN2CC1C(...   \n",
       "4         CHEMBL3912061     CS(=O)(=O)NCCc1cn(Cc2ccc(C(=O)NO)cc2)c2ccccc12   \n",
       "...                 ...                                                ...   \n",
       "2966      CHEMBL1798006  CC[C@H](C)[C@H](NC(=O)C1CCNCC1)C(=O)N1Cc2cc(OC...   \n",
       "2967       CHEMBL470843          O=C(/C=C/c1ccc(-c2cc(CN3CCOCC3)on2)cc1)NO   \n",
       "2968      CHEMBL1798004  CC[C@H](C)[C@H](NC(=O)[C@@H]1CCCN1)C(=O)N1Cc2c...   \n",
       "2969      CHEMBL3215861           CCCCc1nc2cc(/C=C/C(=O)NO)ccc2n1CCN(CC)CC   \n",
       "2970      CHEMBL3233708  O=C(/C=C/c1ccc(OC[C@H](Cc2c[nH]c3ccccc23)NCc2c...   \n",
       "\n",
       "      pActivity            label  \n",
       "0         10.10    Single points  \n",
       "1          9.85  hDAC6-selective  \n",
       "2          9.82    Single points  \n",
       "3          9.80    Single points  \n",
       "4          9.77  hDAC6-selective  \n",
       "...         ...              ...  \n",
       "2966       6.77    Single points  \n",
       "2967       6.76   Semi-selective  \n",
       "2968       6.72    Single points  \n",
       "2969       6.61      Dual-binder  \n",
       "2970       6.53       Non-binder  \n",
       "\n",
       "[2971 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = pd.read_csv(HDAC6/\"HDAC6_2971compounds_withTypes-Ki_newThreshold.csv\", index_col=0)\n",
    "df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b33ec4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.093429Z",
     "iopub.status.busy": "2023-01-14T19:25:31.093150Z",
     "iopub.status.idle": "2023-01-14T19:25:31.099431Z",
     "shell.execute_reply": "2023-01-14T19:25:31.098996Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_labeled[['molecule_chembl_id',  'label']], on='molecule_chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63178d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.101378Z",
     "iopub.status.busy": "2023-01-14T19:25:31.101144Z",
     "iopub.status.idle": "2023-01-14T19:25:31.135810Z",
     "shell.execute_reply": "2023-01-14T19:25:31.135357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>fp_MACCS</th>\n",
       "      <th>fp_Morgan3</th>\n",
       "      <th>fp_MorganF</th>\n",
       "      <th>fp_MAP4</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>n_rot</th>\n",
       "      <th>n_heavy</th>\n",
       "      <th>n_hba</th>\n",
       "      <th>n_hbd</th>\n",
       "      <th>logp</th>\n",
       "      <th>num_ar</th>\n",
       "      <th>num_sa</th>\n",
       "      <th>num_alip</th>\n",
       "      <th>pchembl</th>\n",
       "      <th>label</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL3799183</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1488606, 5343410, 8033062, 15183094, 1042149,...</td>\n",
       "      <td>382.072035</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.50360</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>Semi-selective</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL3770936</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5976924, 3913535, 8033062, 2817337, 33707642,...</td>\n",
       "      <td>335.163377</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.79650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.82</td>\n",
       "      <td>Single points</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL2337862</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[11028593, 3913535, 13317291, 17455853, 103354...</td>\n",
       "      <td>327.115381</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.61819</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>Single points</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL4088663</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5976924, 4714340, 3732398, 4909488, 1081229, ...</td>\n",
       "      <td>307.095691</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.60610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.58</td>\n",
       "      <td>Single points</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  molecule_chembl_id                                           fp_MACCS  \\\n",
       "0      CHEMBL3799183  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      CHEMBL3770936  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      CHEMBL2337862  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      CHEMBL4088663  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          fp_Morgan3  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          fp_MorganF  \\\n",
       "0  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             fp_MAP4  molecular_weight  n_rot  \\\n",
       "0  [1488606, 5343410, 8033062, 15183094, 1042149,...        382.072035    5.0   \n",
       "1  [5976924, 3913535, 8033062, 2817337, 33707642,...        335.163377    3.0   \n",
       "2  [11028593, 3913535, 13317291, 17455853, 103354...        327.115381    4.0   \n",
       "3  [5976924, 4714340, 3732398, 4909488, 1081229, ...        307.095691    3.0   \n",
       "\n",
       "   n_heavy  n_hba  n_hbd     logp  num_ar  num_sa  num_alip  pchembl  \\\n",
       "0     27.0    4.0    3.0  4.50360     3.0     0.0       0.0     6.82   \n",
       "1     25.0    4.0    2.0  2.79650     3.0     0.0       1.0     7.82   \n",
       "2     23.0    7.0    1.0  2.61819     3.0     0.0       0.0     5.99   \n",
       "3     23.0    4.0    3.0  2.60610     3.0     0.0       0.0     6.58   \n",
       "\n",
       "            label  Class  \n",
       "0  Semi-selective    5.0  \n",
       "1   Single points    0.0  \n",
       "2   Single points    0.0  \n",
       "3   Single points    0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Classes'] = np.where(df['label']== 'hDAC1-selective', 2)\n",
    "df['Class'] = np.zeros(len(df))\n",
    "\n",
    "df.loc[df[df.label == 'hDAC1-selective'].index, \"Class\"] = 1.0\n",
    "df.loc[df[df.label == 'hDAC6-selective'].index, \"Class\"] = 2.0\n",
    "df.loc[df[df.label == 'Dual-binder'].index, \"Class\"] = 3.0\n",
    "df.loc[df[df.label == 'Non-binder'].index, \"Class\"] = 4.0\n",
    "df.loc[df[df.label == 'Semi-selective'].index, \"Class\"] = 5.0\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0957d8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.138056Z",
     "iopub.status.busy": "2023-01-14T19:25:31.137815Z",
     "iopub.status.idle": "2023-01-14T19:25:31.152419Z",
     "shell.execute_reply": "2023-01-14T19:25:31.151876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add column for selectivity\n",
    "df[\"activity\"] = np.zeros(len(df))\n",
    "\n",
    "# Mark every molecule as selective if SelectivityWindow is >=2 or >=-2, 0 otherwise\n",
    "df.loc[df[df.pchembl >= 6.6].index, \"activity\"] = 1.0\n",
    "\n",
    "#By using Morgan fingerprints with radius of 3 and 1024 bits\n",
    "indices =  np.array(df.index)\n",
    "X = np.array(list((df['fp_Morgan3']))).astype(float)\n",
    "#X.shape\n",
    "Y =  df[\"activity\"].values\n",
    "Y_class = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9534e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.154800Z",
     "iopub.status.busy": "2023-01-14T19:25:31.154620Z",
     "iopub.status.idle": "2023-01-14T19:25:31.333170Z",
     "shell.execute_reply": "2023-01-14T19:25:31.332568Z"
    }
   },
   "outputs": [],
   "source": [
    "NUMS = 10\n",
    "random_state= [146736, 1367, 209056, 1847464, 89563, 967034, 3689, 689547, 578929, 7458910]\n",
    "X_tr_all = []\n",
    "Y_tr_all = []\n",
    "X_te_all = []\n",
    "Y_te_all = []\n",
    "Y_tr_class_all = []\n",
    "Y_te_class_all = []\n",
    "index_tr_all= []\n",
    "index_te_all = []\n",
    "\n",
    "for i in range(NUMS):\n",
    "    X_tr, X_te, Y_tr, Y_te, Y_tr_class, Y_te_class, index_tr, index_te = train_test_split(X, Y, Y_class,indices, test_size=0.2, random_state=random_state[i], stratify=Y_class)\n",
    "    X_tr_all.append(X_tr)\n",
    "    Y_tr_all.append(Y_tr)\n",
    "    X_te_all.append(X_te)\n",
    "    Y_te_all.append(Y_te)\n",
    "    Y_tr_class_all.append(Y_tr_class)\n",
    "    Y_te_class_all.append(Y_te_class)\n",
    "    index_tr_all.append(index_tr)\n",
    "    index_te_all.append(index_te)\n",
    "globals_dict = globals()\n",
    "    \n",
    "for i in range(0, len(index_te_all)):\n",
    "    globals_dict[f\"trainSet{i}\"] = df.iloc[index_tr_all[i]]\n",
    "    globals_dict[f\"testSet{i}\"] = df.iloc[index_te_all[i]]\n",
    "    globals_dict[f\"trainindex{i}\"] = df.index[index_tr_all[i]]\n",
    "    globals_dict[f\"testindex{i}\"] = df.index[index_te_all[i]]  \n",
    "    globals_dict[f\"X_trainSet{i}\"] = np.array(list(df.iloc[index_tr_all[i]]['fp_Morgan3'])).astype(float)\n",
    "    globals_dict[f\"Y_trainSet{i}\"] = np.array(list(df.iloc[index_tr_all[i]]['activity'])).astype(float)\n",
    "    \n",
    "    globals_dict[f\"Y_trainSet{i}_class\"] = np.array(list(df.iloc[index_tr_all[i]]['Class'])).astype(float)\n",
    "    globals_dict[f\"X_testSet{i}\"] = np.array(list(df.iloc[index_te_all[i]]['fp_Morgan3'])).astype(float)\n",
    "    globals_dict[f\"Y_testSet{i}\"] = np.array(list(df.iloc[index_te_all[i]]['activity'])).astype(float)\n",
    "    \n",
    "    globals_dict[f\"Y_testSet{i}_class\"] = np.array(list(df.iloc[index_te_all[i]]['Class'])).astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7463b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.336049Z",
     "iopub.status.busy": "2023-01-14T19:25:31.335638Z",
     "iopub.status.idle": "2023-01-14T19:25:31.347195Z",
     "shell.execute_reply": "2023-01-14T19:25:31.346679Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import math\n",
    "\n",
    "def matrix_metrix(real_values,pred_values,beta):\n",
    "\n",
    "    CM = confusion_matrix(real_values,pred_values)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0] \n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    Population = TN+FN+TP+FP\n",
    "    Prevalence = round( (TP+FP) / Population,2)\n",
    "    Accuracy   = round( (TP+TN) / Population,4)\n",
    "    Precision  = round( TP / (TP+FP),4 )\n",
    "    NPV        = round( TN / (TN+FN),4 )\n",
    "    FDR        = round( FP / (TP+FP),4 )\n",
    "    FOR        = round( FN / (TN+FN),4 ) \n",
    "    check_Pos  = Precision + FDR\n",
    "    check_Neg  = NPV + FOR\n",
    "    Recall     = round( TP / (TP+FN),4 )\n",
    "    FPR        = round( FP / (TN+FP),4 )\n",
    "    FNR        = round( FN / (TP+FN),4 )\n",
    "    TNR        = round( TN / (TN+FP),4 ) \n",
    "    check_Pos2 = Recall + FNR\n",
    "    check_Neg2 = FPR + TNR\n",
    "    LRPos      = round( Recall/FPR,4 ) \n",
    "    LRNeg      = round( FNR / TNR ,4 )\n",
    "    DOR        = round( LRPos/LRNeg)\n",
    "    BalancedAccuracy = round( 0.5*(Recall+TNR),4)\n",
    "    F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)   \n",
    "    F1_weighted = round(f1_score(real_values, pred_values, average=\"weighted\"), 4)\n",
    "    F1_micro = round(f1_score(real_values, pred_values, average=\"micro\"), 4)\n",
    "    F1_macro = round(f1_score(real_values, pred_values, average=\"macro\"), 4)\n",
    "    FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
    "    MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
    "    BM         = Recall+TNR-1\n",
    "    MK         = Precision+NPV-1\n",
    "\n",
    "    mat_met = pd.DataFrame({\n",
    "    'Metric':['TP','TN','FP','FN','Prevalence','Accuracy','Precision','NPV','FDR','FOR','check_Pos',\n",
    "              'check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','DOR','BalancedAccuracy',\n",
    "              'F1','F1_weighted','F1_micro', 'F1_macro', 'FBeta','MCC','BM','MK'],     \n",
    "    'Value':[TP,TN,FP,FN,Prevalence,Accuracy,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,BalancedAccuracy,F1,F1_weighted,F1_micro, F1_macro, FBeta,MCC,BM,MK]})  \n",
    "    return (mat_met)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faaebf",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ce7c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:31.349545Z",
     "iopub.status.busy": "2023-01-14T19:25:31.349213Z",
     "iopub.status.idle": "2023-01-14T19:25:54.595122Z",
     "shell.execute_reply": "2023-01-14T19:25:54.594820Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       165.600000     8.579044\n",
      "1                    TN        87.600000     7.290786\n",
      "2                    FP        25.800000     3.457681\n",
      "3                    FN        18.100000     3.348300\n",
      "4              Accuracy         0.852244     0.017931\n",
      "5             Precision         0.865140     0.017447\n",
      "6           Sensitivity         0.901126     0.019911\n",
      "7           Specificity         0.771950     0.031480\n",
      "8              F1 score         0.882670     0.015935\n",
      "9   F1 score (weighted)         0.851104     0.018064\n",
      "10     F1 score (macro)         0.840947     0.018474\n",
      "11    Balanced Accuracy         0.836539     0.018544\n",
      "12                  MCC         0.683562     0.036839\n",
      "13                  NPV         0.829120     0.025985\n",
      "14              ROC_AUC         0.836539     0.018544\n",
      "CPU times: user 2min 32s, sys: 352 ms, total: 2min 33s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1121218)\n",
    "\n",
    "TP =np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "Accuracy = np.empty(10)\n",
    "Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores = np.empty(10)\n",
    "f1_scores_W = np.empty(10)\n",
    "f1_scores_M = np.empty(10)\n",
    "BA_scores = np.empty(10)\n",
    "MCC = np.empty(10)\n",
    "NPV = np.empty(10)\n",
    "ROC_AUC= np.empty(10)\n",
    "\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        x_train, x_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "        rf_clf =  RandomForestClassifier(random_state=1121218, max_features = None, n_jobs=16,oob_score=True,\n",
    "                                           max_samples=0.8, )\n",
    "        rf_clf.fit(x_train, y_train)\n",
    "        y_pred = rf_clf.predict(x_test)  \n",
    "        #calculate the evaluation results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "mat_met_rf = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       }) \n",
    "                    \n",
    "print(mat_met_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b453df70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:54.597133Z",
     "iopub.status.busy": "2023-01-14T19:25:54.596977Z",
     "iopub.status.idle": "2023-01-14T19:25:54.600358Z",
     "shell.execute_reply": "2023-01-14T19:25:54.600072Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna  \n",
    "\n",
    "\n",
    "def objective_rf_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "    #min_samples_split : trial.suggest_int('min_samples_split', 2, 50)\n",
    "    #min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 25)\n",
    "    #max_depth = trial.suggest_int('max_depth', 1, 10000)\n",
    "    #\"max_features\" : trial.suggestegorical(\"max_features\", [None]),\n",
    "    #oob_score = trial.suggestegorical('oob_score', ['True','False']),\n",
    "    #max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 1, 10000)\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    cv_scores = np.empty(10)\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        x_train, x_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        rf = RandomForestClassifier(**param_grid, n_jobs=16, random_state=1121218, max_features = None, \n",
    "                                   oob_score=True,\n",
    "                                   max_samples=0.8,) \n",
    "        \n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        cv_scores[idx] = f1_score(y_test, y_pred,  average=\"macro\")\n",
    "      \n",
    "    \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab658a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:54.602041Z",
     "iopub.status.busy": "2023-01-14T19:25:54.601916Z",
     "iopub.status.idle": "2023-01-14T19:25:54.609322Z",
     "shell.execute_reply": "2023-01-14T19:25:54.609049Z"
    }
   },
   "outputs": [],
   "source": [
    "def detailed_objective_rf_CV(trial,X, Y, Y_class):\n",
    "    param_grid = {\n",
    "    #min_samples_split : trial.suggest_int('min_samples_split', 2, 50)\n",
    "    #min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 25)\n",
    "    #max_depth = trial.suggest_int('max_depth', 1, 10000)\n",
    "    #\"max_features\" : trial.suggestegorical(\"max_features\", [None]),\n",
    "    #oob_score = trial.suggestegorical('oob_score', ['True','False']),\n",
    "    #max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 1, 10000)\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    TP=np.empty(10)\n",
    "    TN = np.empty(10)\n",
    "    FP= np.empty(10)\n",
    "    FN= np.empty(10)\n",
    "    Accuracy = np.empty(10)\n",
    "    Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "    Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "    Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "    f1_scores = np.empty(10)\n",
    "    f1_scores_W=np.empty(10)\n",
    "    f1_scores_M=np.empty(10)\n",
    "    BA_scores = np.empty(10)\n",
    "    MCC = np.empty(10)\n",
    "    NPV = np.empty(10)\n",
    "    ROC_AUC= np.empty(10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        rf = RandomForestClassifier(**param_grid, n_jobs=16, random_state=1121218, max_features = None, oob_score=True,\n",
    "                                           max_samples=0.8,)\n",
    "   \n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "       \n",
    "           \n",
    "        #calculate parameters\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)      \n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })   \n",
    "    \n",
    "    return (mat_met)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f39a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T19:25:54.611078Z",
     "iopub.status.busy": "2023-01-14T19:25:54.610954Z",
     "iopub.status.idle": "2023-01-14T21:14:03.359827Z",
     "shell.execute_reply": "2023-01-14T21:14:03.359270Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 10:14:50,873]\u001b[0m A new study created in memory with name: RFclassifier\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:15:27,400]\u001b[0m Trial 0 finished with value: 0.8283868292299704 and parameters: {'n_estimators': 447}. Best is trial 0 with value: 0.8283868292299704.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:16:11,518]\u001b[0m Trial 1 finished with value: 0.8265620151351859 and parameters: {'n_estimators': 538}. Best is trial 0 with value: 0.8283868292299704.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:17:05,476]\u001b[0m Trial 2 finished with value: 0.8284705675051219 and parameters: {'n_estimators': 666}. Best is trial 2 with value: 0.8284705675051219.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:17:51,251]\u001b[0m Trial 3 finished with value: 0.8274969782228313 and parameters: {'n_estimators': 574}. Best is trial 2 with value: 0.8284705675051219.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:18:10,279]\u001b[0m Trial 4 finished with value: 0.8298327570672244 and parameters: {'n_estimators': 228}. Best is trial 4 with value: 0.8298327570672244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:19:29,391]\u001b[0m Trial 5 finished with value: 0.8288241082481702 and parameters: {'n_estimators': 993}. Best is trial 4 with value: 0.8298327570672244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:19:54,655]\u001b[0m Trial 6 finished with value: 0.8297356881780299 and parameters: {'n_estimators': 302}. Best is trial 4 with value: 0.8298327570672244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:20:56,844]\u001b[0m Trial 7 finished with value: 0.8281699182621811 and parameters: {'n_estimators': 779}. Best is trial 4 with value: 0.8298327570672244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:21:56,998]\u001b[0m Trial 8 finished with value: 0.8282956285190155 and parameters: {'n_estimators': 739}. Best is trial 4 with value: 0.8298327570672244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:22:18,763]\u001b[0m Trial 9 finished with value: 0.8305128963175916 and parameters: {'n_estimators': 264}. Best is trial 9 with value: 0.8305128963175916.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:22:28,063]\u001b[0m Trial 10 finished with value: 0.8292621346213235 and parameters: {'n_estimators': 102}. Best is trial 9 with value: 0.8305128963175916.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:22:43,561]\u001b[0m Trial 11 finished with value: 0.8312180775575998 and parameters: {'n_estimators': 184}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:23:10,498]\u001b[0m Trial 12 finished with value: 0.8294361793784791 and parameters: {'n_estimators': 326}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:23:19,910]\u001b[0m Trial 13 finished with value: 0.8291137645083271 and parameters: {'n_estimators': 105}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:23:39,757]\u001b[0m Trial 14 finished with value: 0.830300819644559 and parameters: {'n_estimators': 232}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:24:10,049]\u001b[0m Trial 15 finished with value: 0.8283300971475487 and parameters: {'n_estimators': 374}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:24:27,099]\u001b[0m Trial 16 finished with value: 0.8296947325355355 and parameters: {'n_estimators': 202}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:25:03,318]\u001b[0m Trial 17 finished with value: 0.827973745961066 and parameters: {'n_estimators': 441}. Best is trial 11 with value: 0.8312180775575998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:25:18,576]\u001b[0m Trial 18 finished with value: 0.832646195556294 and parameters: {'n_estimators': 178}. Best is trial 18 with value: 0.832646195556294.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:25:33,917]\u001b[0m Trial 19 finished with value: 0.8323351388521338 and parameters: {'n_estimators': 179}. Best is trial 18 with value: 0.832646195556294.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:26:07,852]\u001b[0m Trial 20 finished with value: 0.8274547304727221 and parameters: {'n_estimators': 412}. Best is trial 18 with value: 0.832646195556294.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:26:21,939]\u001b[0m Trial 21 finished with value: 0.83306563990519 and parameters: {'n_estimators': 162}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:26:34,664]\u001b[0m Trial 22 finished with value: 0.8317498081597027 and parameters: {'n_estimators': 144}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:27:01,510]\u001b[0m Trial 23 finished with value: 0.8300086402349018 and parameters: {'n_estimators': 323}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:27:15,720]\u001b[0m Trial 24 finished with value: 0.8300281817877307 and parameters: {'n_estimators': 166}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:27:56,734]\u001b[0m Trial 25 finished with value: 0.8278779127198017 and parameters: {'n_estimators': 512}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:28:21,671]\u001b[0m Trial 26 finished with value: 0.8297371261341141 and parameters: {'n_estimators': 298}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:29:35,416]\u001b[0m Trial 27 finished with value: 0.8301576123945843 and parameters: {'n_estimators': 925}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:30:06,134]\u001b[0m Trial 28 finished with value: 0.8283300971475487 and parameters: {'n_estimators': 374}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:30:19,319]\u001b[0m Trial 29 finished with value: 0.8320438206139693 and parameters: {'n_estimators': 155}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:30:38,688]\u001b[0m Trial 30 finished with value: 0.8302360937665174 and parameters: {'n_estimators': 231}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:30:52,109]\u001b[0m Trial 31 finished with value: 0.8322485525366525 and parameters: {'n_estimators': 156}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:31:01,211]\u001b[0m Trial 32 finished with value: 0.8291635046390222 and parameters: {'n_estimators': 100}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:31:22,768]\u001b[0m Trial 33 finished with value: 0.8292122513988645 and parameters: {'n_estimators': 259}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:32:02,028]\u001b[0m Trial 34 finished with value: 0.8282755083211957 and parameters: {'n_estimators': 494}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:32:51,197]\u001b[0m Trial 35 finished with value: 0.8271171728038157 and parameters: {'n_estimators': 615}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:33:06,021]\u001b[0m Trial 36 finished with value: 0.832646195556294 and parameters: {'n_estimators': 178}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:33:36,651]\u001b[0m Trial 37 finished with value: 0.82914265196469 and parameters: {'n_estimators': 365}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:33:53,355]\u001b[0m Trial 38 finished with value: 0.8300979928848431 and parameters: {'n_estimators': 201}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:34:17,269]\u001b[0m Trial 39 finished with value: 0.8279195690861567 and parameters: {'n_estimators': 282}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:34:37,839]\u001b[0m Trial 40 finished with value: 0.829614739724606 and parameters: {'n_estimators': 251}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:34:50,345]\u001b[0m Trial 41 finished with value: 0.8307409501790328 and parameters: {'n_estimators': 141}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:35:06,749]\u001b[0m Trial 42 finished with value: 0.8297933475271602 and parameters: {'n_estimators': 196}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:35:18,903]\u001b[0m Trial 43 finished with value: 0.830450441666688 and parameters: {'n_estimators': 140}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:35:36,239]\u001b[0m Trial 44 finished with value: 0.8295809253495585 and parameters: {'n_estimators': 210}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:36:35,278]\u001b[0m Trial 45 finished with value: 0.8278844953582002 and parameters: {'n_estimators': 743}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 10:36:49,750]\u001b[0m Trial 46 finished with value: 0.8305066781519935 and parameters: {'n_estimators': 170}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:37:16,883]\u001b[0m Trial 47 finished with value: 0.8285447033827724 and parameters: {'n_estimators': 334}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:37:28,098]\u001b[0m Trial 48 finished with value: 0.829372291759317 and parameters: {'n_estimators': 129}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:38:34,996]\u001b[0m Trial 49 finished with value: 0.8296306215096283 and parameters: {'n_estimators': 839}. Best is trial 21 with value: 0.83306563990519.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 50.0\n",
      "\tBest value (f1_score): 0.8331\n",
      "\tBest params:\n",
      "\t\tn_estimators: 162\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "study_rf = optuna.create_study(direction='maximize', study_name=\"RFclassifier\")\n",
    "func_rf_0 = lambda trial: objective_rf_CV(trial, X_trainSet0, Y_trainSet0, Y_trainSet0_class)\n",
    "study_rf.optimize(func_rf_0, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a10ec04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T21:14:03.362029Z",
     "iopub.status.busy": "2023-01-14T21:14:03.361837Z",
     "iopub.status.idle": "2023-01-14T21:14:20.818831Z",
     "shell.execute_reply": "2023-01-14T21:14:20.818294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0\n",
      "0                    TP  336.000000\n",
      "1                    TN  176.000000\n",
      "2                    FP   48.000000\n",
      "3                    FN   35.000000\n",
      "4              Accuracy    0.860504\n",
      "5             Precision    0.875000\n",
      "6           Sensitivity    0.905660\n",
      "7           Specificity    0.785700\n",
      "8              F1 score    0.890066\n",
      "9   F1 score (weighted)    0.859621\n",
      "10     F1 score (macro)    0.849631\n",
      "11    Balanced Accuracy    0.845687\n",
      "12                  MCC    0.700193\n",
      "13                  NPV    0.834100\n",
      "14              ROC_AUC    0.845687\n"
     ]
    }
   ],
   "source": [
    "optimized_rf_0 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    " \n",
    "data_testing = pd.DataFrame()    \n",
    "    \n",
    "optimized_rf_0.fit(X_trainSet0, Y_trainSet0,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_0 = optimized_rf_0.predict(X_testSet0)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet0, y_pred_rf_0)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet0, y_pred_rf_0)\n",
    "Precision = precision_score(Y_testSet0, y_pred_rf_0)\n",
    "Sensitivity = recall_score(Y_testSet0, y_pred_rf_0)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet0, y_pred_rf_0)      \n",
    "f1_scores_W = f1_score(Y_testSet0, y_pred_rf_0, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet0, y_pred_rf_0, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet0, y_pred_rf_0)\n",
    "MCC = matthews_corrcoef(Y_testSet0, y_pred_rf_0)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet0, y_pred_rf_0)\n",
    "data_testing['y_test_idx0'] = testindex0\n",
    "data_testing['y_test_Set0'] = Y_testSet0\n",
    "data_testing['y_pred_Set0'] = y_pred_rf_0\n",
    "\n",
    "\n",
    "mat_met_rf_test = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Set0':[np.mean(TP), np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                           np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "    \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116b62f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T21:14:20.821303Z",
     "iopub.status.busy": "2023-01-14T21:14:20.820849Z",
     "iopub.status.idle": "2023-01-14T23:21:01.975109Z",
     "shell.execute_reply": "2023-01-14T23:21:01.974548Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 10:38:59,346]\u001b[0m Trial 50 finished with value: 0.837469330173817 and parameters: {'n_estimators': 278}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:39:19,533]\u001b[0m Trial 51 finished with value: 0.8346875991610766 and parameters: {'n_estimators': 249}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:39:41,424]\u001b[0m Trial 52 finished with value: 0.8361728054004803 and parameters: {'n_estimators': 267}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:40:04,163]\u001b[0m Trial 53 finished with value: 0.8370014546948223 and parameters: {'n_estimators': 282}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:40:27,413]\u001b[0m Trial 54 finished with value: 0.8370014546948223 and parameters: {'n_estimators': 281}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:40:50,417]\u001b[0m Trial 55 finished with value: 0.836096498938168 and parameters: {'n_estimators': 290}. Best is trial 50 with value: 0.837469330173817.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:41:24,675]\u001b[0m Trial 56 finished with value: 0.8392805321721173 and parameters: {'n_estimators': 424}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:41:57,367]\u001b[0m Trial 57 finished with value: 0.838848826338428 and parameters: {'n_estimators': 412}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:42:34,111]\u001b[0m Trial 58 finished with value: 0.8383007581303176 and parameters: {'n_estimators': 467}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:43:08,626]\u001b[0m Trial 59 finished with value: 0.8392675686227988 and parameters: {'n_estimators': 432}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:43:45,430]\u001b[0m Trial 60 finished with value: 0.8387299163900381 and parameters: {'n_estimators': 460}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:44:22,328]\u001b[0m Trial 61 finished with value: 0.8383007581303176 and parameters: {'n_estimators': 467}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:44:58,884]\u001b[0m Trial 62 finished with value: 0.8383187364846721 and parameters: {'n_estimators': 461}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:45:33,850]\u001b[0m Trial 63 finished with value: 0.8383011619477367 and parameters: {'n_estimators': 437}. Best is trial 56 with value: 0.8392805321721173.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:46:17,756]\u001b[0m Trial 64 finished with value: 0.839459751609877 and parameters: {'n_estimators': 556}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:47:01,944]\u001b[0m Trial 65 finished with value: 0.839459751609877 and parameters: {'n_estimators': 557}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:47:45,861]\u001b[0m Trial 66 finished with value: 0.8389736097418176 and parameters: {'n_estimators': 554}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:48:34,722]\u001b[0m Trial 67 finished with value: 0.8394540485551986 and parameters: {'n_estimators': 616}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:49:22,557]\u001b[0m Trial 68 finished with value: 0.8394451628739465 and parameters: {'n_estimators': 600}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:50:10,219]\u001b[0m Trial 69 finished with value: 0.8394451628739465 and parameters: {'n_estimators': 597}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:50:59,740]\u001b[0m Trial 70 finished with value: 0.8389581598729772 and parameters: {'n_estimators': 611}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:51:44,523]\u001b[0m Trial 71 finished with value: 0.839049420109767 and parameters: {'n_estimators': 564}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:52:38,722]\u001b[0m Trial 72 finished with value: 0.8381456277590449 and parameters: {'n_estimators': 680}. Best is trial 64 with value: 0.839459751609877.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:53:26,090]\u001b[0m Trial 73 finished with value: 0.8399745746737729 and parameters: {'n_estimators': 592}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:54:13,597]\u001b[0m Trial 74 finished with value: 0.8399650580614997 and parameters: {'n_estimators': 606}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:55:01,188]\u001b[0m Trial 75 finished with value: 0.8394469836402212 and parameters: {'n_estimators': 603}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:55:47,844]\u001b[0m Trial 76 finished with value: 0.839963237295225 and parameters: {'n_estimators': 594}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:56:41,124]\u001b[0m Trial 77 finished with value: 0.8385485100845276 and parameters: {'n_estimators': 671}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:57:32,185]\u001b[0m Trial 78 finished with value: 0.8389582591958227 and parameters: {'n_estimators': 641}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:58:13,036]\u001b[0m Trial 79 finished with value: 0.8399521339158202 and parameters: {'n_estimators': 514}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:58:53,645]\u001b[0m Trial 80 finished with value: 0.8399477659429344 and parameters: {'n_estimators': 512}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 10:59:35,701]\u001b[0m Trial 81 finished with value: 0.8375824386056007 and parameters: {'n_estimators': 526}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:00:26,137]\u001b[0m Trial 82 finished with value: 0.838617223699021 and parameters: {'n_estimators': 644}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:01:21,363]\u001b[0m Trial 83 finished with value: 0.8386154893295682 and parameters: {'n_estimators': 700}. Best is trial 73 with value: 0.8399745746737729.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:02:01,080]\u001b[0m Trial 84 finished with value: 0.8403776609702405 and parameters: {'n_estimators': 498}. Best is trial 84 with value: 0.8403776609702405.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:02:41,031]\u001b[0m Trial 85 finished with value: 0.8404574124458761 and parameters: {'n_estimators': 500}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:03:21,527]\u001b[0m Trial 86 finished with value: 0.8399521339158202 and parameters: {'n_estimators': 506}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:04:02,352]\u001b[0m Trial 87 finished with value: 0.8399477659429344 and parameters: {'n_estimators': 512}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:04:41,691]\u001b[0m Trial 88 finished with value: 0.8403282893759567 and parameters: {'n_estimators': 495}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:05:20,671]\u001b[0m Trial 89 finished with value: 0.839306619785938 and parameters: {'n_estimators': 491}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:06:02,667]\u001b[0m Trial 90 finished with value: 0.8375524445336111 and parameters: {'n_estimators': 530}. Best is trial 85 with value: 0.8404574124458761.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:06:42,178]\u001b[0m Trial 91 finished with value: 0.8412273172483207 and parameters: {'n_estimators': 494}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:07:21,380]\u001b[0m Trial 92 finished with value: 0.8399677605660514 and parameters: {'n_estimators': 499}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:08:07,437]\u001b[0m Trial 93 finished with value: 0.839459751609877 and parameters: {'n_estimators': 574}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:08:46,212]\u001b[0m Trial 94 finished with value: 0.8412273172483207 and parameters: {'n_estimators': 492}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:09:17,693]\u001b[0m Trial 95 finished with value: 0.8404447445553686 and parameters: {'n_estimators': 394}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:09:49,853]\u001b[0m Trial 96 finished with value: 0.8388754190052936 and parameters: {'n_estimators': 409}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 11:10:28,513]\u001b[0m Trial 97 finished with value: 0.8388354245814492 and parameters: {'n_estimators': 484}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:10:58,362]\u001b[0m Trial 98 finished with value: 0.8400032434902662 and parameters: {'n_estimators': 380}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:11:29,715]\u001b[0m Trial 99 finished with value: 0.8404951739690617 and parameters: {'n_estimators': 388}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 100.0\n",
      "\tBest value (f1_score): 0.8412\n",
      "\tBest params:\n",
      "\t\tn_estimators: 494\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_1 = lambda trial: objective_rf_CV(trial, X_trainSet1, Y_trainSet1, Y_trainSet1_class)\n",
    "study_rf.optimize(func_rf_1, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048b4ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T23:21:01.976840Z",
     "iopub.status.busy": "2023-01-14T23:21:01.976670Z",
     "iopub.status.idle": "2023-01-14T23:21:21.191802Z",
     "shell.execute_reply": "2023-01-14T23:21:21.191202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1\n",
      "0                    TP  336.000000  336.000000\n",
      "1                    TN  176.000000  170.000000\n",
      "2                    FP   48.000000   64.000000\n",
      "3                    FN   35.000000   25.000000\n",
      "4              Accuracy    0.860504    0.850420\n",
      "5             Precision    0.875000    0.840000\n",
      "6           Sensitivity    0.905660    0.930748\n",
      "7           Specificity    0.785700    0.726500\n",
      "8              F1 score    0.890066    0.883049\n",
      "9   F1 score (weighted)    0.859621    0.847454\n",
      "10     F1 score (macro)    0.849631    0.837795\n",
      "11    Balanced Accuracy    0.845687    0.828622\n",
      "12                  MCC    0.700193    0.683976\n",
      "13                  NPV    0.834100    0.871800\n",
      "14              ROC_AUC    0.845687    0.828622\n"
     ]
    }
   ],
   "source": [
    "optimized_rf_1 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_1.fit(X_trainSet1, Y_trainSet1,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_1 = optimized_rf_1.predict(X_testSet1)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet1, y_pred_rf_1)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet1, y_pred_rf_1)\n",
    "Precision = precision_score(Y_testSet1, y_pred_rf_1)\n",
    "Sensitivity = recall_score(Y_testSet1, y_pred_rf_1)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet1, y_pred_rf_1)      \n",
    "f1_scores_W = f1_score(Y_testSet1, y_pred_rf_1, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet1, y_pred_rf_1, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet1, y_pred_rf_1)\n",
    "MCC = matthews_corrcoef(Y_testSet1, y_pred_rf_1)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet1, y_pred_rf_1)\n",
    "data_testing['y_test_idx1'] = testindex1\n",
    "data_testing['y_test_Set1'] = Y_testSet1\n",
    "data_testing['y_pred_Set1'] = y_pred_rf_1\n",
    "\n",
    "\n",
    "set1 = pd.DataFrame({ 'Set1':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_rf_test['Set1'] =set1\n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fb31da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T23:21:21.194018Z",
     "iopub.status.busy": "2023-01-14T23:21:21.193836Z",
     "iopub.status.idle": "2023-01-15T01:39:10.562907Z",
     "shell.execute_reply": "2023-01-15T01:39:10.562395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 11:12:05,758]\u001b[0m Trial 100 finished with value: 0.838975555421128 and parameters: {'n_estimators': 380}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:12:34,697]\u001b[0m Trial 101 finished with value: 0.8399717142096682 and parameters: {'n_estimators': 349}. Best is trial 91 with value: 0.8412273172483207.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:13:03,843]\u001b[0m Trial 102 finished with value: 0.8412392582039265 and parameters: {'n_estimators': 334}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:13:33,327]\u001b[0m Trial 103 finished with value: 0.8398710908882325 and parameters: {'n_estimators': 350}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:14:07,342]\u001b[0m Trial 104 finished with value: 0.8392755182564707 and parameters: {'n_estimators': 396}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:14:34,425]\u001b[0m Trial 105 finished with value: 0.8374074170323234 and parameters: {'n_estimators': 322}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:15:03,825]\u001b[0m Trial 106 finished with value: 0.8394602292990205 and parameters: {'n_estimators': 351}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:15:29,653]\u001b[0m Trial 107 finished with value: 0.838884777974657 and parameters: {'n_estimators': 307}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:16:03,946]\u001b[0m Trial 108 finished with value: 0.8392755182564707 and parameters: {'n_estimators': 398}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:16:41,702]\u001b[0m Trial 109 finished with value: 0.8398105219776063 and parameters: {'n_estimators': 453}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:17:21,843]\u001b[0m Trial 110 finished with value: 0.8399716306088789 and parameters: {'n_estimators': 479}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:17:52,036]\u001b[0m Trial 111 finished with value: 0.83984249618248 and parameters: {'n_estimators': 360}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:18:32,336]\u001b[0m Trial 112 finished with value: 0.8395502728545108 and parameters: {'n_estimators': 483}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:19:09,374]\u001b[0m Trial 113 finished with value: 0.8398060431935693 and parameters: {'n_estimators': 444}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:19:54,669]\u001b[0m Trial 114 finished with value: 0.8412265477442957 and parameters: {'n_estimators': 538}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:20:27,052]\u001b[0m Trial 115 finished with value: 0.838975555421128 and parameters: {'n_estimators': 380}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:21:11,047]\u001b[0m Trial 116 finished with value: 0.8394320487345114 and parameters: {'n_estimators': 534}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:21:39,204]\u001b[0m Trial 117 finished with value: 0.8397746946829219 and parameters: {'n_estimators': 333}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:22:23,629]\u001b[0m Trial 118 finished with value: 0.8410450662252009 and parameters: {'n_estimators': 542}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:23:08,820]\u001b[0m Trial 119 finished with value: 0.8412265477442957 and parameters: {'n_estimators': 538}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:23:54,115]\u001b[0m Trial 120 finished with value: 0.8400667451724063 and parameters: {'n_estimators': 550}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:24:42,350]\u001b[0m Trial 121 finished with value: 0.8384396430796667 and parameters: {'n_estimators': 575}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:25:26,060]\u001b[0m Trial 122 finished with value: 0.8399343133956017 and parameters: {'n_estimators': 536}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:26:10,921]\u001b[0m Trial 123 finished with value: 0.8410450662252009 and parameters: {'n_estimators': 542}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:26:59,373]\u001b[0m Trial 124 finished with value: 0.8388578357212738 and parameters: {'n_estimators': 577}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:27:44,556]\u001b[0m Trial 125 finished with value: 0.8409938301356359 and parameters: {'n_estimators': 545}. Best is trial 102 with value: 0.8412392582039265.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:28:30,050]\u001b[0m Trial 126 finished with value: 0.8415370510020432 and parameters: {'n_estimators': 543}. Best is trial 126 with value: 0.8415370510020432.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:29:13,170]\u001b[0m Trial 127 finished with value: 0.8417734967484478 and parameters: {'n_estimators': 518}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:30:05,513]\u001b[0m Trial 128 finished with value: 0.8403777379091532 and parameters: {'n_estimators': 636}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:30:50,572]\u001b[0m Trial 129 finished with value: 0.8409938301356359 and parameters: {'n_estimators': 545}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:31:34,462]\u001b[0m Trial 130 finished with value: 0.8402589540089618 and parameters: {'n_estimators': 537}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:32:17,665]\u001b[0m Trial 131 finished with value: 0.8413706709399411 and parameters: {'n_estimators': 525}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:33:02,230]\u001b[0m Trial 132 finished with value: 0.8409938301356359 and parameters: {'n_estimators': 545}. Best is trial 127 with value: 0.8417734967484478.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:33:45,477]\u001b[0m Trial 133 finished with value: 0.8418004607398986 and parameters: {'n_estimators': 520}. Best is trial 133 with value: 0.8418004607398986.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:34:28,816]\u001b[0m Trial 134 finished with value: 0.8413706709399411 and parameters: {'n_estimators': 525}. Best is trial 133 with value: 0.8418004607398986.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:35:12,026]\u001b[0m Trial 135 finished with value: 0.841782666583698 and parameters: {'n_estimators': 522}. Best is trial 133 with value: 0.8418004607398986.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:35:54,519]\u001b[0m Trial 136 finished with value: 0.8422962856480689 and parameters: {'n_estimators': 519}. Best is trial 136 with value: 0.8422962856480689.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:36:41,121]\u001b[0m Trial 137 finished with value: 0.8383505684614304 and parameters: {'n_estimators': 568}. Best is trial 136 with value: 0.8422962856480689.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:37:23,597]\u001b[0m Trial 138 finished with value: 0.8426167587438685 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:38:06,288]\u001b[0m Trial 139 finished with value: 0.8422962856480689 and parameters: {'n_estimators': 519}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:38:44,767]\u001b[0m Trial 140 finished with value: 0.8398327080168093 and parameters: {'n_estimators': 471}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:39:32,315]\u001b[0m Trial 141 finished with value: 0.8398023691295723 and parameters: {'n_estimators': 585}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:40:15,411]\u001b[0m Trial 142 finished with value: 0.8409632865983718 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:40:58,746]\u001b[0m Trial 143 finished with value: 0.8409632865983718 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:41:41,082]\u001b[0m Trial 144 finished with value: 0.8399697183279937 and parameters: {'n_estimators': 511}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:42:24,701]\u001b[0m Trial 145 finished with value: 0.841782666583698 and parameters: {'n_estimators': 522}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 11:43:11,476]\u001b[0m Trial 146 finished with value: 0.8383505684614304 and parameters: {'n_estimators': 564}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:43:54,649]\u001b[0m Trial 147 finished with value: 0.8422962856480689 and parameters: {'n_estimators': 519}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:44:37,637]\u001b[0m Trial 148 finished with value: 0.8409020723573486 and parameters: {'n_estimators': 517}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:45:16,210]\u001b[0m Trial 149 finished with value: 0.8402489706980321 and parameters: {'n_estimators': 463}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 150.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_2 = lambda trial: objective_rf_CV(trial, X_trainSet2, Y_trainSet2, Y_trainSet2_class)\n",
    "study_rf.optimize(func_rf_2, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74530207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T01:39:10.564851Z",
     "iopub.status.busy": "2023-01-15T01:39:10.564556Z",
     "iopub.status.idle": "2023-01-15T01:39:29.834790Z",
     "shell.execute_reply": "2023-01-15T01:39:29.834236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2\n",
      "0                    TP  336.000000  336.000000  327.000000\n",
      "1                    TN  176.000000  170.000000  166.000000\n",
      "2                    FP   48.000000   64.000000   58.000000\n",
      "3                    FN   35.000000   25.000000   44.000000\n",
      "4              Accuracy    0.860504    0.850420    0.828571\n",
      "5             Precision    0.875000    0.840000    0.849351\n",
      "6           Sensitivity    0.905660    0.930748    0.881402\n",
      "7           Specificity    0.785700    0.726500    0.741100\n",
      "8              F1 score    0.890066    0.883049    0.865079\n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394\n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028\n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237\n",
      "12                  MCC    0.700193    0.683976    0.631090\n",
      "13                  NPV    0.834100    0.871800    0.790500\n",
      "14              ROC_AUC    0.845687    0.828622    0.811237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimized_rf_2 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_2.fit(X_trainSet2, Y_trainSet2,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_2 = optimized_rf_2.predict(X_testSet2)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet2, y_pred_rf_2)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet2, y_pred_rf_2)\n",
    "Precision = precision_score(Y_testSet2, y_pred_rf_2)\n",
    "Sensitivity = recall_score(Y_testSet2, y_pred_rf_2)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet2, y_pred_rf_2)      \n",
    "f1_scores_W = f1_score(Y_testSet2, y_pred_rf_2, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet2, y_pred_rf_2, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet2, y_pred_rf_2)\n",
    "MCC = matthews_corrcoef(Y_testSet2, y_pred_rf_2)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet2, y_pred_rf_2)\n",
    "data_testing['y_test_idx2'] = testindex2\n",
    "data_testing['y_test_Set2'] = Y_testSet2\n",
    "data_testing['y_pred_Set2'] = y_pred_rf_2\n",
    "\n",
    "set2 = pd.DataFrame({'Set2':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_rf_test['Set2'] =set2\n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b2d0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T01:39:29.837196Z",
     "iopub.status.busy": "2023-01-15T01:39:29.836906Z",
     "iopub.status.idle": "2023-01-15T03:57:14.335253Z",
     "shell.execute_reply": "2023-01-15T03:57:14.334611Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 11:45:59,790]\u001b[0m Trial 150 finished with value: 0.8288910167211127 and parameters: {'n_estimators': 481}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:46:40,753]\u001b[0m Trial 151 finished with value: 0.831124535060687 and parameters: {'n_estimators': 501}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:47:23,273]\u001b[0m Trial 152 finished with value: 0.8315276453965404 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:48:09,508]\u001b[0m Trial 153 finished with value: 0.8292869676760523 and parameters: {'n_estimators': 562}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:48:48,644]\u001b[0m Trial 154 finished with value: 0.8284706170308478 and parameters: {'n_estimators': 484}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:49:25,643]\u001b[0m Trial 155 finished with value: 0.8294671179451534 and parameters: {'n_estimators': 449}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:50:06,285]\u001b[0m Trial 156 finished with value: 0.831118133166879 and parameters: {'n_estimators': 505}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:50:48,720]\u001b[0m Trial 157 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:51:23,373]\u001b[0m Trial 158 finished with value: 0.829871847252393 and parameters: {'n_estimators': 426}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:52:07,700]\u001b[0m Trial 159 finished with value: 0.8293614152932923 and parameters: {'n_estimators': 556}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:52:55,021]\u001b[0m Trial 160 finished with value: 0.8286780401334815 and parameters: {'n_estimators': 586}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:53:38,098]\u001b[0m Trial 161 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 531}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:54:18,254]\u001b[0m Trial 162 finished with value: 0.8307083489377949 and parameters: {'n_estimators': 499}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:55:02,529]\u001b[0m Trial 163 finished with value: 0.8287565532359163 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:56:18,544]\u001b[0m Trial 164 finished with value: 0.8317449673986964 and parameters: {'n_estimators': 961}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:57:00,120]\u001b[0m Trial 165 finished with value: 0.8311209884963631 and parameters: {'n_estimators': 516}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:57:38,887]\u001b[0m Trial 166 finished with value: 0.8289076838872402 and parameters: {'n_estimators': 479}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:58:22,637]\u001b[0m Trial 167 finished with value: 0.8310045730184831 and parameters: {'n_estimators': 538}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:59:08,160]\u001b[0m Trial 168 finished with value: 0.829288792888992 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 11:59:48,460]\u001b[0m Trial 169 finished with value: 0.8307083489377949 and parameters: {'n_estimators': 499}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:00:56,460]\u001b[0m Trial 170 finished with value: 0.830738410775117 and parameters: {'n_estimators': 831}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:01:39,324]\u001b[0m Trial 171 finished with value: 0.8301149863879486 and parameters: {'n_estimators': 540}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:02:22,985]\u001b[0m Trial 172 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:03:07,342]\u001b[0m Trial 173 finished with value: 0.8292359474762729 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:03:55,288]\u001b[0m Trial 174 finished with value: 0.8287548429588556 and parameters: {'n_estimators': 580}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:04:36,498]\u001b[0m Trial 175 finished with value: 0.8311209884963631 and parameters: {'n_estimators': 513}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:05:16,826]\u001b[0m Trial 176 finished with value: 0.8298866265153269 and parameters: {'n_estimators': 488}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:05:54,854]\u001b[0m Trial 177 finished with value: 0.8293958797998547 and parameters: {'n_estimators': 471}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:06:40,188]\u001b[0m Trial 178 finished with value: 0.8295779096090893 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:07:22,933]\u001b[0m Trial 179 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 526}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:08:13,666]\u001b[0m Trial 180 finished with value: 0.8296157913982283 and parameters: {'n_estimators': 615}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:08:57,412]\u001b[0m Trial 181 finished with value: 0.8285863252182505 and parameters: {'n_estimators': 541}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:09:42,791]\u001b[0m Trial 182 finished with value: 0.8287548429588556 and parameters: {'n_estimators': 559}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:10:24,894]\u001b[0m Trial 183 finished with value: 0.830708699620387 and parameters: {'n_estimators': 509}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:11:11,368]\u001b[0m Trial 184 finished with value: 0.829575659634938 and parameters: {'n_estimators': 571}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:11:55,451]\u001b[0m Trial 185 finished with value: 0.8310045730184831 and parameters: {'n_estimators': 537}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:12:35,916]\u001b[0m Trial 186 finished with value: 0.830298915391303 and parameters: {'n_estimators': 494}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:13:18,235]\u001b[0m Trial 187 finished with value: 0.8306349319172833 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:13:56,592]\u001b[0m Trial 188 finished with value: 0.8293171174337323 and parameters: {'n_estimators': 461}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:14:40,588]\u001b[0m Trial 189 finished with value: 0.8295779096090893 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:15:29,308]\u001b[0m Trial 190 finished with value: 0.8299072734218335 and parameters: {'n_estimators': 589}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:16:11,953]\u001b[0m Trial 191 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:16:58,330]\u001b[0m Trial 192 finished with value: 0.8293614152932923 and parameters: {'n_estimators': 560}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:17:42,800]\u001b[0m Trial 193 finished with value: 0.8290968050916719 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:18:25,567]\u001b[0m Trial 194 finished with value: 0.830708699620387 and parameters: {'n_estimators': 512}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:19:05,605]\u001b[0m Trial 195 finished with value: 0.8298866265153269 and parameters: {'n_estimators': 488}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 12:19:50,011]\u001b[0m Trial 196 finished with value: 0.8305234685010656 and parameters: {'n_estimators': 528}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:20:36,635]\u001b[0m Trial 197 finished with value: 0.8291621272141629 and parameters: {'n_estimators': 574}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:21:17,895]\u001b[0m Trial 198 finished with value: 0.8297875907547982 and parameters: {'n_estimators': 504}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:22:02,854]\u001b[0m Trial 199 finished with value: 0.8292359474762729 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 200.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_3 = lambda trial: objective_rf_CV(trial, X_trainSet3, Y_trainSet3, Y_trainSet3_class)\n",
    "study_rf.optimize(func_rf_3, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0700f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T03:57:14.337696Z",
     "iopub.status.busy": "2023-01-15T03:57:14.337496Z",
     "iopub.status.idle": "2023-01-15T03:57:33.755095Z",
     "shell.execute_reply": "2023-01-15T03:57:33.754491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000\n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000\n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000\n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000\n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697\n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374\n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765\n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500\n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000\n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336\n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952\n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136\n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968\n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900\n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136\n"
     ]
    }
   ],
   "source": [
    "optimized_rf_3 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_3.fit(X_trainSet3, Y_trainSet3,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_3 = optimized_rf_3.predict(X_testSet3)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet3, y_pred_rf_3)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet3, y_pred_rf_3)\n",
    "Precision = precision_score(Y_testSet3, y_pred_rf_3)\n",
    "Sensitivity = recall_score(Y_testSet3, y_pred_rf_3)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet3, y_pred_rf_3)      \n",
    "f1_scores_W = f1_score(Y_testSet3, y_pred_rf_3, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet3, y_pred_rf_3, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet3, y_pred_rf_3)\n",
    "MCC = matthews_corrcoef(Y_testSet3, y_pred_rf_3)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet3, y_pred_rf_3)\n",
    "data_testing['y_test_idx3'] = testindex3\n",
    "data_testing['y_test_Set3'] = Y_testSet3\n",
    "data_testing['y_pred_Set3'] = y_pred_rf_3\n",
    "\n",
    "\n",
    "set3 = pd.DataFrame({'Set3':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set3'] =set3   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5ca425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T03:57:33.757514Z",
     "iopub.status.busy": "2023-01-15T03:57:33.757343Z",
     "iopub.status.idle": "2023-01-15T06:15:19.424161Z",
     "shell.execute_reply": "2023-01-15T06:15:19.423694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 12:22:50,859]\u001b[0m Trial 200 finished with value: 0.834966648436539 and parameters: {'n_estimators': 537}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:23:36,065]\u001b[0m Trial 201 finished with value: 0.834966648436539 and parameters: {'n_estimators': 547}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:24:17,557]\u001b[0m Trial 202 finished with value: 0.8370566239962441 and parameters: {'n_estimators': 522}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:24:58,256]\u001b[0m Trial 203 finished with value: 0.8360062804526187 and parameters: {'n_estimators': 500}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:25:42,034]\u001b[0m Trial 204 finished with value: 0.834966648436539 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:26:24,620]\u001b[0m Trial 205 finished with value: 0.8365405473749293 and parameters: {'n_estimators': 520}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:27:09,269]\u001b[0m Trial 206 finished with value: 0.834966648436539 and parameters: {'n_estimators': 558}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:27:56,445]\u001b[0m Trial 207 finished with value: 0.8354780829588458 and parameters: {'n_estimators': 580}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:28:34,477]\u001b[0m Trial 208 finished with value: 0.8351702683849365 and parameters: {'n_estimators': 472}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:29:17,768]\u001b[0m Trial 209 finished with value: 0.8363636977260935 and parameters: {'n_estimators': 533}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:29:57,575]\u001b[0m Trial 210 finished with value: 0.8355787693014317 and parameters: {'n_estimators': 490}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:30:39,977]\u001b[0m Trial 211 finished with value: 0.8365405473749293 and parameters: {'n_estimators': 520}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:31:21,655]\u001b[0m Trial 212 finished with value: 0.8360773401495285 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:32:05,465]\u001b[0m Trial 213 finished with value: 0.8349671119906115 and parameters: {'n_estimators': 536}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:32:50,808]\u001b[0m Trial 214 finished with value: 0.8350091650179525 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:33:32,044]\u001b[0m Trial 215 finished with value: 0.8356447118719131 and parameters: {'n_estimators': 505}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:34:15,947]\u001b[0m Trial 216 finished with value: 0.834966648436539 and parameters: {'n_estimators': 547}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:34:58,500]\u001b[0m Trial 217 finished with value: 0.8370566239962441 and parameters: {'n_estimators': 522}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:35:38,311]\u001b[0m Trial 218 finished with value: 0.8355236377634112 and parameters: {'n_estimators': 487}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:36:22,323]\u001b[0m Trial 219 finished with value: 0.8349671119906115 and parameters: {'n_estimators': 536}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:37:07,454]\u001b[0m Trial 220 finished with value: 0.8358917807349615 and parameters: {'n_estimators': 562}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:37:49,631]\u001b[0m Trial 221 finished with value: 0.8364869875335715 and parameters: {'n_estimators': 525}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:38:30,605]\u001b[0m Trial 222 finished with value: 0.8360773401495285 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:39:11,346]\u001b[0m Trial 223 finished with value: 0.8356013738993961 and parameters: {'n_estimators': 504}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:39:54,983]\u001b[0m Trial 224 finished with value: 0.834966648436539 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:40:37,580]\u001b[0m Trial 225 finished with value: 0.835489731000302 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:41:21,552]\u001b[0m Trial 226 finished with value: 0.8353777505559385 and parameters: {'n_estimators': 551}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:42:01,986]\u001b[0m Trial 227 finished with value: 0.8355430732272179 and parameters: {'n_estimators': 502}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:42:49,248]\u001b[0m Trial 228 finished with value: 0.8358421948845483 and parameters: {'n_estimators': 582}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:43:28,078]\u001b[0m Trial 229 finished with value: 0.835522268922596 and parameters: {'n_estimators': 479}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:44:10,621]\u001b[0m Trial 230 finished with value: 0.8360105605221637 and parameters: {'n_estimators': 527}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:44:52,429]\u001b[0m Trial 231 finished with value: 0.8365405473749293 and parameters: {'n_estimators': 520}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:45:34,100]\u001b[0m Trial 232 finished with value: 0.8360773401495285 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:46:17,222]\u001b[0m Trial 233 finished with value: 0.8350191341133486 and parameters: {'n_estimators': 538}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:46:57,446]\u001b[0m Trial 234 finished with value: 0.8356320248399112 and parameters: {'n_estimators': 496}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:47:42,287]\u001b[0m Trial 235 finished with value: 0.834966648436539 and parameters: {'n_estimators': 565}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:48:23,617]\u001b[0m Trial 236 finished with value: 0.8364827074640264 and parameters: {'n_estimators': 510}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:49:06,826]\u001b[0m Trial 237 finished with value: 0.8350191341133486 and parameters: {'n_estimators': 541}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:49:50,476]\u001b[0m Trial 238 finished with value: 0.835489731000302 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:50:35,026]\u001b[0m Trial 239 finished with value: 0.8353777505559385 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:51:15,771]\u001b[0m Trial 240 finished with value: 0.835167961064404 and parameters: {'n_estimators': 493}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:51:57,820]\u001b[0m Trial 241 finished with value: 0.8360628382111426 and parameters: {'n_estimators': 517}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:52:41,908]\u001b[0m Trial 242 finished with value: 0.8364740233138062 and parameters: {'n_estimators': 534}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:53:23,625]\u001b[0m Trial 243 finished with value: 0.8356009131381207 and parameters: {'n_estimators': 511}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:53:49,107]\u001b[0m Trial 244 finished with value: 0.8371562249224777 and parameters: {'n_estimators': 315}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:54:34,393]\u001b[0m Trial 245 finished with value: 0.8353777505559385 and parameters: {'n_estimators': 554}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 12:55:11,813]\u001b[0m Trial 246 finished with value: 0.8351728457451542 and parameters: {'n_estimators': 466}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:55:58,057]\u001b[0m Trial 247 finished with value: 0.8340831761694238 and parameters: {'n_estimators': 570}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:56:40,391]\u001b[0m Trial 248 finished with value: 0.8360105605221637 and parameters: {'n_estimators': 527}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:57:20,722]\u001b[0m Trial 249 finished with value: 0.835167961064404 and parameters: {'n_estimators': 493}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 250.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_4 = lambda trial: objective_rf_CV(trial, X_trainSet4, Y_trainSet4, Y_trainSet4_class)\n",
    "study_rf.optimize(func_rf_4, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77894dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:15:19.426245Z",
     "iopub.status.busy": "2023-01-15T06:15:19.426060Z",
     "iopub.status.idle": "2023-01-15T06:15:38.478954Z",
     "shell.execute_reply": "2023-01-15T06:15:38.478601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4  \n",
      "0   339.000000  \n",
      "1   159.000000  \n",
      "2    66.000000  \n",
      "3    31.000000  \n",
      "4     0.836975  \n",
      "5     0.837037  \n",
      "6     0.916216  \n",
      "7     0.706700  \n",
      "8     0.874839  \n",
      "9     0.833781  \n",
      "10    0.820552  \n",
      "11    0.811441  \n",
      "12    0.647879  \n",
      "13    0.836800  \n",
      "14    0.811441  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_4 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_4.fit(X_trainSet4, Y_trainSet4,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_4 = optimized_rf_4.predict(X_testSet4)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet4, y_pred_rf_4)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet4, y_pred_rf_4)\n",
    "Precision = precision_score(Y_testSet4, y_pred_rf_4)\n",
    "Sensitivity = recall_score(Y_testSet4, y_pred_rf_4)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet4, y_pred_rf_4)      \n",
    "f1_scores_W = f1_score(Y_testSet4, y_pred_rf_4, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet4, y_pred_rf_4, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet4, y_pred_rf_4)\n",
    "MCC = matthews_corrcoef(Y_testSet4, y_pred_rf_4)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet4, y_pred_rf_4)\n",
    "data_testing['y_test_idx4'] = testindex4\n",
    "data_testing['y_test_Set4'] = Y_testSet4\n",
    "data_testing['y_pred_Set4'] = y_pred_rf_4\n",
    "\n",
    "set4 = pd.DataFrame({'Set4':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set4'] =set4   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37431445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:15:38.480519Z",
     "iopub.status.busy": "2023-01-15T06:15:38.480355Z",
     "iopub.status.idle": "2023-01-15T08:33:10.996486Z",
     "shell.execute_reply": "2023-01-15T08:33:10.995987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 12:58:08,638]\u001b[0m Trial 250 finished with value: 0.820208539141588 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:58:48,574]\u001b[0m Trial 251 finished with value: 0.8199570336764879 and parameters: {'n_estimators': 505}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 12:59:35,360]\u001b[0m Trial 252 finished with value: 0.8215607228201863 and parameters: {'n_estimators': 595}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:00:16,935]\u001b[0m Trial 253 finished with value: 0.8200927940606224 and parameters: {'n_estimators': 526}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:00:54,960]\u001b[0m Trial 254 finished with value: 0.8223278500994027 and parameters: {'n_estimators': 480}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:01:37,864]\u001b[0m Trial 255 finished with value: 0.8206019848820608 and parameters: {'n_estimators': 544}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:02:13,605]\u001b[0m Trial 256 finished with value: 0.8215036662107178 and parameters: {'n_estimators': 450}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:02:57,989]\u001b[0m Trial 257 finished with value: 0.8211002951225088 and parameters: {'n_estimators': 564}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:03:16,371]\u001b[0m Trial 258 finished with value: 0.8205378452395584 and parameters: {'n_estimators': 225}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:03:56,857]\u001b[0m Trial 259 finished with value: 0.8214148907850527 and parameters: {'n_estimators': 512}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:04:38,095]\u001b[0m Trial 260 finished with value: 0.8201569742813584 and parameters: {'n_estimators': 531}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:05:17,346]\u001b[0m Trial 261 finished with value: 0.821244878438779 and parameters: {'n_estimators': 499}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:05:59,989]\u001b[0m Trial 262 finished with value: 0.820622986305 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:06:40,737]\u001b[0m Trial 263 finished with value: 0.8195708034478499 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:07:25,691]\u001b[0m Trial 264 finished with value: 0.8215607228201863 and parameters: {'n_estimators': 575}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:08:03,285]\u001b[0m Trial 265 finished with value: 0.8218460229656003 and parameters: {'n_estimators': 481}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:08:42,770]\u001b[0m Trial 266 finished with value: 0.8213067570553984 and parameters: {'n_estimators': 509}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:09:25,063]\u001b[0m Trial 267 finished with value: 0.8202701439804134 and parameters: {'n_estimators': 538}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:09:48,684]\u001b[0m Trial 268 finished with value: 0.8235690760931338 and parameters: {'n_estimators': 294}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:10:32,434]\u001b[0m Trial 269 finished with value: 0.8216255909437651 and parameters: {'n_estimators': 562}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:11:13,462]\u001b[0m Trial 270 finished with value: 0.8194090375427366 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:11:51,732]\u001b[0m Trial 271 finished with value: 0.8214018311043001 and parameters: {'n_estimators': 493}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:12:34,310]\u001b[0m Trial 272 finished with value: 0.8206019848820608 and parameters: {'n_estimators': 544}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:13:14,317]\u001b[0m Trial 273 finished with value: 0.821917136654557 and parameters: {'n_estimators': 514}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:13:56,447]\u001b[0m Trial 274 finished with value: 0.821080612266209 and parameters: {'n_estimators': 535}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:14:39,908]\u001b[0m Trial 275 finished with value: 0.8202059637596774 and parameters: {'n_estimators': 558}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:15:25,821]\u001b[0m Trial 276 finished with value: 0.8210813868674254 and parameters: {'n_estimators': 585}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:16:03,925]\u001b[0m Trial 277 finished with value: 0.8209789442058956 and parameters: {'n_estimators': 473}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:16:30,624]\u001b[0m Trial 278 finished with value: 0.8212508956229378 and parameters: {'n_estimators': 336}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:17:10,980]\u001b[0m Trial 279 finished with value: 0.8208468026838988 and parameters: {'n_estimators': 503}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:17:45,528]\u001b[0m Trial 280 finished with value: 0.821450134575713 and parameters: {'n_estimators': 433}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:18:27,109]\u001b[0m Trial 281 finished with value: 0.8194090375427366 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:19:10,600]\u001b[0m Trial 282 finished with value: 0.820622986305 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:19:49,821]\u001b[0m Trial 283 finished with value: 0.8218811670570609 and parameters: {'n_estimators': 494}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:20:31,623]\u001b[0m Trial 284 finished with value: 0.8204862398010953 and parameters: {'n_estimators': 525}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:21:14,311]\u001b[0m Trial 285 finished with value: 0.8197915165962654 and parameters: {'n_estimators': 539}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:22:00,067]\u001b[0m Trial 286 finished with value: 0.8210813868674254 and parameters: {'n_estimators': 574}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:22:40,299]\u001b[0m Trial 287 finished with value: 0.8199570336764879 and parameters: {'n_estimators': 505}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:23:24,861]\u001b[0m Trial 288 finished with value: 0.8211002951225088 and parameters: {'n_estimators': 563}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:24:05,875]\u001b[0m Trial 289 finished with value: 0.8197974721468257 and parameters: {'n_estimators': 518}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:24:54,128]\u001b[0m Trial 290 finished with value: 0.821473155995268 and parameters: {'n_estimators': 606}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:25:32,644]\u001b[0m Trial 291 finished with value: 0.8228902042818446 and parameters: {'n_estimators': 483}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:26:08,721]\u001b[0m Trial 292 finished with value: 0.821439094441183 and parameters: {'n_estimators': 455}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:26:51,533]\u001b[0m Trial 293 finished with value: 0.8201849623367382 and parameters: {'n_estimators': 541}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:27:32,397]\u001b[0m Trial 294 finished with value: 0.8212845428602119 and parameters: {'n_estimators': 511}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:28:16,578]\u001b[0m Trial 295 finished with value: 0.8202059637596774 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 13:28:59,184]\u001b[0m Trial 296 finished with value: 0.821080612266209 and parameters: {'n_estimators': 535}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:29:20,435]\u001b[0m Trial 297 finished with value: 0.8205332875171589 and parameters: {'n_estimators': 261}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:29:59,870]\u001b[0m Trial 298 finished with value: 0.8208738453690403 and parameters: {'n_estimators': 501}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:30:41,248]\u001b[0m Trial 299 finished with value: 0.8194090375427366 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 300.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_5 = lambda trial: objective_rf_CV(trial, X_trainSet5, Y_trainSet5, Y_trainSet5_class)\n",
    "study_rf.optimize(func_rf_5, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd17f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T08:33:10.998639Z",
     "iopub.status.busy": "2023-01-15T08:33:10.998378Z",
     "iopub.status.idle": "2023-01-15T08:33:29.977633Z",
     "shell.execute_reply": "2023-01-15T08:33:29.977102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4        Set5  \n",
      "0   339.000000  343.000000  \n",
      "1   159.000000  170.000000  \n",
      "2    66.000000   55.000000  \n",
      "3    31.000000   27.000000  \n",
      "4     0.836975    0.862185  \n",
      "5     0.837037    0.861809  \n",
      "6     0.916216    0.927027  \n",
      "7     0.706700    0.755600  \n",
      "8     0.874839    0.893229  \n",
      "9     0.833781    0.860125  \n",
      "10    0.820552    0.849458  \n",
      "11    0.811441    0.841291  \n",
      "12    0.647879    0.703352  \n",
      "13    0.836800    0.862900  \n",
      "14    0.811441    0.841291  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_5 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_5.fit(X_trainSet5, Y_trainSet5,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_5 = optimized_rf_5.predict(X_testSet5)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet5, y_pred_rf_5)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet5, y_pred_rf_5)\n",
    "Precision = precision_score(Y_testSet5, y_pred_rf_5)\n",
    "Sensitivity = recall_score(Y_testSet5, y_pred_rf_5)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet5, y_pred_rf_5)      \n",
    "f1_scores_W = f1_score(Y_testSet5, y_pred_rf_5, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet5, y_pred_rf_5, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet5, y_pred_rf_5)\n",
    "MCC = matthews_corrcoef(Y_testSet5, y_pred_rf_5)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet5, y_pred_rf_5)\n",
    "data_testing['y_test_idx5'] = testindex5\n",
    "data_testing['y_test_Set5'] = Y_testSet5\n",
    "data_testing['y_pred_Set5'] = y_pred_rf_5\n",
    "\n",
    "\n",
    "Set5 = pd.DataFrame({'Set5':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set5'] =Set5   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90f360eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T08:33:29.979593Z",
     "iopub.status.busy": "2023-01-15T08:33:29.979276Z",
     "iopub.status.idle": "2023-01-15T10:11:11.995998Z",
     "shell.execute_reply": "2023-01-15T10:11:11.995579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 13:31:14,839]\u001b[0m Trial 300 finished with value: 0.8284967375807692 and parameters: {'n_estimators': 363}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:31:48,594]\u001b[0m Trial 301 finished with value: 0.8287472724763086 and parameters: {'n_estimators': 413}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:32:26,980]\u001b[0m Trial 302 finished with value: 0.8304979418872138 and parameters: {'n_estimators': 483}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:33:13,255]\u001b[0m Trial 303 finished with value: 0.8301639701850773 and parameters: {'n_estimators': 575}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:33:56,643]\u001b[0m Trial 304 finished with value: 0.8300728042396678 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:34:39,702]\u001b[0m Trial 305 finished with value: 0.8290817049581187 and parameters: {'n_estimators': 534}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:35:21,252]\u001b[0m Trial 306 finished with value: 0.8291590842532255 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:35:59,000]\u001b[0m Trial 307 finished with value: 0.8281556227197463 and parameters: {'n_estimators': 467}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:36:55,158]\u001b[0m Trial 308 finished with value: 0.831328518794612 and parameters: {'n_estimators': 711}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:37:42,247]\u001b[0m Trial 309 finished with value: 0.8309950282422779 and parameters: {'n_estimators': 591}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:38:21,616]\u001b[0m Trial 310 finished with value: 0.8286818374264058 and parameters: {'n_estimators': 493}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:39:04,141]\u001b[0m Trial 311 finished with value: 0.8286699631195745 and parameters: {'n_estimators': 539}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:39:49,271]\u001b[0m Trial 312 finished with value: 0.8291877217835827 and parameters: {'n_estimators': 563}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:40:39,039]\u001b[0m Trial 313 finished with value: 0.8304734361087762 and parameters: {'n_estimators': 625}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:41:20,198]\u001b[0m Trial 314 finished with value: 0.8291590842532255 and parameters: {'n_estimators': 516}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:42:22,012]\u001b[0m Trial 315 finished with value: 0.8304037068421675 and parameters: {'n_estimators': 780}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:43:05,394]\u001b[0m Trial 316 finished with value: 0.8300641694761847 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:43:47,652]\u001b[0m Trial 317 finished with value: 0.8291613712209575 and parameters: {'n_estimators': 526}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:44:26,880]\u001b[0m Trial 318 finished with value: 0.8287619005913521 and parameters: {'n_estimators': 500}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:45:09,206]\u001b[0m Trial 319 finished with value: 0.8290817049581187 and parameters: {'n_estimators': 534}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:45:49,771]\u001b[0m Trial 320 finished with value: 0.829167649078336 and parameters: {'n_estimators': 510}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:46:34,553]\u001b[0m Trial 321 finished with value: 0.8287673451815556 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:47:12,201]\u001b[0m Trial 322 finished with value: 0.8296709718166226 and parameters: {'n_estimators': 480}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:47:56,158]\u001b[0m Trial 323 finished with value: 0.8300641694761847 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:48:38,290]\u001b[0m Trial 324 finished with value: 0.8291613712209575 and parameters: {'n_estimators': 526}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:49:17,760]\u001b[0m Trial 325 finished with value: 0.8287619005913521 and parameters: {'n_estimators': 500}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:50:01,454]\u001b[0m Trial 326 finished with value: 0.8304010235225256 and parameters: {'n_estimators': 541}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:50:32,491]\u001b[0m Trial 327 finished with value: 0.8278375314513913 and parameters: {'n_estimators': 390}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:51:18,724]\u001b[0m Trial 328 finished with value: 0.8306380893075067 and parameters: {'n_estimators': 581}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:51:59,940]\u001b[0m Trial 329 finished with value: 0.8292142687597798 and parameters: {'n_estimators': 519}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:52:37,967]\u001b[0m Trial 330 finished with value: 0.8286640619309212 and parameters: {'n_estimators': 469}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:53:17,149]\u001b[0m Trial 331 finished with value: 0.8282715998299477 and parameters: {'n_estimators': 494}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:54:02,069]\u001b[0m Trial 332 finished with value: 0.8291877217835827 and parameters: {'n_estimators': 557}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:54:26,832]\u001b[0m Trial 333 finished with value: 0.8295065956209277 and parameters: {'n_estimators': 306}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:55:09,925]\u001b[0m Trial 334 finished with value: 0.8290817049581187 and parameters: {'n_estimators': 534}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:55:45,473]\u001b[0m Trial 335 finished with value: 0.827730506717022 and parameters: {'n_estimators': 446}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:56:12,942]\u001b[0m Trial 336 finished with value: 0.8289087457570045 and parameters: {'n_estimators': 339}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:56:53,582]\u001b[0m Trial 337 finished with value: 0.829167649078336 and parameters: {'n_estimators': 510}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:57:39,606]\u001b[0m Trial 338 finished with value: 0.8297319613587122 and parameters: {'n_estimators': 573}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:58:22,953]\u001b[0m Trial 339 finished with value: 0.8299258440167252 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:59:04,754]\u001b[0m Trial 340 finished with value: 0.8292142687597798 and parameters: {'n_estimators': 519}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 13:59:43,308]\u001b[0m Trial 341 finished with value: 0.8295940889702964 and parameters: {'n_estimators': 487}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:00:26,179]\u001b[0m Trial 342 finished with value: 0.8287505629839298 and parameters: {'n_estimators': 530}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:01:12,965]\u001b[0m Trial 343 finished with value: 0.8301680581716869 and parameters: {'n_estimators': 596}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:02:25,957]\u001b[0m Trial 344 finished with value: 0.8305783041031424 and parameters: {'n_estimators': 914}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:03:09,933]\u001b[0m Trial 345 finished with value: 0.8288339914822054 and parameters: {'n_estimators': 558}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 14:03:50,725]\u001b[0m Trial 346 finished with value: 0.8287619005913521 and parameters: {'n_estimators': 506}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:04:33,418]\u001b[0m Trial 347 finished with value: 0.8304010235225256 and parameters: {'n_estimators': 543}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:05:15,381]\u001b[0m Trial 348 finished with value: 0.8291590842532255 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:05:54,322]\u001b[0m Trial 349 finished with value: 0.8283516629948938 and parameters: {'n_estimators': 492}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 350.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_6 = lambda trial: objective_rf_CV(trial, X_trainSet6, Y_trainSet6, Y_trainSet6_class)\n",
    "study_rf.optimize(func_rf_6, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd421234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T10:11:11.997932Z",
     "iopub.status.busy": "2023-01-15T10:11:11.997620Z",
     "iopub.status.idle": "2023-01-15T10:11:22.934087Z",
     "shell.execute_reply": "2023-01-15T10:11:22.933680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4        Set5        Set6  \n",
      "0   339.000000  343.000000  332.000000  \n",
      "1   159.000000  170.000000  177.000000  \n",
      "2    66.000000   55.000000   55.000000  \n",
      "3    31.000000   27.000000   31.000000  \n",
      "4     0.836975    0.862185    0.855462  \n",
      "5     0.837037    0.861809    0.857881  \n",
      "6     0.916216    0.927027    0.914601  \n",
      "7     0.706700    0.755600    0.762900  \n",
      "8     0.874839    0.893229    0.885333  \n",
      "9     0.833781    0.860125    0.853833  \n",
      "10    0.820552    0.849458    0.844939  \n",
      "11    0.811441    0.841291    0.838766  \n",
      "12    0.647879    0.703352    0.693010  \n",
      "13    0.836800    0.862900    0.851000  \n",
      "14    0.811441    0.841291    0.838766  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_6 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_6.fit(X_trainSet6, Y_trainSet6,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_6 = optimized_rf_6.predict(X_testSet6)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet6, y_pred_rf_6)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet6, y_pred_rf_6)\n",
    "Precision = precision_score(Y_testSet6, y_pred_rf_6)\n",
    "Sensitivity = recall_score(Y_testSet6, y_pred_rf_6)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet6, y_pred_rf_6)      \n",
    "f1_scores_W = f1_score(Y_testSet6, y_pred_rf_6, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet6, y_pred_rf_6, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet6, y_pred_rf_6)\n",
    "MCC = matthews_corrcoef(Y_testSet6, y_pred_rf_6)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet6, y_pred_rf_6)\n",
    "data_testing['y_test_idx6'] = testindex6\n",
    "data_testing['y_test_Set6'] = Y_testSet6\n",
    "data_testing['y_pred_Set6'] = y_pred_rf_6\n",
    "\n",
    "\n",
    "Set6 = pd.DataFrame({'Set6':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set6'] =Set6   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26e94d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T10:11:22.936113Z",
     "iopub.status.busy": "2023-01-15T10:11:22.935897Z",
     "iopub.status.idle": "2023-01-15T11:29:11.681833Z",
     "shell.execute_reply": "2023-01-15T11:29:11.681472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 14:06:42,463]\u001b[0m Trial 350 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 533}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:07:28,715]\u001b[0m Trial 351 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 565}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:08:10,316]\u001b[0m Trial 352 finished with value: 0.8319787004092323 and parameters: {'n_estimators': 507}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:08:48,543]\u001b[0m Trial 353 finished with value: 0.8305863949428105 and parameters: {'n_estimators': 464}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:09:33,750]\u001b[0m Trial 354 finished with value: 0.8327645207371077 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:10:16,578]\u001b[0m Trial 355 finished with value: 0.8323914657431823 and parameters: {'n_estimators': 518}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:10:39,526]\u001b[0m Trial 356 finished with value: 0.8318316256283447 and parameters: {'n_estimators': 276}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:11:18,425]\u001b[0m Trial 357 finished with value: 0.8319744101489734 and parameters: {'n_estimators': 479}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:12:01,305]\u001b[0m Trial 358 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 533}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:12:48,049]\u001b[0m Trial 359 finished with value: 0.8337550009086678 and parameters: {'n_estimators': 578}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:13:29,178]\u001b[0m Trial 360 finished with value: 0.8324965352798257 and parameters: {'n_estimators': 504}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:14:13,732]\u001b[0m Trial 361 finished with value: 0.8327645207371077 and parameters: {'n_estimators': 549}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:14:55,674]\u001b[0m Trial 362 finished with value: 0.8318614360442107 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:15:35,588]\u001b[0m Trial 363 finished with value: 0.8324906655850406 and parameters: {'n_estimators': 488}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:16:18,364]\u001b[0m Trial 364 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 535}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:17:04,278]\u001b[0m Trial 365 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:17:38,635]\u001b[0m Trial 366 finished with value: 0.8301647434134282 and parameters: {'n_estimators': 420}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:18:19,871]\u001b[0m Trial 367 finished with value: 0.8319787004092323 and parameters: {'n_estimators': 509}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:19:03,673]\u001b[0m Trial 368 finished with value: 0.8332831827785239 and parameters: {'n_estimators': 543}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:19:24,173]\u001b[0m Trial 369 finished with value: 0.8332332041509647 and parameters: {'n_estimators': 243}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:20:06,625]\u001b[0m Trial 370 finished with value: 0.8318614360442107 and parameters: {'n_estimators': 523}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:20:55,094]\u001b[0m Trial 371 finished with value: 0.8329047363740774 and parameters: {'n_estimators': 599}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:21:40,166]\u001b[0m Trial 372 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 560}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:22:20,220]\u001b[0m Trial 373 finished with value: 0.8324395483174214 and parameters: {'n_estimators': 499}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:23:03,550]\u001b[0m Trial 374 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 532}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:23:41,343]\u001b[0m Trial 375 finished with value: 0.8315575831907267 and parameters: {'n_estimators': 473}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:24:28,426]\u001b[0m Trial 376 finished with value: 0.8337887947985918 and parameters: {'n_estimators': 583}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:24:58,649]\u001b[0m Trial 377 finished with value: 0.8300416896141869 and parameters: {'n_estimators': 371}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:25:40,632]\u001b[0m Trial 378 finished with value: 0.8329093006137758 and parameters: {'n_estimators': 514}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:26:24,176]\u001b[0m Trial 379 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:27:03,924]\u001b[0m Trial 380 finished with value: 0.8324906655850406 and parameters: {'n_estimators': 488}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:27:46,136]\u001b[0m Trial 381 finished with value: 0.8323792709148041 and parameters: {'n_estimators': 525}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:28:31,535]\u001b[0m Trial 382 finished with value: 0.8327645207371077 and parameters: {'n_estimators': 557}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:29:11,549]\u001b[0m Trial 383 finished with value: 0.8329052114490014 and parameters: {'n_estimators': 500}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:29:55,286]\u001b[0m Trial 384 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 539}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:30:31,991]\u001b[0m Trial 385 finished with value: 0.830486289759202 and parameters: {'n_estimators': 455}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:31:14,144]\u001b[0m Trial 386 finished with value: 0.8318614360442107 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:31:59,481]\u001b[0m Trial 387 finished with value: 0.8332831827785239 and parameters: {'n_estimators': 569}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:32:51,924]\u001b[0m Trial 388 finished with value: 0.833376721751948 and parameters: {'n_estimators': 657}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:33:33,362]\u001b[0m Trial 389 finished with value: 0.8319787004092323 and parameters: {'n_estimators': 509}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:34:17,704]\u001b[0m Trial 390 finished with value: 0.8332831827785239 and parameters: {'n_estimators': 553}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:35:01,162]\u001b[0m Trial 391 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 535}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:35:27,531]\u001b[0m Trial 392 finished with value: 0.8299918002001799 and parameters: {'n_estimators': 319}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:36:07,050]\u001b[0m Trial 393 finished with value: 0.8320250024534606 and parameters: {'n_estimators': 487}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:36:48,431]\u001b[0m Trial 394 finished with value: 0.8324965352798257 and parameters: {'n_estimators': 511}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:37:35,662]\u001b[0m Trial 395 finished with value: 0.8333572625805775 and parameters: {'n_estimators': 584}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 14:38:19,370]\u001b[0m Trial 396 finished with value: 0.8323338156899162 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:39:02,062]\u001b[0m Trial 397 finished with value: 0.8328516505605096 and parameters: {'n_estimators': 528}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:40:21,391]\u001b[0m Trial 398 finished with value: 0.8323542257956837 and parameters: {'n_estimators': 1000}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:41:01,420]\u001b[0m Trial 399 finished with value: 0.8324395483174214 and parameters: {'n_estimators': 497}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 400.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_7 = lambda trial: objective_rf_CV(trial, X_trainSet7, Y_trainSet7, Y_trainSet7_class)\n",
    "study_rf.optimize(func_rf_7, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c60073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T11:29:11.683621Z",
     "iopub.status.busy": "2023-01-15T11:29:11.683440Z",
     "iopub.status.idle": "2023-01-15T11:29:20.997193Z",
     "shell.execute_reply": "2023-01-15T11:29:20.996743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4        Set5        Set6        Set7  \n",
      "0   339.000000  343.000000  332.000000  344.000000  \n",
      "1   159.000000  170.000000  177.000000  174.000000  \n",
      "2    66.000000   55.000000   55.000000   47.000000  \n",
      "3    31.000000   27.000000   31.000000   30.000000  \n",
      "4     0.836975    0.862185    0.855462    0.870588  \n",
      "5     0.837037    0.861809    0.857881    0.879795  \n",
      "6     0.916216    0.927027    0.914601    0.919786  \n",
      "7     0.706700    0.755600    0.762900    0.787300  \n",
      "8     0.874839    0.893229    0.885333    0.899346  \n",
      "9     0.833781    0.860125    0.853833    0.869438  \n",
      "10    0.820552    0.849458    0.844939    0.859085  \n",
      "11    0.811441    0.841291    0.838766    0.853558  \n",
      "12    0.647879    0.703352    0.693010    0.719813  \n",
      "13    0.836800    0.862900    0.851000    0.852900  \n",
      "14    0.811441    0.841291    0.838766    0.853558  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_7 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_7.fit(X_trainSet7, Y_trainSet7,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_7 = optimized_rf_7.predict(X_testSet7)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet7, y_pred_rf_7)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet7, y_pred_rf_7)\n",
    "Precision = precision_score(Y_testSet7, y_pred_rf_7)\n",
    "Sensitivity = recall_score(Y_testSet7, y_pred_rf_7)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet7, y_pred_rf_7)      \n",
    "f1_scores_W = f1_score(Y_testSet7, y_pred_rf_7, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet7, y_pred_rf_7, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet7, y_pred_rf_7)\n",
    "MCC = matthews_corrcoef(Y_testSet7, y_pred_rf_7)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet7, y_pred_rf_7)\n",
    "data_testing['y_test_idx7'] = testindex7\n",
    "data_testing['y_test_Set7'] = Y_testSet7\n",
    "data_testing['y_pred_Set7'] = y_pred_rf_7\n",
    "\n",
    "Set7 = pd.DataFrame({'Set7':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set7'] =Set7   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c09790c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T11:29:20.999164Z",
     "iopub.status.busy": "2023-01-15T11:29:20.998897Z",
     "iopub.status.idle": "2023-01-15T12:40:02.426998Z",
     "shell.execute_reply": "2023-01-15T12:40:02.426494Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 14:41:43,000]\u001b[0m Trial 400 finished with value: 0.8286219705907685 and parameters: {'n_estimators': 467}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:42:26,765]\u001b[0m Trial 401 finished with value: 0.8278163338146374 and parameters: {'n_estimators': 562}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:43:07,345]\u001b[0m Trial 402 finished with value: 0.8277500478838606 and parameters: {'n_estimators': 517}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:43:50,321]\u001b[0m Trial 403 finished with value: 0.8291363002062516 and parameters: {'n_estimators': 536}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:44:30,477]\u001b[0m Trial 404 finished with value: 0.8298925056512539 and parameters: {'n_estimators': 503}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:45:14,880]\u001b[0m Trial 405 finished with value: 0.8273960836866703 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:46:00,243]\u001b[0m Trial 406 finished with value: 0.8287971673521355 and parameters: {'n_estimators': 572}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:46:35,764]\u001b[0m Trial 407 finished with value: 0.8300065669841837 and parameters: {'n_estimators': 442}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:47:14,446]\u001b[0m Trial 408 finished with value: 0.8298593044722242 and parameters: {'n_estimators': 481}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:47:56,689]\u001b[0m Trial 409 finished with value: 0.8281468381795308 and parameters: {'n_estimators': 524}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:48:39,712]\u001b[0m Trial 410 finished with value: 0.8294654928308602 and parameters: {'n_estimators': 539}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:49:08,112]\u001b[0m Trial 411 finished with value: 0.8301736320150294 and parameters: {'n_estimators': 348}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:49:49,077]\u001b[0m Trial 412 finished with value: 0.829140034151922 and parameters: {'n_estimators': 511}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:50:34,485]\u001b[0m Trial 413 finished with value: 0.8278163338146374 and parameters: {'n_estimators': 560}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:51:23,095]\u001b[0m Trial 414 finished with value: 0.8309276170631396 and parameters: {'n_estimators': 610}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:52:02,799]\u001b[0m Trial 415 finished with value: 0.8287115028339078 and parameters: {'n_estimators': 494}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:52:44,826]\u001b[0m Trial 416 finished with value: 0.8281468381795308 and parameters: {'n_estimators': 526}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:53:28,889]\u001b[0m Trial 417 finished with value: 0.8273960836866703 and parameters: {'n_estimators': 550}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:54:10,333]\u001b[0m Trial 418 finished with value: 0.8281551195308273 and parameters: {'n_estimators': 515}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:54:41,661]\u001b[0m Trial 419 finished with value: 0.8300747325907156 and parameters: {'n_estimators': 402}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:55:23,570]\u001b[0m Trial 420 finished with value: 0.829049659089405 and parameters: {'n_estimators': 534}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:56:08,801]\u001b[0m Trial 421 finished with value: 0.8296142514065205 and parameters: {'n_estimators': 581}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:56:46,806]\u001b[0m Trial 422 finished with value: 0.8298593044722242 and parameters: {'n_estimators': 481}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:57:26,526]\u001b[0m Trial 423 finished with value: 0.8295600282931126 and parameters: {'n_estimators': 507}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:57:37,052]\u001b[0m Trial 424 finished with value: 0.8308854339539469 and parameters: {'n_estimators': 121}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:58:19,467]\u001b[0m Trial 425 finished with value: 0.8277219283755987 and parameters: {'n_estimators': 543}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:59:01,035]\u001b[0m Trial 426 finished with value: 0.8285588338232877 and parameters: {'n_estimators': 525}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 14:59:44,928]\u001b[0m Trial 427 finished with value: 0.8287220830286939 and parameters: {'n_estimators': 564}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:00:24,322]\u001b[0m Trial 428 finished with value: 0.8299423536659439 and parameters: {'n_estimators': 497}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:00:39,756]\u001b[0m Trial 429 finished with value: 0.8306064862732206 and parameters: {'n_estimators': 188}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:01:22,375]\u001b[0m Trial 430 finished with value: 0.8282223669144431 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:02:02,998]\u001b[0m Trial 431 finished with value: 0.8281468381795308 and parameters: {'n_estimators': 522}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:02:40,243]\u001b[0m Trial 432 finished with value: 0.829933916348967 and parameters: {'n_estimators': 472}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:03:25,813]\u001b[0m Trial 433 finished with value: 0.8287922936958007 and parameters: {'n_estimators': 590}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:04:05,561]\u001b[0m Trial 434 finished with value: 0.8301173236674012 and parameters: {'n_estimators': 504}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:04:49,078]\u001b[0m Trial 435 finished with value: 0.8268311753185721 and parameters: {'n_estimators': 559}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:05:30,424]\u001b[0m Trial 436 finished with value: 0.8285763311116334 and parameters: {'n_estimators': 520}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:06:12,859]\u001b[0m Trial 437 finished with value: 0.8291329300801362 and parameters: {'n_estimators': 540}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:06:48,810]\u001b[0m Trial 438 finished with value: 0.8291117090557094 and parameters: {'n_estimators': 455}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:07:27,332]\u001b[0m Trial 439 finished with value: 0.8286357880254741 and parameters: {'n_estimators': 489}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:08:12,446]\u001b[0m Trial 440 finished with value: 0.8287158514190764 and parameters: {'n_estimators': 574}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:08:54,067]\u001b[0m Trial 441 finished with value: 0.828553058648259 and parameters: {'n_estimators': 532}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:09:34,345]\u001b[0m Trial 442 finished with value: 0.8296274584201125 and parameters: {'n_estimators': 512}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:10:18,141]\u001b[0m Trial 443 finished with value: 0.8269102453400127 and parameters: {'n_estimators': 556}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:10:57,426]\u001b[0m Trial 444 finished with value: 0.8299423536659439 and parameters: {'n_estimators': 497}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:11:21,376]\u001b[0m Trial 445 finished with value: 0.8304367880101967 and parameters: {'n_estimators': 295}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:12:03,165]\u001b[0m Trial 446 finished with value: 0.8289688923897142 and parameters: {'n_estimators': 533}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:12:46,564]\u001b[0m Trial 447 finished with value: 0.8278119174281254 and parameters: {'n_estimators': 548}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:13:27,003]\u001b[0m Trial 448 finished with value: 0.829140034151922 and parameters: {'n_estimators': 514}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:13:56,635]\u001b[0m Trial 449 finished with value: 0.8322253729378841 and parameters: {'n_estimators': 371}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 450.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_8 = lambda trial: objective_rf_CV(trial, X_trainSet8, Y_trainSet8, Y_trainSet8_class)\n",
    "study_rf.optimize(func_rf_8, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b28fc6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T12:40:02.428883Z",
     "iopub.status.busy": "2023-01-15T12:40:02.428732Z",
     "iopub.status.idle": "2023-01-15T12:40:12.099940Z",
     "shell.execute_reply": "2023-01-15T12:40:12.099548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8  \n",
      "0   339.000000  343.000000  332.000000  344.000000  344.000000  \n",
      "1   159.000000  170.000000  177.000000  174.000000  167.000000  \n",
      "2    66.000000   55.000000   55.000000   47.000000   60.000000  \n",
      "3    31.000000   27.000000   31.000000   30.000000   24.000000  \n",
      "4     0.836975    0.862185    0.855462    0.870588    0.858824  \n",
      "5     0.837037    0.861809    0.857881    0.879795    0.851485  \n",
      "6     0.916216    0.927027    0.914601    0.919786    0.934783  \n",
      "7     0.706700    0.755600    0.762900    0.787300    0.735700  \n",
      "8     0.874839    0.893229    0.885333    0.899346    0.891192  \n",
      "9     0.833781    0.860125    0.853833    0.869438    0.856036  \n",
      "10    0.820552    0.849458    0.844939    0.859085    0.845117  \n",
      "11    0.811441    0.841291    0.838766    0.853558    0.835233  \n",
      "12    0.647879    0.703352    0.693010    0.719813    0.697599  \n",
      "13    0.836800    0.862900    0.851000    0.852900    0.874300  \n",
      "14    0.811441    0.841291    0.838766    0.853558    0.835233  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_8 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_8.fit(X_trainSet8, Y_trainSet8,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_8 = optimized_rf_8.predict(X_testSet8)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet8, y_pred_rf_8)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet8, y_pred_rf_8)\n",
    "Precision = precision_score(Y_testSet8, y_pred_rf_8)\n",
    "Sensitivity = recall_score(Y_testSet8, y_pred_rf_8)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet8, y_pred_rf_8)      \n",
    "f1_scores_W = f1_score(Y_testSet8, y_pred_rf_8, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet8, y_pred_rf_8, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet8, y_pred_rf_8)\n",
    "MCC = matthews_corrcoef(Y_testSet8, y_pred_rf_8)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet8, y_pred_rf_8)\n",
    "data_testing['y_test_idx8'] = testindex8\n",
    "data_testing['y_test_Set8'] = Y_testSet8\n",
    "data_testing['y_pred_Set8'] = y_pred_rf_8\n",
    "\n",
    "Set8 = pd.DataFrame({'Set8':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "mat_met_rf_test['Set8'] =Set8   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "282487d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T12:40:12.101696Z",
     "iopub.status.busy": "2023-01-15T12:40:12.101523Z",
     "iopub.status.idle": "2023-01-15T13:48:12.994865Z",
     "shell.execute_reply": "2023-01-15T13:48:12.994346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:14:38,731]\u001b[0m Trial 450 finished with value: 0.8262040334880567 and parameters: {'n_estimators': 474}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:15:24,132]\u001b[0m Trial 451 finished with value: 0.8260707502867171 and parameters: {'n_estimators': 575}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:15:59,028]\u001b[0m Trial 452 finished with value: 0.8243950236048615 and parameters: {'n_estimators': 437}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:16:41,188]\u001b[0m Trial 453 finished with value: 0.8253174848875571 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:17:20,654]\u001b[0m Trial 454 finished with value: 0.8265982335965282 and parameters: {'n_estimators': 498}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:17:47,254]\u001b[0m Trial 455 finished with value: 0.8263967650847632 and parameters: {'n_estimators': 329}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:18:31,325]\u001b[0m Trial 456 finished with value: 0.8256032737674277 and parameters: {'n_estimators': 554}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:19:12,094]\u001b[0m Trial 457 finished with value: 0.8257275258541676 and parameters: {'n_estimators': 512}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:20:01,298]\u001b[0m Trial 458 finished with value: 0.8274666366581869 and parameters: {'n_estimators': 627}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:20:43,676]\u001b[0m Trial 459 finished with value: 0.8257815486630639 and parameters: {'n_estimators': 533}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:21:22,411]\u001b[0m Trial 460 finished with value: 0.8266115560076402 and parameters: {'n_estimators': 486}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:22:07,335]\u001b[0m Trial 461 finished with value: 0.8256640746140839 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:22:54,745]\u001b[0m Trial 462 finished with value: 0.8275956252388463 and parameters: {'n_estimators': 600}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:23:38,027]\u001b[0m Trial 463 finished with value: 0.8260733689743649 and parameters: {'n_estimators': 545}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:24:19,021]\u001b[0m Trial 464 finished with value: 0.8248517483616947 and parameters: {'n_estimators': 519}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:25:01,447]\u001b[0m Trial 465 finished with value: 0.8257271916241061 and parameters: {'n_estimators': 536}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:25:41,484]\u001b[0m Trial 466 finished with value: 0.8261341698210212 and parameters: {'n_estimators': 503}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:26:22,726]\u001b[0m Trial 467 finished with value: 0.8248517483616947 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:26:53,771]\u001b[0m Trial 468 finished with value: 0.8262142651573378 and parameters: {'n_estimators': 387}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:27:30,476]\u001b[0m Trial 469 finished with value: 0.8267210561587486 and parameters: {'n_estimators': 463}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:28:38,334]\u001b[0m Trial 470 finished with value: 0.8297473038267651 and parameters: {'n_estimators': 878}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:29:22,047]\u001b[0m Trial 471 finished with value: 0.8261281383895908 and parameters: {'n_estimators': 557}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:30:00,089]\u001b[0m Trial 472 finished with value: 0.8266115560076402 and parameters: {'n_estimators': 482}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:30:42,937]\u001b[0m Trial 473 finished with value: 0.8261915896296748 and parameters: {'n_estimators': 544}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:31:23,104]\u001b[0m Trial 474 finished with value: 0.8257275258541676 and parameters: {'n_estimators': 510}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:32:09,132]\u001b[0m Trial 475 finished with value: 0.8264196561766098 and parameters: {'n_estimators': 586}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:32:50,558]\u001b[0m Trial 476 finished with value: 0.8248512201887213 and parameters: {'n_estimators': 528}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:33:30,204]\u001b[0m Trial 477 finished with value: 0.8265982335965282 and parameters: {'n_estimators': 498}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:34:30,181]\u001b[0m Trial 478 finished with value: 0.82702904234573 and parameters: {'n_estimators': 765}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:35:14,528]\u001b[0m Trial 479 finished with value: 0.8261281383895908 and parameters: {'n_estimators': 562}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:35:57,095]\u001b[0m Trial 480 finished with value: 0.8253187783843401 and parameters: {'n_estimators': 540}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:36:38,316]\u001b[0m Trial 481 finished with value: 0.8248517483616947 and parameters: {'n_estimators': 521}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:37:23,455]\u001b[0m Trial 482 finished with value: 0.8260707502867171 and parameters: {'n_estimators': 573}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:38:02,499]\u001b[0m Trial 483 finished with value: 0.8256811931775416 and parameters: {'n_estimators': 493}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:38:30,853]\u001b[0m Trial 484 finished with value: 0.8257181890542122 and parameters: {'n_estimators': 358}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:39:14,651]\u001b[0m Trial 485 finished with value: 0.8256032737674277 and parameters: {'n_estimators': 549}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:39:55,042]\u001b[0m Trial 486 finished with value: 0.8261394650292024 and parameters: {'n_estimators': 513}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:40:37,305]\u001b[0m Trial 487 finished with value: 0.8253174848875571 and parameters: {'n_estimators': 530}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:41:15,007]\u001b[0m Trial 488 finished with value: 0.8267444148204296 and parameters: {'n_estimators': 472}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:41:32,581]\u001b[0m Trial 489 finished with value: 0.8273485098647496 and parameters: {'n_estimators': 212}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:42:12,337]\u001b[0m Trial 490 finished with value: 0.8262484194702635 and parameters: {'n_estimators': 507}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:42:46,802]\u001b[0m Trial 491 finished with value: 0.8244524117077354 and parameters: {'n_estimators': 426}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:43:29,539]\u001b[0m Trial 492 finished with value: 0.8256032737674277 and parameters: {'n_estimators': 547}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:44:11,703]\u001b[0m Trial 493 finished with value: 0.8253174848875571 and parameters: {'n_estimators': 529}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:44:56,342]\u001b[0m Trial 494 finished with value: 0.8256640746140839 and parameters: {'n_estimators': 566}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:45:36,312]\u001b[0m Trial 495 finished with value: 0.8261484847314648 and parameters: {'n_estimators': 495}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:46:17,023]\u001b[0m Trial 496 finished with value: 0.8252617893283054 and parameters: {'n_estimators': 517}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:47:00,589]\u001b[0m Trial 497 finished with value: 0.8260733689743649 and parameters: {'n_estimators': 546}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:47:46,268]\u001b[0m Trial 498 finished with value: 0.8272962274208565 and parameters: {'n_estimators': 582}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:48:24,963]\u001b[0m Trial 499 finished with value: 0.8266115560076402 and parameters: {'n_estimators': 485}. Best is trial 138 with value: 0.8426167587438685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_rf_1 = optuna.create_study(direction='maximize', study_name=\"RFclfressor_1\")\n",
    "func_rf_9 = lambda trial: objective_rf_CV(trial, X_trainSet9, Y_trainSet9, Y_trainSet9_class)\n",
    "study_rf.optimize(func_rf_9, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d6f415a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:48:12.996908Z",
     "iopub.status.busy": "2023-01-15T13:48:12.996544Z",
     "iopub.status.idle": "2023-01-15T13:48:21.639171Z",
     "shell.execute_reply": "2023-01-15T13:48:21.638848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
      "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
      "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
      "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
      "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
      "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
      "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
      "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
      "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
      "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
      "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
      "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
      "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
      "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
      "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8        Set9  \n",
      "0   339.000000  343.000000  332.000000  344.000000  344.000000  349.000000  \n",
      "1   159.000000  170.000000  177.000000  174.000000  167.000000  160.000000  \n",
      "2    66.000000   55.000000   55.000000   47.000000   60.000000   49.000000  \n",
      "3    31.000000   27.000000   31.000000   30.000000   24.000000   37.000000  \n",
      "4     0.836975    0.862185    0.855462    0.870588    0.858824    0.855462  \n",
      "5     0.837037    0.861809    0.857881    0.879795    0.851485    0.876884  \n",
      "6     0.916216    0.927027    0.914601    0.919786    0.934783    0.904145  \n",
      "7     0.706700    0.755600    0.762900    0.787300    0.735700    0.765600  \n",
      "8     0.874839    0.893229    0.885333    0.899346    0.891192    0.890306  \n",
      "9     0.833781    0.860125    0.853833    0.869438    0.856036    0.854432  \n",
      "10    0.820552    0.849458    0.844939    0.859085    0.845117    0.839242  \n",
      "11    0.811441    0.841291    0.838766    0.853558    0.835233    0.834848  \n",
      "12    0.647879    0.703352    0.693010    0.719813    0.697599    0.679312  \n",
      "13    0.836800    0.862900    0.851000    0.852900    0.874300    0.812200  \n",
      "14    0.811441    0.841291    0.838766    0.853558    0.835233    0.834848  \n"
     ]
    }
   ],
   "source": [
    "optimized_rf_9 = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "\n",
    "\n",
    "#learn\n",
    "        \n",
    "optimized_rf_9.fit(X_trainSet9, Y_trainSet9,)\n",
    "\n",
    "#predict        \n",
    "y_pred_rf_9 = optimized_rf_9.predict(X_testSet9)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet9, y_pred_rf_9)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet9, y_pred_rf_9)\n",
    "Precision = precision_score(Y_testSet9, y_pred_rf_9)\n",
    "Sensitivity = recall_score(Y_testSet9, y_pred_rf_9)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet9, y_pred_rf_9)      \n",
    "f1_scores_W = f1_score(Y_testSet9, y_pred_rf_9, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet9, y_pred_rf_9, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet9, y_pred_rf_9)\n",
    "MCC = matthews_corrcoef(Y_testSet9, y_pred_rf_9)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet9, y_pred_rf_9)\n",
    "data_testing['y_test_idx9'] = testindex9\n",
    "data_testing['y_test_Set9'] = Y_testSet9\n",
    "data_testing['y_pred_Set9'] = y_pred_rf_9\n",
    "\n",
    "Set9 = pd.DataFrame({'Set9':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })  \n",
    "\n",
    "mat_met_rf_test['Set9'] =Set9   \n",
    "print(mat_met_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56f46996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:48:21.640573Z",
     "iopub.status.busy": "2023-01-15T13:48:21.640457Z",
     "iopub.status.idle": "2023-01-15T13:48:21.653545Z",
     "shell.execute_reply": "2023-01-15T13:48:21.653274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.8426\n",
      "\tBest params:\n",
      "\t\tn_estimators: 521\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tNumber of trials: {len(study_rf.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_rf.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11f01be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:48:21.654699Z",
     "iopub.status.busy": "2023-01-15T13:48:21.654593Z",
     "iopub.status.idle": "2023-01-15T13:48:21.791878Z",
     "shell.execute_reply": "2023-01-15T13:48:21.791380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study_rf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdae427e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:48:21.793712Z",
     "iopub.status.busy": "2023-01-15T13:48:21.793550Z",
     "iopub.status.idle": "2023-01-15T13:50:02.240490Z",
     "shell.execute_reply": "2023-01-15T13:50:02.240136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value (average)</th>\n",
       "      <th>Value (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>165.900000</td>\n",
       "      <td>8.171087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>6.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>3.107339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>3.794733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.852244</td>\n",
       "      <td>0.014942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.863984</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>0.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.027348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.882861</td>\n",
       "      <td>0.013962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.851033</td>\n",
       "      <td>0.014893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.840817</td>\n",
       "      <td>0.014898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.836204</td>\n",
       "      <td>0.014658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>0.030021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.831380</td>\n",
       "      <td>0.028915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.836204</td>\n",
       "      <td>0.014658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value (average)  Value (std)\n",
       "0                    TP       165.900000     8.171087\n",
       "1                    TN        87.300000     6.667500\n",
       "2                    FP        26.100000     3.107339\n",
       "3                    FN        17.800000     3.794733\n",
       "4              Accuracy         0.852244     0.014942\n",
       "5             Precision         0.863984     0.015618\n",
       "6           Sensitivity         0.902899     0.021359\n",
       "7           Specificity         0.769500     0.027348\n",
       "8              F1 score         0.882861     0.013962\n",
       "9   F1 score (weighted)         0.851033     0.014893\n",
       "10     F1 score (macro)         0.840817     0.014898\n",
       "11    Balanced Accuracy         0.836204     0.014658\n",
       "12                  MCC         0.683740     0.030021\n",
       "13                  NPV         0.831380     0.028915\n",
       "14              ROC_AUC         0.836204     0.014658"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objective_rf_CV(study_rf.best_trial, X, Y, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c0d030a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:50:02.242017Z",
     "iopub.status.busy": "2023-01-15T13:50:02.241883Z",
     "iopub.status.idle": "2023-01-15T13:50:02.255169Z",
     "shell.execute_reply": "2023-01-15T13:50:02.254826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Set0</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Set3</th>\n",
       "      <th>Set4</th>\n",
       "      <th>Set5</th>\n",
       "      <th>Set6</th>\n",
       "      <th>Set7</th>\n",
       "      <th>Set8</th>\n",
       "      <th>Set9</th>\n",
       "      <th>ave</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>339.100000</td>\n",
       "      <td>6.505553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>6.565905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>6.629899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>5.982382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.860504</td>\n",
       "      <td>0.850420</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.843697</td>\n",
       "      <td>0.836975</td>\n",
       "      <td>0.862185</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.852269</td>\n",
       "      <td>0.012638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.849351</td>\n",
       "      <td>0.850374</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.861809</td>\n",
       "      <td>0.857881</td>\n",
       "      <td>0.879795</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.857962</td>\n",
       "      <td>0.015180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.930748</td>\n",
       "      <td>0.881402</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.914601</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.904145</td>\n",
       "      <td>0.914613</td>\n",
       "      <td>0.015461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.785700</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>0.706700</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>0.762900</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>0.735700</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.749560</td>\n",
       "      <td>0.026411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.890066</td>\n",
       "      <td>0.883049</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.874839</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>0.885333</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.890306</td>\n",
       "      <td>0.885244</td>\n",
       "      <td>0.009967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.859621</td>\n",
       "      <td>0.847454</td>\n",
       "      <td>0.827394</td>\n",
       "      <td>0.841336</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.860125</td>\n",
       "      <td>0.853833</td>\n",
       "      <td>0.869438</td>\n",
       "      <td>0.856036</td>\n",
       "      <td>0.854432</td>\n",
       "      <td>0.850345</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.849631</td>\n",
       "      <td>0.837795</td>\n",
       "      <td>0.815028</td>\n",
       "      <td>0.827952</td>\n",
       "      <td>0.820552</td>\n",
       "      <td>0.849458</td>\n",
       "      <td>0.844939</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>0.845117</td>\n",
       "      <td>0.839242</td>\n",
       "      <td>0.838880</td>\n",
       "      <td>0.013892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.845687</td>\n",
       "      <td>0.828622</td>\n",
       "      <td>0.811237</td>\n",
       "      <td>0.820136</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.853558</td>\n",
       "      <td>0.835233</td>\n",
       "      <td>0.834848</td>\n",
       "      <td>0.832082</td>\n",
       "      <td>0.014176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.700193</td>\n",
       "      <td>0.683976</td>\n",
       "      <td>0.631090</td>\n",
       "      <td>0.659968</td>\n",
       "      <td>0.647879</td>\n",
       "      <td>0.703352</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.719813</td>\n",
       "      <td>0.697599</td>\n",
       "      <td>0.679312</td>\n",
       "      <td>0.681619</td>\n",
       "      <td>0.027553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.834100</td>\n",
       "      <td>0.871800</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.829900</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.862900</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.852900</td>\n",
       "      <td>0.874300</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.841640</td>\n",
       "      <td>0.026547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.845687</td>\n",
       "      <td>0.828622</td>\n",
       "      <td>0.811237</td>\n",
       "      <td>0.820136</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.853558</td>\n",
       "      <td>0.835233</td>\n",
       "      <td>0.834848</td>\n",
       "      <td>0.832082</td>\n",
       "      <td>0.014176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric        Set0        Set1        Set2        Set3  \\\n",
       "0                    TP  336.000000  336.000000  327.000000  341.000000   \n",
       "1                    TN  176.000000  170.000000  166.000000  161.000000   \n",
       "2                    FP   48.000000   64.000000   58.000000   60.000000   \n",
       "3                    FN   35.000000   25.000000   44.000000   33.000000   \n",
       "4              Accuracy    0.860504    0.850420    0.828571    0.843697   \n",
       "5             Precision    0.875000    0.840000    0.849351    0.850374   \n",
       "6           Sensitivity    0.905660    0.930748    0.881402    0.911765   \n",
       "7           Specificity    0.785700    0.726500    0.741100    0.728500   \n",
       "8              F1 score    0.890066    0.883049    0.865079    0.880000   \n",
       "9   F1 score (weighted)    0.859621    0.847454    0.827394    0.841336   \n",
       "10     F1 score (macro)    0.849631    0.837795    0.815028    0.827952   \n",
       "11    Balanced Accuracy    0.845687    0.828622    0.811237    0.820136   \n",
       "12                  MCC    0.700193    0.683976    0.631090    0.659968   \n",
       "13                  NPV    0.834100    0.871800    0.790500    0.829900   \n",
       "14              ROC_AUC    0.845687    0.828622    0.811237    0.820136   \n",
       "\n",
       "          Set4        Set5        Set6        Set7        Set8        Set9  \\\n",
       "0   339.000000  343.000000  332.000000  344.000000  344.000000  349.000000   \n",
       "1   159.000000  170.000000  177.000000  174.000000  167.000000  160.000000   \n",
       "2    66.000000   55.000000   55.000000   47.000000   60.000000   49.000000   \n",
       "3    31.000000   27.000000   31.000000   30.000000   24.000000   37.000000   \n",
       "4     0.836975    0.862185    0.855462    0.870588    0.858824    0.855462   \n",
       "5     0.837037    0.861809    0.857881    0.879795    0.851485    0.876884   \n",
       "6     0.916216    0.927027    0.914601    0.919786    0.934783    0.904145   \n",
       "7     0.706700    0.755600    0.762900    0.787300    0.735700    0.765600   \n",
       "8     0.874839    0.893229    0.885333    0.899346    0.891192    0.890306   \n",
       "9     0.833781    0.860125    0.853833    0.869438    0.856036    0.854432   \n",
       "10    0.820552    0.849458    0.844939    0.859085    0.845117    0.839242   \n",
       "11    0.811441    0.841291    0.838766    0.853558    0.835233    0.834848   \n",
       "12    0.647879    0.703352    0.693010    0.719813    0.697599    0.679312   \n",
       "13    0.836800    0.862900    0.851000    0.852900    0.874300    0.812200   \n",
       "14    0.811441    0.841291    0.838766    0.853558    0.835233    0.834848   \n",
       "\n",
       "           ave       std  \n",
       "0   339.100000  6.505553  \n",
       "1   168.000000  6.565905  \n",
       "2    56.200000  6.629899  \n",
       "3    31.700000  5.982382  \n",
       "4     0.852269  0.012638  \n",
       "5     0.857962  0.015180  \n",
       "6     0.914613  0.015461  \n",
       "7     0.749560  0.026411  \n",
       "8     0.885244  0.009967  \n",
       "9     0.850345  0.012902  \n",
       "10    0.838880  0.013892  \n",
       "11    0.832082  0.014176  \n",
       "12    0.681619  0.027553  \n",
       "13    0.841640  0.026547  \n",
       "14    0.832082  0.014176  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_met_rf_test['ave'] = mat_met_rf_test.iloc[:,1:11].mean(axis='columns', numeric_only=True)\n",
    "mat_met_rf_test['std'] = mat_met_rf_test.iloc[:,1:11].std(axis='columns', numeric_only=True)\n",
    "mat_met_rf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36fe8bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:50:02.256530Z",
     "iopub.status.busy": "2023-01-15T13:50:02.256400Z",
     "iopub.status.idle": "2023-01-15T13:58:24.268436Z",
     "shell.execute_reply": "2023-01-15T13:58:24.268003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test_idx0</th>\n",
       "      <th>y_test0</th>\n",
       "      <th>y_pred_rf0</th>\n",
       "      <th>y_pred_rf1</th>\n",
       "      <th>y_pred_rf2</th>\n",
       "      <th>y_pred_rf3</th>\n",
       "      <th>y_pred_rf4</th>\n",
       "      <th>y_pred_rf_ave</th>\n",
       "      <th>y_pred_rf_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test_idx0  y_test0  y_pred_rf0  y_pred_rf1  y_pred_rf2  y_pred_rf3  \\\n",
       "0               0      1.0         1.0         1.0         1.0         1.0   \n",
       "1               1      1.0         1.0         1.0         1.0         1.0   \n",
       "2               2      0.0         0.0         0.0         0.0         0.0   \n",
       "3               3      0.0         1.0         1.0         1.0         1.0   \n",
       "4               4      0.0         1.0         1.0         1.0         1.0   \n",
       "...           ...      ...         ...         ...         ...         ...   \n",
       "2966         2966      1.0         1.0         1.0         1.0         1.0   \n",
       "2967         2967      1.0         1.0         1.0         1.0         1.0   \n",
       "2968         2968      0.0         1.0         1.0         1.0         1.0   \n",
       "2969         2969      1.0         0.0         0.0         0.0         0.0   \n",
       "2970         2970      1.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "      y_pred_rf4  y_pred_rf_ave  y_pred_rf_std  \n",
       "0            1.0            1.0            0.0  \n",
       "1            1.0            1.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            1.0            1.0            0.0  \n",
       "4            1.0            1.0            0.0  \n",
       "...          ...            ...            ...  \n",
       "2966         1.0            1.0            0.0  \n",
       "2967         1.0            1.0            0.0  \n",
       "2968         1.0            1.0            0.0  \n",
       "2969         0.0            0.0            0.0  \n",
       "2970         0.0            0.0            0.0  \n",
       "\n",
       "[2971 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to fit into these X values \n",
    "\n",
    "TP =np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "\n",
    "\n",
    "\n",
    "Accuracy_outer = []\n",
    "Precision_outer = [] #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity_outer = [] # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity_outer = [] #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores_outer = []\n",
    "f1_scores_W_outer = []\n",
    "f1_scores_M_outer = []\n",
    "BA_scores_outer = []\n",
    "MCC_outer = []\n",
    "NPV_outer = []\n",
    "ROC_AUC_outer = []\n",
    "data_rf=pd.DataFrame()\n",
    "\n",
    "NUM_TRIALS = 5\n",
    "random_state= [687266, 98656, 56, 280189, 76543] # \n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    cv_change = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state[i])\n",
    "    data_inner = pd.DataFrame({'y_test_idx': pd.Series(dtype='int'),\n",
    "                   'y_test': pd.Series(dtype='float'),\n",
    "                   'y_pred': pd.Series(dtype='float')})\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv_change.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        optimizedCV_rf = RandomForestClassifier(n_estimators = study_rf.best_params['n_estimators'],\n",
    "                                            n_jobs=16, \n",
    "                                            random_state=5, \n",
    "                                            max_features = None,\n",
    "                                            oob_score=True,\n",
    "                                            max_samples=0.8,\n",
    "                                          )\n",
    "        optimizedCV_rf.fit(X_train,\n",
    "                          y_train, \n",
    "                          \n",
    "                  )\n",
    "        #print(test_idx)\n",
    "        y_pred_optimized_rf = optimizedCV_rf.predict(X_test) \n",
    "        data_inner = data_inner.append(pd.DataFrame({'y_test_idx': test_idx, 'y_test': y_test, 'y_pred_rf': y_pred_optimized_rf } ), )\n",
    "        data_inner.reset_index(inplace=True, drop=True) \n",
    "        data_inner.sort_values(by='y_test_idx', inplace=True) \n",
    "        \n",
    "   \n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimized_rf)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        \n",
    "    \n",
    "        Accuracy_outer.append(accuracy_score(y_test, y_pred_optimized_rf))\n",
    "        Precision_outer.append(precision_score(y_test, y_pred_optimized_rf))\n",
    "        Sensitivity_outer.append(recall_score(y_test, y_pred_optimized_rf))\n",
    "        Specificity_outer.append(round( TN[idx] / (TN[idx]+FP[idx]),4 ))\n",
    "        f1_scores_outer.append(f1_score(y_test, y_pred_optimized_rf))\n",
    "        f1_scores_W_outer.append(f1_score(y_test, y_pred_optimized_rf, average=\"weighted\"))\n",
    "        f1_scores_M_outer.append(f1_score(y_test, y_pred_optimized_rf, average=\"macro\"))\n",
    "        BA_scores_outer.append(balanced_accuracy_score(y_test, y_pred_optimized_rf))\n",
    "        MCC_outer.append(matthews_corrcoef(y_test, y_pred_optimized_rf))\n",
    "        NPV_outer.append(round( TN[idx] / (TN[idx]+FN[idx]),4 ))\n",
    "        ROC_AUC_outer.append(roc_auc_score(y_test, y_pred_optimized_rf))\n",
    "    data_rf['y_test_idx' + str(i)] = data_inner['y_test_idx']\n",
    "    data_rf['y_test' + str(i)] = data_inner['y_test']\n",
    "    data_rf['y_pred_rf' + str(i)] = data_inner['y_pred_rf']\n",
    "   # data_rf['correct' + str(i)] = correct_value\n",
    "   # data_rf['pred' + str(i)] = y_pred_optimized_rf\n",
    "\n",
    "mat_met_optimized_rf = pd.DataFrame({'Metric':['Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(Accuracy_outer),np.mean(Precision_outer),\n",
    "                                           np.mean(Sensitivity_outer),np.mean(Specificity_outer),np.mean(f1_scores_outer),\n",
    "                                           np.mean(f1_scores_W_outer), np.mean(f1_scores_M_outer), np.mean(BA_scores_outer), \n",
    "                                           np.mean(MCC_outer),np.mean(NPV_outer),np.mean(ROC_AUC_outer)],\n",
    "                        'Value (std)': [ np.std(Accuracy_outer, ddof=1),np.std(Precision_outer, ddof=1),\n",
    "                                        np.std(Sensitivity_outer,ddof=1),np.std(Specificity_outer,ddof=1),np.std(f1_scores_outer, ddof=1),\n",
    "                                        np.std(f1_scores_W_outer, ddof=1),np.std(f1_scores_M_outer, ddof=1), np.std(BA_scores_outer, ddof=1), \n",
    "                                        np.std(MCC_outer, ddof=1),np.std(NPV_outer, ddof=1),np.std(ROC_AUC_outer, ddof=1)]\n",
    "                       }) \n",
    "\n",
    "\n",
    "rf_run0 = data_rf[['y_test_idx0', 'y_test0', 'y_pred_rf0']]\n",
    "rf_run0.sort_values(by='y_test_idx0', inplace=True)\n",
    "rf_run0.reset_index(inplace=True, drop=True)\n",
    "rf_run1 = data_rf[['y_test_idx1', 'y_test1', 'y_pred_rf1']]\n",
    "rf_run1.sort_values(by='y_test_idx1', inplace=True)\n",
    "rf_run1.reset_index(inplace=True, drop=True)\n",
    "rf_run2 = data_rf[['y_test_idx2', 'y_test2', 'y_pred_rf2']]\n",
    "rf_run2.sort_values(by='y_test_idx2', inplace=True)\n",
    "rf_run2.reset_index(inplace=True, drop=True)\n",
    "rf_run3 = data_rf[['y_test_idx3', 'y_test3', 'y_pred_rf3']]\n",
    "rf_run3.sort_values(by='y_test_idx3', inplace=True)\n",
    "rf_run3.reset_index(inplace=True, drop=True)\n",
    "rf_run4 = data_rf[['y_test_idx4', 'y_test4', 'y_pred_rf4']]\n",
    "rf_run4.sort_values(by='y_test_idx4', inplace=True)\n",
    "rf_run4.reset_index(inplace=True, drop=True)\n",
    "rf_5preds = pd.concat([rf_run0, rf_run1, rf_run2, rf_run3, rf_run4], axis=1)\n",
    "rf_5preds = rf_5preds[['y_test_idx0', 'y_test0', 'y_pred_rf0', 'y_pred_rf1', 'y_pred_rf2', 'y_pred_rf3', 'y_pred_rf4']]\n",
    "rf_5preds['y_pred_rf_ave'] = rf_5preds.iloc[:,2:11].mean(axis='columns', numeric_only=True)\n",
    "rf_5preds['y_pred_rf_std'] = rf_5preds.iloc[:,2:].std(axis='columns', numeric_only=True)\n",
    "# maybe also calculate the std for each value\n",
    "rf_5preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d030d28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:58:24.270147Z",
     "iopub.status.busy": "2023-01-15T13:58:24.270022Z",
     "iopub.status.idle": "2023-01-15T13:58:24.285529Z",
     "shell.execute_reply": "2023-01-15T13:58:24.285134Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_5preds.to_csv('rf_5test_CV_result.csv')\n",
    "mat_met_optimized_rf.to_csv('mat_met_rf_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5e07fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T13:58:24.287264Z",
     "iopub.status.busy": "2023-01-15T13:58:24.287118Z",
     "iopub.status.idle": "2023-01-15T14:00:23.554441Z",
     "shell.execute_reply": "2023-01-15T14:00:23.554020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF baseline model f1_score 0.8454 with a standard deviation of 0.0282\n",
      "RF optimized model f1_score 0.8444 with a standard deviation of 0.0240\n"
     ]
    }
   ],
   "source": [
    "#cross valide using this optimized RF \n",
    "rf_baseline_CVscore = cross_val_score(rf_clf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "#rf_opt_testSet_score = cross_val_score(optimized_rf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "rf_opt_CVscore = cross_val_score(optimizedCV_rf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "print(\"RF baseline model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(rf_baseline_CVscore), np.std(rf_baseline_CVscore, ddof=1)))\n",
    "#print(\"RF optimized model (tested on Y_te) f1_score %0.4f with a standard deviation of %0.4f\" % (rf_opt_testSet_score.mean(), rf_opt_testSet_score.std()))\n",
    "print(\"RF optimized model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(rf_opt_CVscore), np.std(rf_opt_CVscore, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebe6aad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:00:23.556179Z",
     "iopub.status.busy": "2023-01-15T14:00:23.556033Z",
     "iopub.status.idle": "2023-01-15T14:00:23.717067Z",
     "shell.execute_reply": "2023-01-15T14:00:23.716699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optimizedCV_rf_clf.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_clf, \"./rf_clf.joblib\")\n",
    "#joblib.dump(optimized_rf, \"./optimized_rf.joblib\") # fitted to whole training set with last random_state selected\n",
    "joblib.dump(optimizedCV_rf, \"./optimizedCV_rf_clf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21965b",
   "metadata": {},
   "source": [
    "## LGBMclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3717154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:00:23.718864Z",
     "iopub.status.busy": "2023-01-15T14:00:23.718722Z",
     "iopub.status.idle": "2023-01-15T14:00:26.420912Z",
     "shell.execute_reply": "2023-01-15T14:00:26.420523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       163.700000     8.564137\n",
      "1                    TN        87.200000     6.142746\n",
      "2                    FP        26.200000     3.326660\n",
      "3                    FN        20.000000     4.109609\n",
      "4              Accuracy         0.844500     0.020837\n",
      "5             Precision         0.861749     0.018749\n",
      "6           Sensitivity         0.890857     0.023506\n",
      "7           Specificity         0.768930     0.026838\n",
      "8              F1 score         0.875964     0.018886\n",
      "9   F1 score (weighted)         0.843598     0.020791\n",
      "10     F1 score (macro)         0.833259     0.020788\n",
      "11    Balanced Accuracy         0.829891     0.020223\n",
      "12                  MCC         0.667688     0.041543\n",
      "13                  NPV         0.813970     0.031333\n",
      "14              ROC_AUC         0.829891     0.020223\n",
      "CPU times: user 33.2 s, sys: 95.9 ms, total: 33.3 s\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TP=np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP= np.empty(10)\n",
    "FN= np.empty(10)\n",
    "Accuracy = np.empty(10)\n",
    "Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores = np.empty(10)\n",
    "f1_scores_W=np.empty(10)\n",
    "f1_scores_M = np.empty(10)\n",
    "BA_scores = np.empty(10)\n",
    "MCC = np.empty(10)\n",
    "NPV = np.empty(10)\n",
    "ROC_AUC= np.empty(10)\n",
    "\n",
    "\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "        \n",
    "        lgbm_clf = lgbm.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        random_state=1121218,\n",
    "        #n_estimators=150,\n",
    "        boosting_type =\"gbdt\",  # default histogram binning of LGBM,\n",
    "        n_jobs=16,\n",
    "        #min_child_samples = 15,\n",
    "        subsample=0.8, # also called bagging_fraction\n",
    "        subsample_freq=10,\n",
    "     \n",
    "           )\n",
    "\n",
    "\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        lgbm_clf.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric=\"logloss\",\n",
    "                    #early_stopping_rounds=150,\n",
    "                    verbose=False,\n",
    "                    )\n",
    "\n",
    "        y_pred = lgbm_clf.predict(X_test) \n",
    "        \n",
    "        #calculate the evaluation results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "mat_met_lgbm = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })  \n",
    "print(mat_met_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfeeaa88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:00:26.422585Z",
     "iopub.status.busy": "2023-01-15T14:00:26.422446Z",
     "iopub.status.idle": "2023-01-15T14:00:26.427695Z",
     "shell.execute_reply": "2023-01-15T14:00:26.427379Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna  \n",
    "\n",
    "def objective_lgbm_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 900),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        #\"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 150, 300),\n",
    "        #\"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        #\"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0, 0.001),\n",
    "        #\"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1.0,100),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 750),\n",
    "        #\"min_child_samples\": trial.suggest_int(\"min_child_samples\", 15, 100),\n",
    "        #\"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        #\"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6,1),\n",
    "        #\"bagging_freq\": trial.suggestegorical(\"bagging_freq\", [1]),\n",
    "        }\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv_scores=np.empty(10)\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        lgbm_model = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                            random_state=1121218, \n",
    "                                            boosting_type =\"gbdt\", \n",
    "                                            **param_grid, n_jobs=16,\n",
    "                                            subsample=0.8, # also called bagging_fraction\n",
    "                                            subsample_freq=10,\n",
    "                                         )\n",
    "    \n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        lgbm_model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        y_pred = lgbm_model.predict(X_test)\n",
    "        cv_scores[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "       \n",
    "        \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0709063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:00:26.429288Z",
     "iopub.status.busy": "2023-01-15T14:00:26.429167Z",
     "iopub.status.idle": "2023-01-15T14:00:26.440452Z",
     "shell.execute_reply": "2023-01-15T14:00:26.440138Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is basically inner set parameters\n",
    "def detailed_objective_lgbm_cv(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 900),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        #\"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 150, 300),\n",
    "        #\"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        #\"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0, 0.001),\n",
    "        #\"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1.0,100),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 750),\n",
    "        #\"min_child_samples\": trial.suggest_int(\"min_child_samples\", 15, 100),\n",
    "        #\"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        #\"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6,1),\n",
    "        #\"bagging_freq\": trial.suggestegorical(\"bagging_freq\", [1]),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "  \n",
    "    TP=np.empty(10)\n",
    "    TN = np.empty(10)\n",
    "    FP= np.empty(10)\n",
    "    FN= np.empty(10)\n",
    "    Accuracy = np.empty(10)\n",
    "    Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "    Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "    Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "    f1_scores = np.empty(10)\n",
    "    f1_scores_W = np.empty(10)\n",
    "    f1_scores_M =np.empty(10)\n",
    "    BA_scores = np.empty(10)\n",
    "    MCC = np.empty(10)\n",
    "    NPV = np.empty(10)\n",
    "    ROC_AUC= np.empty(10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        lgbm_model = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                            random_state=1121218, \n",
    "                                            boosting_type =\"gbdt\", \n",
    "                                            **param_grid, n_jobs=16,\n",
    "                                            subsample=0.8, # also called bagging_fraction\n",
    "                                            subsample_freq=10,\n",
    "                                         )\n",
    "    \n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        lgbm_model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "        y_pred = lgbm_model.predict(X_test)\n",
    "        \n",
    "        #calculate the evaluation results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })  \n",
    "    print(mat_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1d2b480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:00:26.441934Z",
     "iopub.status.busy": "2023-01-15T14:00:26.441801Z",
     "iopub.status.idle": "2023-01-15T14:04:04.106805Z",
     "shell.execute_reply": "2023-01-15T14:04:04.106462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:55:00,611]\u001b[0m A new study created in memory with name: LGBMClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:01,838]\u001b[0m Trial 0 finished with value: 0.8128469329089295 and parameters: {'n_estimators': 464, 'learning_rate': 0.18399659282122405, 'max_depth': 5, 'max_bin': 269, 'num_leaves': 409}. Best is trial 0 with value: 0.8128469329089295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:04,309]\u001b[0m Trial 1 finished with value: 0.8160608278594896 and parameters: {'n_estimators': 811, 'learning_rate': 0.05814872884196103, 'max_depth': 9, 'max_bin': 193, 'num_leaves': 304}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:06,073]\u001b[0m Trial 2 finished with value: 0.8154424250807011 and parameters: {'n_estimators': 636, 'learning_rate': 0.0788071718003575, 'max_depth': 7, 'max_bin': 213, 'num_leaves': 594}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:08,137]\u001b[0m Trial 3 finished with value: 0.8157212895665273 and parameters: {'n_estimators': 749, 'learning_rate': 0.08656724180836663, 'max_depth': 10, 'max_bin': 229, 'num_leaves': 212}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:13,938]\u001b[0m Trial 4 finished with value: 0.8053148167695152 and parameters: {'n_estimators': 517, 'learning_rate': 0.007573190153367867, 'max_depth': 7, 'max_bin': 244, 'num_leaves': 529}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:16,028]\u001b[0m Trial 5 finished with value: 0.8159061382776406 and parameters: {'n_estimators': 510, 'learning_rate': 0.052903607763381, 'max_depth': 7, 'max_bin': 266, 'num_leaves': 587}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:17,059]\u001b[0m Trial 6 finished with value: 0.8050097015302926 and parameters: {'n_estimators': 103, 'learning_rate': 0.1746463742052527, 'max_depth': 6, 'max_bin': 258, 'num_leaves': 479}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:19,695]\u001b[0m Trial 7 finished with value: 0.8120827801795603 and parameters: {'n_estimators': 156, 'learning_rate': 0.04153186518769612, 'max_depth': 11, 'max_bin': 187, 'num_leaves': 411}. Best is trial 1 with value: 0.8160608278594896.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:20,985]\u001b[0m Trial 8 finished with value: 0.8180492309840179 and parameters: {'n_estimators': 533, 'learning_rate': 0.16760429794943665, 'max_depth': 7, 'max_bin': 220, 'num_leaves': 613}. Best is trial 8 with value: 0.8180492309840179.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:22,277]\u001b[0m Trial 9 finished with value: 0.8150060719077098 and parameters: {'n_estimators': 620, 'learning_rate': 0.18971260090858022, 'max_depth': 10, 'max_bin': 154, 'num_leaves': 92}. Best is trial 8 with value: 0.8180492309840179.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:23,311]\u001b[0m Trial 10 finished with value: 0.8090167789388379 and parameters: {'n_estimators': 304, 'learning_rate': 0.13627176342909653, 'max_depth': 3, 'max_bin': 165, 'num_leaves': 672}. Best is trial 8 with value: 0.8180492309840179.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:24,973]\u001b[0m Trial 11 finished with value: 0.8157992318591374 and parameters: {'n_estimators': 883, 'learning_rate': 0.13157923910369845, 'max_depth': 9, 'max_bin': 198, 'num_leaves': 262}. Best is trial 8 with value: 0.8180492309840179.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:26,910]\u001b[0m Trial 12 finished with value: 0.8244326703685532 and parameters: {'n_estimators': 868, 'learning_rate': 0.12489976021612062, 'max_depth': 12, 'max_bin': 296, 'num_leaves': 247}. Best is trial 12 with value: 0.8244326703685532.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:28,983]\u001b[0m Trial 13 finished with value: 0.8244776377402715 and parameters: {'n_estimators': 361, 'learning_rate': 0.13601378315170842, 'max_depth': 12, 'max_bin': 280, 'num_leaves': 745}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:31,227]\u001b[0m Trial 14 finished with value: 0.8099812428106323 and parameters: {'n_estimators': 317, 'learning_rate': 0.12034655380187421, 'max_depth': 12, 'max_bin': 291, 'num_leaves': 748}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:32,864]\u001b[0m Trial 15 finished with value: 0.8121464983151201 and parameters: {'n_estimators': 344, 'learning_rate': 0.1502713716485567, 'max_depth': 12, 'max_bin': 293, 'num_leaves': 70}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:35,022]\u001b[0m Trial 16 finished with value: 0.8185495659354224 and parameters: {'n_estimators': 200, 'learning_rate': 0.0959272933636359, 'max_depth': 12, 'max_bin': 297, 'num_leaves': 224}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:36,804]\u001b[0m Trial 17 finished with value: 0.8178241458685808 and parameters: {'n_estimators': 395, 'learning_rate': 0.1136120912648608, 'max_depth': 10, 'max_bin': 275, 'num_leaves': 151}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:38,656]\u001b[0m Trial 18 finished with value: 0.8184735560102411 and parameters: {'n_estimators': 663, 'learning_rate': 0.14382873323504766, 'max_depth': 11, 'max_bin': 243, 'num_leaves': 364}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:40,207]\u001b[0m Trial 19 finished with value: 0.8135981027451334 and parameters: {'n_estimators': 244, 'learning_rate': 0.16177096729361407, 'max_depth': 9, 'max_bin': 280, 'num_leaves': 331}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:42,381]\u001b[0m Trial 20 finished with value: 0.8143014671614084 and parameters: {'n_estimators': 415, 'learning_rate': 0.11390942169256993, 'max_depth': 11, 'max_bin': 252, 'num_leaves': 716}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:44,649]\u001b[0m Trial 21 finished with value: 0.8179351400522583 and parameters: {'n_estimators': 229, 'learning_rate': 0.09705352773755536, 'max_depth': 12, 'max_bin': 299, 'num_leaves': 193}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:47,320]\u001b[0m Trial 22 finished with value: 0.8194814000417011 and parameters: {'n_estimators': 167, 'learning_rate': 0.07079037736569749, 'max_depth': 12, 'max_bin': 283, 'num_leaves': 250}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:49,294]\u001b[0m Trial 23 finished with value: 0.8142386226608773 and parameters: {'n_estimators': 90, 'learning_rate': 0.07200258440953518, 'max_depth': 11, 'max_bin': 281, 'num_leaves': 305}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:51,906]\u001b[0m Trial 24 finished with value: 0.8097431790010307 and parameters: {'n_estimators': 158, 'learning_rate': 0.03413967691399567, 'max_depth': 12, 'max_bin': 284, 'num_leaves': 129}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:53,137]\u001b[0m Trial 25 finished with value: 0.8028352612927016 and parameters: {'n_estimators': 54, 'learning_rate': 0.11947688437123004, 'max_depth': 10, 'max_bin': 263, 'num_leaves': 436}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:56,331]\u001b[0m Trial 26 finished with value: 0.7982529139318767 and parameters: {'n_estimators': 899, 'learning_rate': 0.015922421437110798, 'max_depth': 3, 'max_bin': 236, 'num_leaves': 265}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:57,619]\u001b[0m Trial 27 finished with value: 0.8187980219821428 and parameters: {'n_estimators': 755, 'learning_rate': 0.199811659899965, 'max_depth': 11, 'max_bin': 273, 'num_leaves': 40}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:55:59,577]\u001b[0m Trial 28 finished with value: 0.8165616185620438 and parameters: {'n_estimators': 275, 'learning_rate': 0.06704500111477428, 'max_depth': 9, 'max_bin': 287, 'num_leaves': 159}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:00,749]\u001b[0m Trial 29 finished with value: 0.8104360839816165 and parameters: {'n_estimators': 420, 'learning_rate': 0.15791982958356643, 'max_depth': 5, 'max_bin': 251, 'num_leaves': 368}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:02,581]\u001b[0m Trial 30 finished with value: 0.8154320466049676 and parameters: {'n_estimators': 361, 'learning_rate': 0.08648584274864769, 'max_depth': 8, 'max_bin': 270, 'num_leaves': 474}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:56:03,947]\u001b[0m Trial 31 finished with value: 0.8133020129968784 and parameters: {'n_estimators': 758, 'learning_rate': 0.19428987556433186, 'max_depth': 11, 'max_bin': 273, 'num_leaves': 37}. Best is trial 13 with value: 0.8244776377402715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:05,432]\u001b[0m Trial 32 finished with value: 0.8248888660514749 and parameters: {'n_estimators': 827, 'learning_rate': 0.1784117612902918, 'max_depth': 12, 'max_bin': 300, 'num_leaves': 253}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:06,915]\u001b[0m Trial 33 finished with value: 0.8175827058951489 and parameters: {'n_estimators': 796, 'learning_rate': 0.18047230418703825, 'max_depth': 12, 'max_bin': 298, 'num_leaves': 245}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:08,879]\u001b[0m Trial 34 finished with value: 0.8210473182269012 and parameters: {'n_estimators': 831, 'learning_rate': 0.13267116634679266, 'max_depth': 12, 'max_bin': 288, 'num_leaves': 305}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:10,755]\u001b[0m Trial 35 finished with value: 0.8183660172107841 and parameters: {'n_estimators': 835, 'learning_rate': 0.13003016655437571, 'max_depth': 10, 'max_bin': 300, 'num_leaves': 310}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:12,282]\u001b[0m Trial 36 finished with value: 0.8140407923831182 and parameters: {'n_estimators': 684, 'learning_rate': 0.14784551817883262, 'max_depth': 11, 'max_bin': 289, 'num_leaves': 352}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:14,237]\u001b[0m Trial 37 finished with value: 0.8157035495676744 and parameters: {'n_estimators': 848, 'learning_rate': 0.10706336505289772, 'max_depth': 12, 'max_bin': 266, 'num_leaves': 183}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:15,682]\u001b[0m Trial 38 finished with value: 0.8236206179317271 and parameters: {'n_estimators': 570, 'learning_rate': 0.17090433232124508, 'max_depth': 8, 'max_bin': 258, 'num_leaves': 414}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:16,822]\u001b[0m Trial 39 finished with value: 0.8116994417572698 and parameters: {'n_estimators': 581, 'learning_rate': 0.16945306214199757, 'max_depth': 6, 'max_bin': 253, 'num_leaves': 546}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:18,214]\u001b[0m Trial 40 finished with value: 0.8166975015538291 and parameters: {'n_estimators': 731, 'learning_rate': 0.18248230631885248, 'max_depth': 8, 'max_bin': 260, 'num_leaves': 420}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:19,404]\u001b[0m Trial 41 finished with value: 0.8070010112235458 and parameters: {'n_estimators': 790, 'learning_rate': 0.15698354734114175, 'max_depth': 5, 'max_bin': 290, 'num_leaves': 276}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:20,606]\u001b[0m Trial 42 finished with value: 0.8133606327442194 and parameters: {'n_estimators': 456, 'learning_rate': 0.13771452496768674, 'max_depth': 4, 'max_bin': 278, 'num_leaves': 646}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:22,560]\u001b[0m Trial 43 finished with value: 0.8179711200016584 and parameters: {'n_estimators': 714, 'learning_rate': 0.1253952815831108, 'max_depth': 11, 'max_bin': 210, 'num_leaves': 505}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:23,744]\u001b[0m Trial 44 finished with value: 0.8103597412428611 and parameters: {'n_estimators': 575, 'learning_rate': 0.16850183458211693, 'max_depth': 6, 'max_bin': 290, 'num_leaves': 217}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:25,504]\u001b[0m Trial 45 finished with value: 0.8218553327406977 and parameters: {'n_estimators': 847, 'learning_rate': 0.1407679665415009, 'max_depth': 12, 'max_bin': 283, 'num_leaves': 296}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:27,029]\u001b[0m Trial 46 finished with value: 0.8148325201961473 and parameters: {'n_estimators': 485, 'learning_rate': 0.17838162736165636, 'max_depth': 10, 'max_bin': 226, 'num_leaves': 575}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:28,406]\u001b[0m Trial 47 finished with value: 0.8136558955076904 and parameters: {'n_estimators': 872, 'learning_rate': 0.14427047278983446, 'max_depth': 8, 'max_bin': 266, 'num_leaves': 393}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:29,922]\u001b[0m Trial 48 finished with value: 0.8182315765446532 and parameters: {'n_estimators': 803, 'learning_rate': 0.18949379361611987, 'max_depth': 11, 'max_bin': 277, 'num_leaves': 456}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:31,560]\u001b[0m Trial 49 finished with value: 0.8158312877925518 and parameters: {'n_estimators': 696, 'learning_rate': 0.15506472660072196, 'max_depth': 10, 'max_bin': 294, 'num_leaves': 339}. Best is trial 32 with value: 0.8248888660514749.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 50.0\n",
      "\tBest value (f1_score): 0.8249\n",
      "\tBest params:\n",
      "\t\tn_estimators: 827\n",
      "\t\tlearning_rate: 0.1784117612902918\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 300\n",
      "\t\tnum_leaves: 253\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "study_lgbm = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier\")\n",
    "func_lgbm_0 = lambda trial: objective_lgbm_CV(trial, X_trainSet0, Y_trainSet0, Y_trainSet0_class)\n",
    "study_lgbm.optimize(func_lgbm_0, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f9cdad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:04:04.108707Z",
     "iopub.status.busy": "2023-01-15T14:04:04.108433Z",
     "iopub.status.idle": "2023-01-15T14:04:05.035252Z",
     "shell.execute_reply": "2023-01-15T14:04:05.034903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0\n",
      "0                    TP  333.000000\n",
      "1                    TN  175.000000\n",
      "2                    FP   49.000000\n",
      "3                    FN   38.000000\n",
      "4              Accuracy    0.853782\n",
      "5             Precision    0.871728\n",
      "6           Sensitivity    0.897574\n",
      "7           Specificity    0.781200\n",
      "8              F1 score    0.884462\n",
      "9   F1 score (weighted)    0.853009\n",
      "10     F1 score (macro)    0.842689\n",
      "11    Balanced Accuracy    0.839412\n",
      "12                  MCC    0.686036\n",
      "13                  NPV    0.821600\n",
      "14              ROC_AUC    0.839412\n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_0 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "                                         \n",
    "    \n",
    "eval_set = [(X_testSet0, Y_testSet0)]\n",
    "optimized_lgbm_0.fit(X_trainSet0,\n",
    "                Y_trainSet0,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_0 = optimized_lgbm_0.predict(X_testSet0)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet0, y_pred_lgbm_0)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet0, y_pred_lgbm_0)\n",
    "Precision = precision_score(Y_testSet0, y_pred_lgbm_0)\n",
    "Sensitivity = recall_score(Y_testSet0, y_pred_lgbm_0)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet0, y_pred_lgbm_0)      \n",
    "f1_scores_W = f1_score(Y_testSet0, y_pred_lgbm_0, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet0, y_pred_lgbm_0, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet0, y_pred_lgbm_0)\n",
    "MCC = matthews_corrcoef(Y_testSet0, y_pred_lgbm_0)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet0, y_pred_lgbm_0)\n",
    "\n",
    "\n",
    "mat_met_lgbm_test = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Set0':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "    \n",
    "print(mat_met_lgbm_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44ae2113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:04:05.036859Z",
     "iopub.status.busy": "2023-01-15T14:04:05.036738Z",
     "iopub.status.idle": "2023-01-15T14:05:40.535584Z",
     "shell.execute_reply": "2023-01-15T14:05:40.535254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:56:33,670]\u001b[0m Trial 50 finished with value: 0.8309476814924903 and parameters: {'n_estimators': 642, 'learning_rate': 0.14019807606018655, 'max_depth': 12, 'max_bin': 238, 'num_leaves': 631}. Best is trial 50 with value: 0.8309476814924903.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:35,754]\u001b[0m Trial 51 finished with value: 0.8292844864012505 and parameters: {'n_estimators': 596, 'learning_rate': 0.14282419232206836, 'max_depth': 12, 'max_bin': 240, 'num_leaves': 663}. Best is trial 50 with value: 0.8309476814924903.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:37,592]\u001b[0m Trial 52 finished with value: 0.8270475179446249 and parameters: {'n_estimators': 635, 'learning_rate': 0.16375927859501582, 'max_depth': 12, 'max_bin': 234, 'num_leaves': 693}. Best is trial 50 with value: 0.8309476814924903.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:39,446]\u001b[0m Trial 53 finished with value: 0.833324492554716 and parameters: {'n_estimators': 623, 'learning_rate': 0.16193547547571907, 'max_depth': 12, 'max_bin': 233, 'num_leaves': 715}. Best is trial 53 with value: 0.833324492554716.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:41,335]\u001b[0m Trial 54 finished with value: 0.8346056249142816 and parameters: {'n_estimators': 624, 'learning_rate': 0.1587697229488451, 'max_depth': 12, 'max_bin': 233, 'num_leaves': 695}. Best is trial 54 with value: 0.8346056249142816.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:43,221]\u001b[0m Trial 55 finished with value: 0.8367740868647484 and parameters: {'n_estimators': 608, 'learning_rate': 0.16096545002740337, 'max_depth': 11, 'max_bin': 218, 'num_leaves': 683}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:45,073]\u001b[0m Trial 56 finished with value: 0.8351742108718634 and parameters: {'n_estimators': 628, 'learning_rate': 0.16474955639739952, 'max_depth': 11, 'max_bin': 218, 'num_leaves': 696}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:46,977]\u001b[0m Trial 57 finished with value: 0.8236428162396707 and parameters: {'n_estimators': 612, 'learning_rate': 0.1523066098500919, 'max_depth': 11, 'max_bin': 218, 'num_leaves': 632}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:48,930]\u001b[0m Trial 58 finished with value: 0.832176600445709 and parameters: {'n_estimators': 663, 'learning_rate': 0.16024768952686672, 'max_depth': 11, 'max_bin': 215, 'num_leaves': 717}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:50,917]\u001b[0m Trial 59 finished with value: 0.8310820919816029 and parameters: {'n_estimators': 540, 'learning_rate': 0.1617704879986341, 'max_depth': 11, 'max_bin': 201, 'num_leaves': 694}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:52,938]\u001b[0m Trial 60 finished with value: 0.825109313504111 and parameters: {'n_estimators': 538, 'learning_rate': 0.16344236520677688, 'max_depth': 10, 'max_bin': 202, 'num_leaves': 722}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:54,637]\u001b[0m Trial 61 finished with value: 0.8249717447677496 and parameters: {'n_estimators': 655, 'learning_rate': 0.17350647564071328, 'max_depth': 11, 'max_bin': 184, 'num_leaves': 689}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:56,493]\u001b[0m Trial 62 finished with value: 0.8294704761496838 and parameters: {'n_estimators': 544, 'learning_rate': 0.16131479823295358, 'max_depth': 11, 'max_bin': 219, 'num_leaves': 719}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:58,140]\u001b[0m Trial 63 finished with value: 0.8262821630717452 and parameters: {'n_estimators': 656, 'learning_rate': 0.15052795530704852, 'max_depth': 9, 'max_bin': 210, 'num_leaves': 607}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:56:59,860]\u001b[0m Trial 64 finished with value: 0.8291890961595902 and parameters: {'n_estimators': 508, 'learning_rate': 0.18542968566969187, 'max_depth': 11, 'max_bin': 232, 'num_leaves': 745}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:01,643]\u001b[0m Trial 65 finished with value: 0.8285241893048216 and parameters: {'n_estimators': 619, 'learning_rate': 0.17325437899106055, 'max_depth': 11, 'max_bin': 202, 'num_leaves': 674}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:03,604]\u001b[0m Trial 66 finished with value: 0.8231026060748743 and parameters: {'n_estimators': 689, 'learning_rate': 0.1645351135315381, 'max_depth': 12, 'max_bin': 225, 'num_leaves': 627}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:05,559]\u001b[0m Trial 67 finished with value: 0.8322759545051742 and parameters: {'n_estimators': 556, 'learning_rate': 0.15667627037144471, 'max_depth': 10, 'max_bin': 187, 'num_leaves': 708}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:07,308]\u001b[0m Trial 68 finished with value: 0.8271393369290398 and parameters: {'n_estimators': 463, 'learning_rate': 0.1565206136856647, 'max_depth': 10, 'max_bin': 182, 'num_leaves': 708}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:08,819]\u001b[0m Trial 69 finished with value: 0.8246678786954778 and parameters: {'n_estimators': 524, 'learning_rate': 0.18860454174014185, 'max_depth': 10, 'max_bin': 192, 'num_leaves': 659}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:10,271]\u001b[0m Trial 70 finished with value: 0.8317546856728496 and parameters: {'n_estimators': 553, 'learning_rate': 0.1978624025759413, 'max_depth': 9, 'max_bin': 178, 'num_leaves': 589}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:11,755]\u001b[0m Trial 71 finished with value: 0.8202341896306562 and parameters: {'n_estimators': 562, 'learning_rate': 0.19446775025638846, 'max_depth': 9, 'max_bin': 172, 'num_leaves': 575}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:13,509]\u001b[0m Trial 72 finished with value: 0.827687597482323 and parameters: {'n_estimators': 488, 'learning_rate': 0.14860932866495985, 'max_depth': 9, 'max_bin': 213, 'num_leaves': 736}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:15,280]\u001b[0m Trial 73 finished with value: 0.8312752258224956 and parameters: {'n_estimators': 605, 'learning_rate': 0.19833601460084832, 'max_depth': 10, 'max_bin': 174, 'num_leaves': 693}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:17,092]\u001b[0m Trial 74 finished with value: 0.8350391245574041 and parameters: {'n_estimators': 603, 'learning_rate': 0.19441157062517445, 'max_depth': 10, 'max_bin': 160, 'num_leaves': 675}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:18,932]\u001b[0m Trial 75 finished with value: 0.8291197086715177 and parameters: {'n_estimators': 676, 'learning_rate': 0.17860878110787512, 'max_depth': 10, 'max_bin': 158, 'num_leaves': 599}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:20,562]\u001b[0m Trial 76 finished with value: 0.8310212979997116 and parameters: {'n_estimators': 589, 'learning_rate': 0.1839707224343735, 'max_depth': 9, 'max_bin': 163, 'num_leaves': 675}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:22,368]\u001b[0m Trial 77 finished with value: 0.8323689645637635 and parameters: {'n_estimators': 722, 'learning_rate': 0.19214580573968043, 'max_depth': 11, 'max_bin': 193, 'num_leaves': 651}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:24,100]\u001b[0m Trial 78 finished with value: 0.8235833941451485 and parameters: {'n_estimators': 710, 'learning_rate': 0.18944690540687276, 'max_depth': 11, 'max_bin': 194, 'num_leaves': 727}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:25,694]\u001b[0m Trial 79 finished with value: 0.823871549693405 and parameters: {'n_estimators': 626, 'learning_rate': 0.17597350476555804, 'max_depth': 11, 'max_bin': 246, 'num_leaves': 649}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:27,413]\u001b[0m Trial 80 finished with value: 0.8195722256684063 and parameters: {'n_estimators': 745, 'learning_rate': 0.1710050861334462, 'max_depth': 11, 'max_bin': 229, 'num_leaves': 747}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:57:28,997]\u001b[0m Trial 81 finished with value: 0.8172041379570046 and parameters: {'n_estimators': 663, 'learning_rate': 0.19987343916975425, 'max_depth': 10, 'max_bin': 150, 'num_leaves': 704}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:30,512]\u001b[0m Trial 82 finished with value: 0.8255975578272823 and parameters: {'n_estimators': 561, 'learning_rate': 0.19412504678023715, 'max_depth': 10, 'max_bin': 171, 'num_leaves': 678}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:32,176]\u001b[0m Trial 83 finished with value: 0.8289999074584069 and parameters: {'n_estimators': 508, 'learning_rate': 0.18593564162976342, 'max_depth': 12, 'max_bin': 179, 'num_leaves': 650}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:33,857]\u001b[0m Trial 84 finished with value: 0.8229008380565235 and parameters: {'n_estimators': 776, 'learning_rate': 0.19410148733875496, 'max_depth': 11, 'max_bin': 223, 'num_leaves': 616}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:45,512]\u001b[0m Trial 85 finished with value: 0.38305499462024917 and parameters: {'n_estimators': 717, 'learning_rate': 0.00020264868976280215, 'max_depth': 9, 'max_bin': 188, 'num_leaves': 714}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:47,185]\u001b[0m Trial 86 finished with value: 0.8348434043658989 and parameters: {'n_estimators': 639, 'learning_rate': 0.16847764301080875, 'max_depth': 10, 'max_bin': 207, 'num_leaves': 578}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:48,967]\u001b[0m Trial 87 finished with value: 0.8249705349649087 and parameters: {'n_estimators': 642, 'learning_rate': 0.1673713487571898, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 552}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:50,874]\u001b[0m Trial 88 finished with value: 0.8353974414785762 and parameters: {'n_estimators': 604, 'learning_rate': 0.1583745517787744, 'max_depth': 11, 'max_bin': 213, 'num_leaves': 729}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:53,056]\u001b[0m Trial 89 finished with value: 0.8322604940004708 and parameters: {'n_estimators': 593, 'learning_rate': 0.13403323368317, 'max_depth': 10, 'max_bin': 206, 'num_leaves': 663}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:55,011]\u001b[0m Trial 90 finished with value: 0.8291093408503343 and parameters: {'n_estimators': 615, 'learning_rate': 0.1531813637796525, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 638}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:56,795]\u001b[0m Trial 91 finished with value: 0.8320598650889227 and parameters: {'n_estimators': 580, 'learning_rate': 0.16658905945011904, 'max_depth': 10, 'max_bin': 206, 'num_leaves': 678}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:57:58,557]\u001b[0m Trial 92 finished with value: 0.8273127439812681 and parameters: {'n_estimators': 600, 'learning_rate': 0.14621221744829463, 'max_depth': 10, 'max_bin': 216, 'num_leaves': 702}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:00,428]\u001b[0m Trial 93 finished with value: 0.8257616039367959 and parameters: {'n_estimators': 632, 'learning_rate': 0.13273174889524558, 'max_depth': 11, 'max_bin': 222, 'num_leaves': 660}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:02,159]\u001b[0m Trial 94 finished with value: 0.8336599532473217 and parameters: {'n_estimators': 680, 'learning_rate': 0.15798911745378064, 'max_depth': 10, 'max_bin': 230, 'num_leaves': 617}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:03,961]\u001b[0m Trial 95 finished with value: 0.8337155018778104 and parameters: {'n_estimators': 680, 'learning_rate': 0.15637416437291934, 'max_depth': 12, 'max_bin': 230, 'num_leaves': 612}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:05,628]\u001b[0m Trial 96 finished with value: 0.8327180828666455 and parameters: {'n_estimators': 697, 'learning_rate': 0.18076198952199948, 'max_depth': 12, 'max_bin': 232, 'num_leaves': 574}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:07,341]\u001b[0m Trial 97 finished with value: 0.8312059364034144 and parameters: {'n_estimators': 696, 'learning_rate': 0.17442189280681775, 'max_depth': 12, 'max_bin': 230, 'num_leaves': 503}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:08,888]\u001b[0m Trial 98 finished with value: 0.8272961330905597 and parameters: {'n_estimators': 678, 'learning_rate': 0.17998032445965148, 'max_depth': 12, 'max_bin': 241, 'num_leaves': 558}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:10,588]\u001b[0m Trial 99 finished with value: 0.8313753891102232 and parameters: {'n_estimators': 641, 'learning_rate': 0.16790791311998776, 'max_depth': 12, 'max_bin': 234, 'num_leaves': 529}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 100.0\n",
      "\tBest value (f1_score): 0.8368\n",
      "\tBest params:\n",
      "\t\tn_estimators: 608\n",
      "\t\tlearning_rate: 0.16096545002740337\n",
      "\t\tmax_depth: 11\n",
      "\t\tmax_bin: 218\n",
      "\t\tnum_leaves: 683\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_lgbm_1 = lambda trial: objective_lgbm_CV(trial, X_trainSet1, Y_trainSet1, Y_trainSet1_class)\n",
    "study_lgbm.optimize(func_lgbm_1, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dafbda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:05:40.537235Z",
     "iopub.status.busy": "2023-01-15T14:05:40.537115Z",
     "iopub.status.idle": "2023-01-15T14:05:40.742974Z",
     "shell.execute_reply": "2023-01-15T14:05:40.742601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1\n",
      "0                    TP  333.000000  327.000000\n",
      "1                    TN  175.000000  166.000000\n",
      "2                    FP   49.000000   68.000000\n",
      "3                    FN   38.000000   34.000000\n",
      "4              Accuracy    0.853782    0.828571\n",
      "5             Precision    0.871728    0.827848\n",
      "6           Sensitivity    0.897574    0.905817\n",
      "7           Specificity    0.781200    0.709400\n",
      "8              F1 score    0.884462    0.865079\n",
      "9   F1 score (weighted)    0.853009    0.825711\n",
      "10     F1 score (macro)    0.842689    0.815028\n",
      "11    Balanced Accuracy    0.839412    0.807609\n",
      "12                  MCC    0.686036    0.636177\n",
      "13                  NPV    0.821600    0.830000\n",
      "14              ROC_AUC    0.839412    0.807609\n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_1 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "    \n",
    "eval_set = [(X_testSet1, Y_testSet1)]\n",
    "optimized_lgbm_1.fit(X_trainSet1,\n",
    "                Y_trainSet1,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_1 = optimized_lgbm_1.predict(X_testSet1)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet1, y_pred_lgbm_1)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet1, y_pred_lgbm_1)\n",
    "Precision = precision_score(Y_testSet1, y_pred_lgbm_1)\n",
    "Sensitivity = recall_score(Y_testSet1, y_pred_lgbm_1)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet1, y_pred_lgbm_1)      \n",
    "f1_scores_W = f1_score(Y_testSet1, y_pred_lgbm_1, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet1, y_pred_lgbm_1, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet1, y_pred_lgbm_1)\n",
    "MCC = matthews_corrcoef(Y_testSet1, y_pred_lgbm_1)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet1, y_pred_lgbm_1)\n",
    "\n",
    "\n",
    "set1 = pd.DataFrame({ 'Set1':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set1'] =set1\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f6ed3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:05:40.744630Z",
     "iopub.status.busy": "2023-01-15T14:05:40.744513Z",
     "iopub.status.idle": "2023-01-15T14:07:11.358903Z",
     "shell.execute_reply": "2023-01-15T14:07:11.358584Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:58:12,820]\u001b[0m Trial 100 finished with value: 0.8338981254898836 and parameters: {'n_estimators': 705, 'learning_rate': 0.1601338029680051, 'max_depth': 12, 'max_bin': 227, 'num_leaves': 624}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:14,780]\u001b[0m Trial 101 finished with value: 0.8317055116054257 and parameters: {'n_estimators': 740, 'learning_rate': 0.1591876102181212, 'max_depth': 12, 'max_bin': 228, 'num_leaves': 623}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:16,769]\u001b[0m Trial 102 finished with value: 0.8347636529800125 and parameters: {'n_estimators': 765, 'learning_rate': 0.15295618475816705, 'max_depth': 12, 'max_bin': 249, 'num_leaves': 570}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:18,652]\u001b[0m Trial 103 finished with value: 0.8323105882306047 and parameters: {'n_estimators': 766, 'learning_rate': 0.1528879720573002, 'max_depth': 12, 'max_bin': 247, 'num_leaves': 605}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:20,660]\u001b[0m Trial 104 finished with value: 0.8316842722881003 and parameters: {'n_estimators': 666, 'learning_rate': 0.1457463313579451, 'max_depth': 12, 'max_bin': 221, 'num_leaves': 732}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:22,547]\u001b[0m Trial 105 finished with value: 0.8277989847451248 and parameters: {'n_estimators': 651, 'learning_rate': 0.13901401559368087, 'max_depth': 11, 'max_bin': 237, 'num_leaves': 616}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:24,397]\u001b[0m Trial 106 finished with value: 0.833446410367203 and parameters: {'n_estimators': 780, 'learning_rate': 0.1498557690354673, 'max_depth': 12, 'max_bin': 226, 'num_leaves': 582}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:26,207]\u001b[0m Trial 107 finished with value: 0.8312477783831829 and parameters: {'n_estimators': 792, 'learning_rate': 0.14895064952519707, 'max_depth': 11, 'max_bin': 225, 'num_leaves': 588}. Best is trial 55 with value: 0.8367740868647484.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:29,715]\u001b[0m Trial 108 finished with value: 0.8369651886281539 and parameters: {'n_estimators': 772, 'learning_rate': 0.04607912200758605, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 530}. Best is trial 108 with value: 0.8369651886281539.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:32,104]\u001b[0m Trial 109 finished with value: 0.8427011547257633 and parameters: {'n_estimators': 744, 'learning_rate': 0.07647295397910811, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 533}. Best is trial 109 with value: 0.8427011547257633.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:35,615]\u001b[0m Trial 110 finished with value: 0.8384520588678468 and parameters: {'n_estimators': 813, 'learning_rate': 0.04573910222599637, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 499}. Best is trial 109 with value: 0.8427011547257633.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:38,535]\u001b[0m Trial 111 finished with value: 0.8399702190522824 and parameters: {'n_estimators': 765, 'learning_rate': 0.06075264674444707, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 509}. Best is trial 109 with value: 0.8427011547257633.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:41,921]\u001b[0m Trial 112 finished with value: 0.8371927099364888 and parameters: {'n_estimators': 817, 'learning_rate': 0.049085384068759556, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 524}. Best is trial 109 with value: 0.8427011547257633.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:44,817]\u001b[0m Trial 113 finished with value: 0.8483380594061133 and parameters: {'n_estimators': 817, 'learning_rate': 0.051638143204308144, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 491}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:48,110]\u001b[0m Trial 114 finished with value: 0.8372064580505644 and parameters: {'n_estimators': 816, 'learning_rate': 0.04741447836367852, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 498}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:51,201]\u001b[0m Trial 115 finished with value: 0.8429332334026313 and parameters: {'n_estimators': 856, 'learning_rate': 0.04938034787943043, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 492}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:54,558]\u001b[0m Trial 116 finished with value: 0.83352492392079 and parameters: {'n_estimators': 816, 'learning_rate': 0.045615454829438545, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 483}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:58:57,448]\u001b[0m Trial 117 finished with value: 0.8430355644852048 and parameters: {'n_estimators': 860, 'learning_rate': 0.05961451381325401, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:00,447]\u001b[0m Trial 118 finished with value: 0.8395917707856103 and parameters: {'n_estimators': 850, 'learning_rate': 0.06380369216769163, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 441}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:03,245]\u001b[0m Trial 119 finished with value: 0.8417493907473347 and parameters: {'n_estimators': 896, 'learning_rate': 0.061331346592021364, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:06,351]\u001b[0m Trial 120 finished with value: 0.8437535031141369 and parameters: {'n_estimators': 862, 'learning_rate': 0.059812833160898714, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 445}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:09,463]\u001b[0m Trial 121 finished with value: 0.8430420809693601 and parameters: {'n_estimators': 886, 'learning_rate': 0.060180108334405555, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:12,476]\u001b[0m Trial 122 finished with value: 0.844744309026255 and parameters: {'n_estimators': 880, 'learning_rate': 0.059862483243327734, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:15,490]\u001b[0m Trial 123 finished with value: 0.8422458425098812 and parameters: {'n_estimators': 885, 'learning_rate': 0.059147666054322146, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:18,502]\u001b[0m Trial 124 finished with value: 0.8395626999045847 and parameters: {'n_estimators': 899, 'learning_rate': 0.061459543074498246, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:21,356]\u001b[0m Trial 125 finished with value: 0.8483343848375752 and parameters: {'n_estimators': 890, 'learning_rate': 0.060671139745046516, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:24,288]\u001b[0m Trial 126 finished with value: 0.8382022504236168 and parameters: {'n_estimators': 897, 'learning_rate': 0.057855263914542945, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 453}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:27,163]\u001b[0m Trial 127 finished with value: 0.8421156901091814 and parameters: {'n_estimators': 860, 'learning_rate': 0.06821028602862508, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 431}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:30,066]\u001b[0m Trial 128 finished with value: 0.838646062263875 and parameters: {'n_estimators': 857, 'learning_rate': 0.07894060181803608, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 389}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:34,317]\u001b[0m Trial 129 finished with value: 0.836030902867104 and parameters: {'n_estimators': 874, 'learning_rate': 0.03259957968308515, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 461}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:37,043]\u001b[0m Trial 130 finished with value: 0.8354920718462597 and parameters: {'n_estimators': 843, 'learning_rate': 0.0670693093127172, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 429}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 15:59:39,816]\u001b[0m Trial 131 finished with value: 0.8406238312783867 and parameters: {'n_estimators': 890, 'learning_rate': 0.06038374821185475, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 442}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:42,486]\u001b[0m Trial 132 finished with value: 0.8389797343113056 and parameters: {'n_estimators': 859, 'learning_rate': 0.056403389761628564, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 471}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:45,423]\u001b[0m Trial 133 finished with value: 0.8391071591640978 and parameters: {'n_estimators': 880, 'learning_rate': 0.062350324987675315, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 400}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:48,102]\u001b[0m Trial 134 finished with value: 0.8421918775658561 and parameters: {'n_estimators': 884, 'learning_rate': 0.0733784382410855, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 447}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:50,409]\u001b[0m Trial 135 finished with value: 0.8355423611565348 and parameters: {'n_estimators': 886, 'learning_rate': 0.07618596217727877, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 379}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:53,300]\u001b[0m Trial 136 finished with value: 0.8373150839433985 and parameters: {'n_estimators': 874, 'learning_rate': 0.05312423272203767, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 419}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:56,981]\u001b[0m Trial 137 finished with value: 0.8300853617081391 and parameters: {'n_estimators': 830, 'learning_rate': 0.034240244684338936, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 487}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 15:59:59,774]\u001b[0m Trial 138 finished with value: 0.8438899448705162 and parameters: {'n_estimators': 862, 'learning_rate': 0.0719094359768034, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 453}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:02,661]\u001b[0m Trial 139 finished with value: 0.8428578223064566 and parameters: {'n_estimators': 891, 'learning_rate': 0.07150389627689079, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:04,650]\u001b[0m Trial 140 finished with value: 0.8342524593093966 and parameters: {'n_estimators': 861, 'learning_rate': 0.0886671581018314, 'max_depth': 7, 'max_bin': 200, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:07,322]\u001b[0m Trial 141 finished with value: 0.8428497677195816 and parameters: {'n_estimators': 887, 'learning_rate': 0.07197911735130956, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:09,959]\u001b[0m Trial 142 finished with value: 0.8429766977446163 and parameters: {'n_estimators': 843, 'learning_rate': 0.07143734872292494, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 404}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:12,657]\u001b[0m Trial 143 finished with value: 0.8436328414090948 and parameters: {'n_estimators': 844, 'learning_rate': 0.06917354406778348, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:15,216]\u001b[0m Trial 144 finished with value: 0.8412126271188456 and parameters: {'n_estimators': 840, 'learning_rate': 0.08090919969228527, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 412}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:17,828]\u001b[0m Trial 145 finished with value: 0.8362675445421835 and parameters: {'n_estimators': 873, 'learning_rate': 0.07627348671270838, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 476}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:19,700]\u001b[0m Trial 146 finished with value: 0.8246155093231018 and parameters: {'n_estimators': 834, 'learning_rate': 0.07215047507796679, 'max_depth': 4, 'max_bin': 204, 'num_leaves': 401}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:22,263]\u001b[0m Trial 147 finished with value: 0.8438808580586082 and parameters: {'n_estimators': 874, 'learning_rate': 0.08462204793052086, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 426}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:24,815]\u001b[0m Trial 148 finished with value: 0.8352565036042545 and parameters: {'n_estimators': 845, 'learning_rate': 0.08710276999043821, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 417}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:28,015]\u001b[0m Trial 149 finished with value: 0.84205304399031 and parameters: {'n_estimators': 865, 'learning_rate': 0.05279445196954669, 'max_depth': 12, 'max_bin': 191, 'num_leaves': 370}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 150.0\n",
      "\tBest value (f1_score): 0.8483\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_2 = lambda trial: objective_lgbm_CV(trial, X_trainSet2, Y_trainSet2, Y_trainSet2_class)\n",
    "study_lgbm.optimize(func_lgbm_2, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef8fbce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:07:11.360325Z",
     "iopub.status.busy": "2023-01-15T14:07:11.360209Z",
     "iopub.status.idle": "2023-01-15T14:07:11.543674Z",
     "shell.execute_reply": "2023-01-15T14:07:11.543291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2\n",
      "0                    TP  333.000000  327.000000  320.000000\n",
      "1                    TN  175.000000  166.000000  165.000000\n",
      "2                    FP   49.000000   68.000000   59.000000\n",
      "3                    FN   38.000000   34.000000   51.000000\n",
      "4              Accuracy    0.853782    0.828571    0.815126\n",
      "5             Precision    0.871728    0.827848    0.844327\n",
      "6           Sensitivity    0.897574    0.905817    0.862534\n",
      "7           Specificity    0.781200    0.709400    0.736600\n",
      "8              F1 score    0.884462    0.865079    0.853333\n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431\n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667\n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570\n",
      "12                  MCC    0.686036    0.636177    0.603661\n",
      "13                  NPV    0.821600    0.830000    0.763900\n",
      "14              ROC_AUC    0.839412    0.807609    0.799570\n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_2 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet2, Y_testSet2)]\n",
    "optimized_lgbm_2.fit(X_trainSet2,\n",
    "                Y_trainSet2,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_2 = optimized_lgbm_2.predict(X_testSet2)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet2, y_pred_lgbm_2)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet2, y_pred_lgbm_2)\n",
    "Precision = precision_score(Y_testSet2, y_pred_lgbm_2)\n",
    "Sensitivity = recall_score(Y_testSet2, y_pred_lgbm_2)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet2, y_pred_lgbm_2)      \n",
    "f1_scores_W = f1_score(Y_testSet2, y_pred_lgbm_2, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet2, y_pred_lgbm_2, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet2, y_pred_lgbm_2)\n",
    "MCC = matthews_corrcoef(Y_testSet2, y_pred_lgbm_2)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet2, y_pred_lgbm_2)\n",
    "\n",
    "\n",
    "Set2 = pd.DataFrame({ 'Set2':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set2'] = Set2\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a48b792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:07:11.545212Z",
     "iopub.status.busy": "2023-01-15T14:07:11.545090Z",
     "iopub.status.idle": "2023-01-15T14:08:39.993317Z",
     "shell.execute_reply": "2023-01-15T14:08:39.992862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:00:30,449]\u001b[0m Trial 150 finished with value: 0.8280012709492285 and parameters: {'n_estimators': 829, 'learning_rate': 0.08329724082688882, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 473}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:33,003]\u001b[0m Trial 151 finished with value: 0.8245664530815716 and parameters: {'n_estimators': 883, 'learning_rate': 0.06959223233743105, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 426}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:35,618]\u001b[0m Trial 152 finished with value: 0.8241073202636281 and parameters: {'n_estimators': 900, 'learning_rate': 0.07237642734261178, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:37,944]\u001b[0m Trial 153 finished with value: 0.824075851583955 and parameters: {'n_estimators': 798, 'learning_rate': 0.09154973870284216, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 464}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:40,859]\u001b[0m Trial 154 finished with value: 0.8236251395850311 and parameters: {'n_estimators': 875, 'learning_rate': 0.06565447435355247, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 489}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:44,589]\u001b[0m Trial 155 finished with value: 0.824408668620879 and parameters: {'n_estimators': 856, 'learning_rate': 0.04006743825551075, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 405}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:47,578]\u001b[0m Trial 156 finished with value: 0.8275855748281856 and parameters: {'n_estimators': 883, 'learning_rate': 0.054624094188152124, 'max_depth': 11, 'max_bin': 219, 'num_leaves': 386}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:50,276]\u001b[0m Trial 157 finished with value: 0.8264011039362972 and parameters: {'n_estimators': 837, 'learning_rate': 0.07450156982029364, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 447}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:52,603]\u001b[0m Trial 158 finished with value: 0.8329157517809523 and parameters: {'n_estimators': 859, 'learning_rate': 0.08159780064320434, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 421}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:54,932]\u001b[0m Trial 159 finished with value: 0.8250294429241588 and parameters: {'n_estimators': 821, 'learning_rate': 0.10111470138459516, 'max_depth': 11, 'max_bin': 216, 'num_leaves': 514}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:00:57,785]\u001b[0m Trial 160 finished with value: 0.8304302130410856 and parameters: {'n_estimators': 871, 'learning_rate': 0.06580256473262627, 'max_depth': 12, 'max_bin': 194, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:00,552]\u001b[0m Trial 161 finished with value: 0.8221738368188282 and parameters: {'n_estimators': 851, 'learning_rate': 0.06798419936661601, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 430}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:03,034]\u001b[0m Trial 162 finished with value: 0.8288998876649669 and parameters: {'n_estimators': 900, 'learning_rate': 0.0699762131019452, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:05,664]\u001b[0m Trial 163 finished with value: 0.8262213023244538 and parameters: {'n_estimators': 863, 'learning_rate': 0.07528804836448803, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 481}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:08,570]\u001b[0m Trial 164 finished with value: 0.8203971154136858 and parameters: {'n_estimators': 806, 'learning_rate': 0.051432102511324636, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 409}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:11,386]\u001b[0m Trial 165 finished with value: 0.8259108369116369 and parameters: {'n_estimators': 844, 'learning_rate': 0.057999926030878474, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 466}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:14,282]\u001b[0m Trial 166 finished with value: 0.8309555107768583 and parameters: {'n_estimators': 883, 'learning_rate': 0.06573385230660418, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 355}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:18,268]\u001b[0m Trial 167 finished with value: 0.8293165277351442 and parameters: {'n_estimators': 868, 'learning_rate': 0.040504594752505195, 'max_depth': 12, 'max_bin': 186, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:21,049]\u001b[0m Trial 168 finished with value: 0.8285691925043519 and parameters: {'n_estimators': 825, 'learning_rate': 0.07143885060810266, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:24,127]\u001b[0m Trial 169 finished with value: 0.8234259051792684 and parameters: {'n_estimators': 886, 'learning_rate': 0.057037537971167986, 'max_depth': 11, 'max_bin': 203, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:26,543]\u001b[0m Trial 170 finished with value: 0.8316478585890383 and parameters: {'n_estimators': 851, 'learning_rate': 0.07821233879834374, 'max_depth': 12, 'max_bin': 221, 'num_leaves': 445}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:29,695]\u001b[0m Trial 171 finished with value: 0.8259848947715293 and parameters: {'n_estimators': 865, 'learning_rate': 0.051055849139464725, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 328}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:32,652]\u001b[0m Trial 172 finished with value: 0.8235463206157977 and parameters: {'n_estimators': 869, 'learning_rate': 0.05418722075303312, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 382}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:35,541]\u001b[0m Trial 173 finished with value: 0.8266594307340164 and parameters: {'n_estimators': 839, 'learning_rate': 0.06219734320611651, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 362}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:37,910]\u001b[0m Trial 174 finished with value: 0.8280411901884254 and parameters: {'n_estimators': 858, 'learning_rate': 0.06949176466691517, 'max_depth': 12, 'max_bin': 192, 'num_leaves': 373}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:40,644]\u001b[0m Trial 175 finished with value: 0.8226658443599211 and parameters: {'n_estimators': 883, 'learning_rate': 0.05832381254893145, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 396}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:43,208]\u001b[0m Trial 176 finished with value: 0.8301019978458675 and parameters: {'n_estimators': 899, 'learning_rate': 0.0737646365926782, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 416}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:46,092]\u001b[0m Trial 177 finished with value: 0.8307390655343596 and parameters: {'n_estimators': 830, 'learning_rate': 0.065092511240948, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 488}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:48,507]\u001b[0m Trial 178 finished with value: 0.8303872653870099 and parameters: {'n_estimators': 811, 'learning_rate': 0.08368382030731854, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 467}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:51,856]\u001b[0m Trial 179 finished with value: 0.826113166278944 and parameters: {'n_estimators': 875, 'learning_rate': 0.05150450050821348, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 435}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:01:55,251]\u001b[0m Trial 180 finished with value: 0.827756090923087 and parameters: {'n_estimators': 854, 'learning_rate': 0.0634636627409831, 'max_depth': 11, 'max_bin': 210, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:01:58,594]\u001b[0m Trial 181 finished with value: 0.8265198442918177 and parameters: {'n_estimators': 897, 'learning_rate': 0.05810626617042359, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:01,804]\u001b[0m Trial 182 finished with value: 0.8254448172909704 and parameters: {'n_estimators': 884, 'learning_rate': 0.06139569938312157, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 441}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:04,662]\u001b[0m Trial 183 finished with value: 0.8322563947008639 and parameters: {'n_estimators': 900, 'learning_rate': 0.06862762591302396, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 540}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:07,042]\u001b[0m Trial 184 finished with value: 0.8230115979206936 and parameters: {'n_estimators': 869, 'learning_rate': 0.07886460598933623, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 465}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:10,160]\u001b[0m Trial 185 finished with value: 0.8266281272800331 and parameters: {'n_estimators': 845, 'learning_rate': 0.05468936042144251, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 422}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:12,879]\u001b[0m Trial 186 finished with value: 0.8232461531191012 and parameters: {'n_estimators': 864, 'learning_rate': 0.073180235713699, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:16,640]\u001b[0m Trial 187 finished with value: 0.8307269556227934 and parameters: {'n_estimators': 883, 'learning_rate': 0.04396771208101793, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 498}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:19,649]\u001b[0m Trial 188 finished with value: 0.828617746986812 and parameters: {'n_estimators': 795, 'learning_rate': 0.060243699864389814, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 480}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:22,430]\u001b[0m Trial 189 finished with value: 0.8226336835323123 and parameters: {'n_estimators': 833, 'learning_rate': 0.0666245251934265, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 517}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:25,123]\u001b[0m Trial 190 finished with value: 0.81994438548076 and parameters: {'n_estimators': 848, 'learning_rate': 0.049334964977465895, 'max_depth': 6, 'max_bin': 211, 'num_leaves': 412}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:27,581]\u001b[0m Trial 191 finished with value: 0.8300368858783234 and parameters: {'n_estimators': 839, 'learning_rate': 0.08172157329226232, 'max_depth': 12, 'max_bin': 189, 'num_leaves': 430}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:30,025]\u001b[0m Trial 192 finished with value: 0.830206336154462 and parameters: {'n_estimators': 863, 'learning_rate': 0.07815050559750723, 'max_depth': 12, 'max_bin': 184, 'num_leaves': 411}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:32,665]\u001b[0m Trial 193 finished with value: 0.8300689509200806 and parameters: {'n_estimators': 877, 'learning_rate': 0.09188160878984825, 'max_depth': 12, 'max_bin': 192, 'num_leaves': 393}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:35,118]\u001b[0m Trial 194 finished with value: 0.8232157580285934 and parameters: {'n_estimators': 888, 'learning_rate': 0.07043008149167299, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 443}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:37,856]\u001b[0m Trial 195 finished with value: 0.8278422088657784 and parameters: {'n_estimators': 818, 'learning_rate': 0.06311204352656562, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 459}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:40,718]\u001b[0m Trial 196 finished with value: 0.8254387136737533 and parameters: {'n_estimators': 900, 'learning_rate': 0.053532746897442196, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 423}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:43,187]\u001b[0m Trial 197 finished with value: 0.8266501754040869 and parameters: {'n_estimators': 852, 'learning_rate': 0.08416844345968484, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:46,119]\u001b[0m Trial 198 finished with value: 0.8244989168311907 and parameters: {'n_estimators': 869, 'learning_rate': 0.06654496721950952, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 411}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:48,803]\u001b[0m Trial 199 finished with value: 0.8251741702775133 and parameters: {'n_estimators': 833, 'learning_rate': 0.07604643930396084, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 474}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 200.0\n",
      "\tBest value (f1_score): 0.8483\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_3 = lambda trial: objective_lgbm_CV(trial, X_trainSet3, Y_trainSet3, Y_trainSet3_class)\n",
    "study_lgbm.optimize(func_lgbm_3, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e514e22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:39.995058Z",
     "iopub.status.busy": "2023-01-15T14:08:39.994929Z",
     "iopub.status.idle": "2023-01-15T14:08:40.253959Z",
     "shell.execute_reply": "2023-01-15T14:08:40.253483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000\n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000\n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000\n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000\n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294\n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670\n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701\n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600\n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391\n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113\n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210\n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153\n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473\n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100\n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153\n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_3 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet3, Y_testSet3)]\n",
    "optimized_lgbm_3.fit(X_trainSet3,\n",
    "                Y_trainSet3,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_3 = optimized_lgbm_3.predict(X_testSet3)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet3, y_pred_lgbm_3)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet3, y_pred_lgbm_3)\n",
    "Precision = precision_score(Y_testSet3, y_pred_lgbm_3)\n",
    "Sensitivity = recall_score(Y_testSet3, y_pred_lgbm_3)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet3, y_pred_lgbm_3)      \n",
    "f1_scores_W = f1_score(Y_testSet3, y_pred_lgbm_3, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet3, y_pred_lgbm_3, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet3, y_pred_lgbm_3)\n",
    "MCC = matthews_corrcoef(Y_testSet3, y_pred_lgbm_3)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet3, y_pred_lgbm_3)\n",
    "\n",
    "\n",
    "Set3 = pd.DataFrame({ 'Set3':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set3'] = Set3\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6528c0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:40.255839Z",
     "iopub.status.busy": "2023-01-15T14:08:40.255649Z",
     "iopub.status.idle": "2023-01-15T14:10:12.263472Z",
     "shell.execute_reply": "2023-01-15T14:10:12.263125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:02:51,993]\u001b[0m Trial 200 finished with value: 0.8297022933921021 and parameters: {'n_estimators': 852, 'learning_rate': 0.05709331182899308, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 450}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:54,468]\u001b[0m Trial 201 finished with value: 0.8225628647300587 and parameters: {'n_estimators': 886, 'learning_rate': 0.06065953515868323, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 434}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:57,043]\u001b[0m Trial 202 finished with value: 0.8340727201954781 and parameters: {'n_estimators': 884, 'learning_rate': 0.07213173037300394, 'max_depth': 12, 'max_bin': 222, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:02:59,652]\u001b[0m Trial 203 finished with value: 0.8302674669249368 and parameters: {'n_estimators': 869, 'learning_rate': 0.06349811641887776, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 421}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:02,485]\u001b[0m Trial 204 finished with value: 0.8312939023753037 and parameters: {'n_estimators': 899, 'learning_rate': 0.05947210508935068, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 460}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:04,950]\u001b[0m Trial 205 finished with value: 0.826368716587276 and parameters: {'n_estimators': 858, 'learning_rate': 0.06750617828578061, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 399}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:07,851]\u001b[0m Trial 206 finished with value: 0.8252819268061753 and parameters: {'n_estimators': 883, 'learning_rate': 0.054782012927762296, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 491}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:10,211]\u001b[0m Trial 207 finished with value: 0.8329115431517515 and parameters: {'n_estimators': 837, 'learning_rate': 0.08082994692613116, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:12,539]\u001b[0m Trial 208 finished with value: 0.8309042698628462 and parameters: {'n_estimators': 865, 'learning_rate': 0.07480837388327932, 'max_depth': 11, 'max_bin': 218, 'num_leaves': 471}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:15,373]\u001b[0m Trial 209 finished with value: 0.8236328782042529 and parameters: {'n_estimators': 805, 'learning_rate': 0.05046652492341652, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 383}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:17,644]\u001b[0m Trial 210 finished with value: 0.8259933347759759 and parameters: {'n_estimators': 885, 'learning_rate': 0.06979088979195829, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 429}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:20,456]\u001b[0m Trial 211 finished with value: 0.8303344569163486 and parameters: {'n_estimators': 297, 'learning_rate': 0.06061569327996363, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 512}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:22,949]\u001b[0m Trial 212 finished with value: 0.8293452139641498 and parameters: {'n_estimators': 786, 'learning_rate': 0.0637587472478958, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 343}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:25,857]\u001b[0m Trial 213 finished with value: 0.8264942809126847 and parameters: {'n_estimators': 845, 'learning_rate': 0.05738460157067147, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 533}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:28,302]\u001b[0m Trial 214 finished with value: 0.8239634673626568 and parameters: {'n_estimators': 871, 'learning_rate': 0.06102820050799545, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 456}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:30,840]\u001b[0m Trial 215 finished with value: 0.8294073304899353 and parameters: {'n_estimators': 821, 'learning_rate': 0.06811856102033227, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 500}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:33,654]\u001b[0m Trial 216 finished with value: 0.8255162968368234 and parameters: {'n_estimators': 900, 'learning_rate': 0.05498102108856741, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 474}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:35,868]\u001b[0m Trial 217 finished with value: 0.8240723105317029 and parameters: {'n_estimators': 853, 'learning_rate': 0.07116302868783406, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 413}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:38,761]\u001b[0m Trial 218 finished with value: 0.8261426309269743 and parameters: {'n_estimators': 877, 'learning_rate': 0.049285812860656045, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 439}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:41,138]\u001b[0m Trial 219 finished with value: 0.8277370379317563 and parameters: {'n_estimators': 836, 'learning_rate': 0.06369016872618052, 'max_depth': 12, 'max_bin': 187, 'num_leaves': 450}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:43,399]\u001b[0m Trial 220 finished with value: 0.8291716255936805 and parameters: {'n_estimators': 863, 'learning_rate': 0.07705205120617967, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 509}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:46,478]\u001b[0m Trial 221 finished with value: 0.8283488980275141 and parameters: {'n_estimators': 848, 'learning_rate': 0.06519075045175363, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:49,429]\u001b[0m Trial 222 finished with value: 0.830716733538849 and parameters: {'n_estimators': 885, 'learning_rate': 0.05987298277057905, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 443}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:52,489]\u001b[0m Trial 223 finished with value: 0.8233139609404028 and parameters: {'n_estimators': 861, 'learning_rate': 0.05624573300915228, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:54,974]\u001b[0m Trial 224 finished with value: 0.8323991221747706 and parameters: {'n_estimators': 139, 'learning_rate': 0.06532445610335069, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 484}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:57,614]\u001b[0m Trial 225 finished with value: 0.828522086861677 and parameters: {'n_estimators': 389, 'learning_rate': 0.07221989113116045, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 405}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:03:59,654]\u001b[0m Trial 226 finished with value: 0.8099826732243478 and parameters: {'n_estimators': 825, 'learning_rate': 0.05208545470099745, 'max_depth': 3, 'max_bin': 219, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:02,325]\u001b[0m Trial 227 finished with value: 0.8310771848883707 and parameters: {'n_estimators': 873, 'learning_rate': 0.06140758582503475, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 424}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:04,828]\u001b[0m Trial 228 finished with value: 0.8292188781597982 and parameters: {'n_estimators': 853, 'learning_rate': 0.07452201018259505, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 373}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:07,334]\u001b[0m Trial 229 finished with value: 0.8292718393348173 and parameters: {'n_estimators': 754, 'learning_rate': 0.06826185563901842, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 458}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:09,920]\u001b[0m Trial 230 finished with value: 0.8262633714217268 and parameters: {'n_estimators': 900, 'learning_rate': 0.05826583638981832, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 444}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:04:12,594]\u001b[0m Trial 231 finished with value: 0.8328632495984518 and parameters: {'n_estimators': 882, 'learning_rate': 0.06258704126200429, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 431}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:15,209]\u001b[0m Trial 232 finished with value: 0.8241319360212367 and parameters: {'n_estimators': 900, 'learning_rate': 0.06463716829820326, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 551}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:18,459]\u001b[0m Trial 233 finished with value: 0.8220868229088054 and parameters: {'n_estimators': 884, 'learning_rate': 0.044100131705040534, 'max_depth': 12, 'max_bin': 221, 'num_leaves': 420}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:20,630]\u001b[0m Trial 234 finished with value: 0.817798107701676 and parameters: {'n_estimators': 868, 'learning_rate': 0.05451636082976407, 'max_depth': 4, 'max_bin': 215, 'num_leaves': 438}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:23,562]\u001b[0m Trial 235 finished with value: 0.8314987626506003 and parameters: {'n_estimators': 843, 'learning_rate': 0.06044142338291093, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 455}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:25,907]\u001b[0m Trial 236 finished with value: 0.8231330845901288 and parameters: {'n_estimators': 888, 'learning_rate': 0.07988238823529101, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 473}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:28,476]\u001b[0m Trial 237 finished with value: 0.8274914692635565 and parameters: {'n_estimators': 861, 'learning_rate': 0.06921548708251159, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 393}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:31,137]\u001b[0m Trial 238 finished with value: 0.8315891344486804 and parameters: {'n_estimators': 877, 'learning_rate': 0.07358954892722033, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 417}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:34,186]\u001b[0m Trial 239 finished with value: 0.831284905487153 and parameters: {'n_estimators': 844, 'learning_rate': 0.058648295896901105, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 435}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:36,971]\u001b[0m Trial 240 finished with value: 0.8187570693146411 and parameters: {'n_estimators': 900, 'learning_rate': 0.04786854829552929, 'max_depth': 8, 'max_bin': 223, 'num_leaves': 409}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:40,004]\u001b[0m Trial 241 finished with value: 0.8327955265538526 and parameters: {'n_estimators': 874, 'learning_rate': 0.06307466223081452, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 399}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:42,693]\u001b[0m Trial 242 finished with value: 0.8266529057332261 and parameters: {'n_estimators': 883, 'learning_rate': 0.06779570535445356, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:45,852]\u001b[0m Trial 243 finished with value: 0.8276591007468189 and parameters: {'n_estimators': 859, 'learning_rate': 0.05399832413010979, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:48,637]\u001b[0m Trial 244 finished with value: 0.8326569334245191 and parameters: {'n_estimators': 872, 'learning_rate': 0.06138999002143466, 'max_depth': 12, 'max_bin': 219, 'num_leaves': 467}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:51,241]\u001b[0m Trial 245 finished with value: 0.8307744786755817 and parameters: {'n_estimators': 823, 'learning_rate': 0.06496867818349725, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 523}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:53,680]\u001b[0m Trial 246 finished with value: 0.8264737608218992 and parameters: {'n_estimators': 888, 'learning_rate': 0.08605431398070854, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:56,203]\u001b[0m Trial 247 finished with value: 0.8316272034674557 and parameters: {'n_estimators': 852, 'learning_rate': 0.0709894512438171, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:04:58,826]\u001b[0m Trial 248 finished with value: 0.830949989292414 and parameters: {'n_estimators': 836, 'learning_rate': 0.05760751677494157, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:01,430]\u001b[0m Trial 249 finished with value: 0.8286329006724749 and parameters: {'n_estimators': 868, 'learning_rate': 0.06653645683438936, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 491}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 250.0\n",
      "\tBest value (f1_score): 0.8483\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_4 = lambda trial: objective_lgbm_CV(trial, X_trainSet4, Y_trainSet4, Y_trainSet4_class)\n",
    "study_lgbm.optimize(func_lgbm_4, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b50d2b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:10:12.265077Z",
     "iopub.status.busy": "2023-01-15T14:10:12.264946Z",
     "iopub.status.idle": "2023-01-15T14:10:12.501741Z",
     "shell.execute_reply": "2023-01-15T14:10:12.501385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4  \n",
      "0   342.000000  \n",
      "1   160.000000  \n",
      "2    65.000000  \n",
      "3    28.000000  \n",
      "4     0.843697  \n",
      "5     0.840295  \n",
      "6     0.924324  \n",
      "7     0.711100  \n",
      "8     0.880309  \n",
      "9     0.840418  \n",
      "10    0.827564  \n",
      "11    0.817718  \n",
      "12    0.662808  \n",
      "13    0.851100  \n",
      "14    0.817718  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_4 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet4, Y_testSet4)]\n",
    "optimized_lgbm_4.fit(X_trainSet4,\n",
    "                Y_trainSet4,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_4 = optimized_lgbm_4.predict(X_testSet4)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet4, y_pred_lgbm_4)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet4, y_pred_lgbm_4)\n",
    "Precision = precision_score(Y_testSet4, y_pred_lgbm_4)\n",
    "Sensitivity = recall_score(Y_testSet4, y_pred_lgbm_4)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet4, y_pred_lgbm_4)      \n",
    "f1_scores_W = f1_score(Y_testSet4, y_pred_lgbm_4, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet4, y_pred_lgbm_4, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet4, y_pred_lgbm_4)\n",
    "MCC = matthews_corrcoef(Y_testSet4, y_pred_lgbm_4)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet4, y_pred_lgbm_4)\n",
    "\n",
    "\n",
    "Set4 = pd.DataFrame({ 'Set4':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set4'] = Set4\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c56fd97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:10:12.503469Z",
     "iopub.status.busy": "2023-01-15T14:10:12.503347Z",
     "iopub.status.idle": "2023-01-15T14:11:47.158489Z",
     "shell.execute_reply": "2023-01-15T14:11:47.158054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:05:04,768]\u001b[0m Trial 250 finished with value: 0.8160357781695442 and parameters: {'n_estimators': 899, 'learning_rate': 0.05143650922117319, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 388}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:07,169]\u001b[0m Trial 251 finished with value: 0.8154063412059103 and parameters: {'n_estimators': 856, 'learning_rate': 0.07782700646250278, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 416}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:09,847]\u001b[0m Trial 252 finished with value: 0.8139699114343948 and parameters: {'n_estimators': 879, 'learning_rate': 0.06201050742453476, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 366}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:12,676]\u001b[0m Trial 253 finished with value: 0.8146052547467016 and parameters: {'n_estimators': 841, 'learning_rate': 0.056654426897229285, 'max_depth': 11, 'max_bin': 198, 'num_leaves': 444}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:15,191]\u001b[0m Trial 254 finished with value: 0.808801543713949 and parameters: {'n_estimators': 810, 'learning_rate': 0.0732920488500766, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 429}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:17,694]\u001b[0m Trial 255 finished with value: 0.8111498920312789 and parameters: {'n_estimators': 885, 'learning_rate': 0.06812093955075481, 'max_depth': 12, 'max_bin': 192, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:20,465]\u001b[0m Trial 256 finished with value: 0.8148220736117514 and parameters: {'n_estimators': 864, 'learning_rate': 0.06074552698439135, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 474}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:23,093]\u001b[0m Trial 257 finished with value: 0.8110397608547759 and parameters: {'n_estimators': 886, 'learning_rate': 0.0636098029031603, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:26,052]\u001b[0m Trial 258 finished with value: 0.8177239748047084 and parameters: {'n_estimators': 900, 'learning_rate': 0.053859227510415233, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 407}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:28,745]\u001b[0m Trial 259 finished with value: 0.8109658586989724 and parameters: {'n_estimators': 825, 'learning_rate': 0.07999909415452348, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 424}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:31,959]\u001b[0m Trial 260 finished with value: 0.8147545137478087 and parameters: {'n_estimators': 850, 'learning_rate': 0.0393083762552718, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 119}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:34,420]\u001b[0m Trial 261 finished with value: 0.8114255618105377 and parameters: {'n_estimators': 734, 'learning_rate': 0.07500101297508782, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 504}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:37,206]\u001b[0m Trial 262 finished with value: 0.8111197477771087 and parameters: {'n_estimators': 868, 'learning_rate': 0.058106600974512125, 'max_depth': 12, 'max_bin': 184, 'num_leaves': 436}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:39,761]\u001b[0m Trial 263 finished with value: 0.8167567707645993 and parameters: {'n_estimators': 872, 'learning_rate': 0.0700490489883936, 'max_depth': 12, 'max_bin': 194, 'num_leaves': 457}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:41,691]\u001b[0m Trial 264 finished with value: 0.8065586593244858 and parameters: {'n_estimators': 837, 'learning_rate': 0.09029931278773046, 'max_depth': 11, 'max_bin': 205, 'num_leaves': 488}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:44,574]\u001b[0m Trial 265 finished with value: 0.8181363102769575 and parameters: {'n_estimators': 801, 'learning_rate': 0.047572530966632616, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 381}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:46,959]\u001b[0m Trial 266 finished with value: 0.8146457056860562 and parameters: {'n_estimators': 226, 'learning_rate': 0.06549183716251504, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 431}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:48,771]\u001b[0m Trial 267 finished with value: 0.8118967955448287 and parameters: {'n_estimators': 854, 'learning_rate': 0.11416569447449422, 'max_depth': 11, 'max_bin': 211, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:51,349]\u001b[0m Trial 268 finished with value: 0.8116016130778549 and parameters: {'n_estimators': 887, 'learning_rate': 0.06066185214156721, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 413}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:54,006]\u001b[0m Trial 269 finished with value: 0.816890060524751 and parameters: {'n_estimators': 866, 'learning_rate': 0.0517508950668787, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 397}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:56,264]\u001b[0m Trial 270 finished with value: 0.8132725837464949 and parameters: {'n_estimators': 885, 'learning_rate': 0.07068935442893975, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 479}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:05:58,883]\u001b[0m Trial 271 finished with value: 0.8106927801656412 and parameters: {'n_estimators': 900, 'learning_rate': 0.05720278065144524, 'max_depth': 12, 'max_bin': 224, 'num_leaves': 537}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:01,181]\u001b[0m Trial 272 finished with value: 0.811417823896693 and parameters: {'n_estimators': 845, 'learning_rate': 0.08329033642303509, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 464}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:03,643]\u001b[0m Trial 273 finished with value: 0.8136975507689698 and parameters: {'n_estimators': 827, 'learning_rate': 0.0771097555032841, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 442}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:05,688]\u001b[0m Trial 274 finished with value: 0.8095571853711216 and parameters: {'n_estimators': 869, 'learning_rate': 0.10271179490271275, 'max_depth': 12, 'max_bin': 188, 'num_leaves': 421}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:08,178]\u001b[0m Trial 275 finished with value: 0.8098206183094749 and parameters: {'n_estimators': 856, 'learning_rate': 0.06586600994478004, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:10,780]\u001b[0m Trial 276 finished with value: 0.8128716671591854 and parameters: {'n_estimators': 878, 'learning_rate': 0.06295741725729564, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 452}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:12,937]\u001b[0m Trial 277 finished with value: 0.8137033857841642 and parameters: {'n_estimators': 814, 'learning_rate': 0.07220489746158364, 'max_depth': 11, 'max_bin': 202, 'num_leaves': 413}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:15,666]\u001b[0m Trial 278 finished with value: 0.817133089407864 and parameters: {'n_estimators': 444, 'learning_rate': 0.05486200105591052, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 522}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:18,201]\u001b[0m Trial 279 finished with value: 0.8148169996066095 and parameters: {'n_estimators': 784, 'learning_rate': 0.06786720908538153, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 469}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:20,832]\u001b[0m Trial 280 finished with value: 0.8126087031990163 and parameters: {'n_estimators': 900, 'learning_rate': 0.06133048995872997, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 395}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:06:23,058]\u001b[0m Trial 281 finished with value: 0.8155301266573172 and parameters: {'n_estimators': 845, 'learning_rate': 0.05085741467906276, 'max_depth': 7, 'max_bin': 206, 'num_leaves': 443}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:25,403]\u001b[0m Trial 282 finished with value: 0.8124261057109722 and parameters: {'n_estimators': 873, 'learning_rate': 0.07660391133718031, 'max_depth': 12, 'max_bin': 194, 'num_leaves': 426}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:27,987]\u001b[0m Trial 283 finished with value: 0.8129882908958596 and parameters: {'n_estimators': 856, 'learning_rate': 0.05730698723323397, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 481}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:30,311]\u001b[0m Trial 284 finished with value: 0.8125272749535087 and parameters: {'n_estimators': 883, 'learning_rate': 0.0664506819493623, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 355}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:32,718]\u001b[0m Trial 285 finished with value: 0.8157139449301141 and parameters: {'n_estimators': 829, 'learning_rate': 0.07218197222579015, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 459}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:35,256]\u001b[0m Trial 286 finished with value: 0.8142224884597182 and parameters: {'n_estimators': 864, 'learning_rate': 0.05991676954850193, 'max_depth': 12, 'max_bin': 221, 'num_leaves': 502}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:38,280]\u001b[0m Trial 287 finished with value: 0.8206989547447344 and parameters: {'n_estimators': 886, 'learning_rate': 0.04421806603835189, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 410}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:41,039]\u001b[0m Trial 288 finished with value: 0.8104052041430713 and parameters: {'n_estimators': 839, 'learning_rate': 0.06344430311705636, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 563}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:43,145]\u001b[0m Trial 289 finished with value: 0.8134837496470094 and parameters: {'n_estimators': 871, 'learning_rate': 0.09444608288080956, 'max_depth': 11, 'max_bin': 196, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:45,976]\u001b[0m Trial 290 finished with value: 0.8151238161190284 and parameters: {'n_estimators': 854, 'learning_rate': 0.05419290736856316, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 453}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:48,396]\u001b[0m Trial 291 finished with value: 0.8110679185616732 and parameters: {'n_estimators': 884, 'learning_rate': 0.06924145729713714, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 373}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:49,986]\u001b[0m Trial 292 finished with value: 0.8078947008430297 and parameters: {'n_estimators': 801, 'learning_rate': 0.07996705241836458, 'max_depth': 6, 'max_bin': 213, 'num_leaves': 429}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:52,272]\u001b[0m Trial 293 finished with value: 0.8090043200489949 and parameters: {'n_estimators': 861, 'learning_rate': 0.0740151707568215, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 471}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:54,754]\u001b[0m Trial 294 finished with value: 0.8047832584572279 and parameters: {'n_estimators': 900, 'learning_rate': 0.058964583692789764, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 418}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:57,508]\u001b[0m Trial 295 finished with value: 0.8143668908523484 and parameters: {'n_estimators': 833, 'learning_rate': 0.049237800932399496, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:06:59,904]\u001b[0m Trial 296 finished with value: 0.814240261042728 and parameters: {'n_estimators': 877, 'learning_rate': 0.06549674729094063, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:01,936]\u001b[0m Trial 297 finished with value: 0.8068117289543772 and parameters: {'n_estimators': 850, 'learning_rate': 0.08415135356351353, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 389}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:04,361]\u001b[0m Trial 298 finished with value: 0.8133101139750616 and parameters: {'n_estimators': 815, 'learning_rate': 0.06975205019394018, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 517}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:06,321]\u001b[0m Trial 299 finished with value: 0.8075122339372303 and parameters: {'n_estimators': 887, 'learning_rate': 0.056400509229376575, 'max_depth': 5, 'max_bin': 191, 'num_leaves': 487}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 300.0\n",
      "\tBest value (f1_score): 0.8483\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_5 = lambda trial: objective_lgbm_CV(trial, X_trainSet5, Y_trainSet5, Y_trainSet5_class)\n",
    "study_lgbm.optimize(func_lgbm_5, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef058434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:11:47.160197Z",
     "iopub.status.busy": "2023-01-15T14:11:47.160050Z",
     "iopub.status.idle": "2023-01-15T14:11:47.375412Z",
     "shell.execute_reply": "2023-01-15T14:11:47.375003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4        Set5  \n",
      "0   342.000000  339.000000  \n",
      "1   160.000000  176.000000  \n",
      "2    65.000000   49.000000  \n",
      "3    28.000000   31.000000  \n",
      "4     0.843697    0.865546  \n",
      "5     0.840295    0.873711  \n",
      "6     0.924324    0.916216  \n",
      "7     0.711100    0.782200  \n",
      "8     0.880309    0.894459  \n",
      "9     0.840418    0.864342  \n",
      "10    0.827564    0.854637  \n",
      "11    0.817718    0.849219  \n",
      "12    0.662808    0.711081  \n",
      "13    0.851100    0.850200  \n",
      "14    0.817718    0.849219  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_5 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet5, Y_testSet5)]\n",
    "optimized_lgbm_5.fit(X_trainSet5,\n",
    "                Y_trainSet5,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_5 = optimized_lgbm_5.predict(X_testSet5)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet5, y_pred_lgbm_5)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet5, y_pred_lgbm_5)\n",
    "Precision = precision_score(Y_testSet5, y_pred_lgbm_5)\n",
    "Sensitivity = recall_score(Y_testSet5, y_pred_lgbm_5)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet5, y_pred_lgbm_5)      \n",
    "f1_scores_W = f1_score(Y_testSet5, y_pred_lgbm_5, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet5, y_pred_lgbm_5, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet5, y_pred_lgbm_5)\n",
    "MCC = matthews_corrcoef(Y_testSet5, y_pred_lgbm_5)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet5, y_pred_lgbm_5)\n",
    "\n",
    "\n",
    "Set5 = pd.DataFrame({ 'Set5':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set5'] = Set5\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "deb65060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:11:47.377014Z",
     "iopub.status.busy": "2023-01-15T14:11:47.376894Z",
     "iopub.status.idle": "2023-01-15T14:13:24.222644Z",
     "shell.execute_reply": "2023-01-15T14:13:24.222205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:07:09,454]\u001b[0m Trial 300 finished with value: 0.8181279437502846 and parameters: {'n_estimators': 864, 'learning_rate': 0.06262313885980557, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 439}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:11,755]\u001b[0m Trial 301 finished with value: 0.8147009386192264 and parameters: {'n_estimators': 844, 'learning_rate': 0.07547999790681284, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 462}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:14,466]\u001b[0m Trial 302 finished with value: 0.8190675763920388 and parameters: {'n_estimators': 875, 'learning_rate': 0.05327695901260655, 'max_depth': 11, 'max_bin': 213, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:17,076]\u001b[0m Trial 303 finished with value: 0.8190629676027024 and parameters: {'n_estimators': 900, 'learning_rate': 0.06670349231754451, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 447}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:19,873]\u001b[0m Trial 304 finished with value: 0.817998626617787 and parameters: {'n_estimators': 829, 'learning_rate': 0.06068138079196549, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 416}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:22,960]\u001b[0m Trial 305 finished with value: 0.8242163424948892 and parameters: {'n_estimators': 862, 'learning_rate': 0.04762111651251363, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 543}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:25,464]\u001b[0m Trial 306 finished with value: 0.8224032801472807 and parameters: {'n_estimators': 879, 'learning_rate': 0.06382382207696118, 'max_depth': 12, 'max_bin': 186, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:27,963]\u001b[0m Trial 307 finished with value: 0.8194381731276744 and parameters: {'n_estimators': 900, 'learning_rate': 0.07097476057581534, 'max_depth': 12, 'max_bin': 194, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:30,425]\u001b[0m Trial 308 finished with value: 0.8198927029105615 and parameters: {'n_estimators': 346, 'learning_rate': 0.08098677764389774, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 494}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:33,010]\u001b[0m Trial 309 finished with value: 0.8231487374989539 and parameters: {'n_estimators': 766, 'learning_rate': 0.058967823225522346, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 477}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:35,468]\u001b[0m Trial 310 finished with value: 0.8146755935725055 and parameters: {'n_estimators': 849, 'learning_rate': 0.054788062251790934, 'max_depth': 11, 'max_bin': 203, 'num_leaves': 60}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:39,101]\u001b[0m Trial 311 finished with value: 0.8214421922668951 and parameters: {'n_estimators': 885, 'learning_rate': 0.0372809424353935, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 400}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:41,798]\u001b[0m Trial 312 finished with value: 0.8237458394446383 and parameters: {'n_estimators': 867, 'learning_rate': 0.0673950464961367, 'max_depth': 12, 'max_bin': 181, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:44,342]\u001b[0m Trial 313 finished with value: 0.8204188739951433 and parameters: {'n_estimators': 819, 'learning_rate': 0.07601955825081573, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 432}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:47,162]\u001b[0m Trial 314 finished with value: 0.8173232640849862 and parameters: {'n_estimators': 842, 'learning_rate': 0.06348078104627085, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 509}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:49,607]\u001b[0m Trial 315 finished with value: 0.8187868405444794 and parameters: {'n_estimators': 873, 'learning_rate': 0.08869263781391633, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 412}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:52,236]\u001b[0m Trial 316 finished with value: 0.8251646660261812 and parameters: {'n_estimators': 854, 'learning_rate': 0.07271257766989273, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 456}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:55,032]\u001b[0m Trial 317 finished with value: 0.8217287497760217 and parameters: {'n_estimators': 888, 'learning_rate': 0.0518503853466352, 'max_depth': 12, 'max_bin': 222, 'num_leaves': 438}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:57,648]\u001b[0m Trial 318 finished with value: 0.8197117665048603 and parameters: {'n_estimators': 833, 'learning_rate': 0.058045576111863326, 'max_depth': 11, 'max_bin': 218, 'num_leaves': 379}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:07:59,905]\u001b[0m Trial 319 finished with value: 0.820484277586482 and parameters: {'n_estimators': 868, 'learning_rate': 0.06900355723509409, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 192}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:02,509]\u001b[0m Trial 320 finished with value: 0.8257676564801502 and parameters: {'n_estimators': 887, 'learning_rate': 0.06158932122462237, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 422}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:05,212]\u001b[0m Trial 321 finished with value: 0.8224845628242422 and parameters: {'n_estimators': 855, 'learning_rate': 0.06430725466713746, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 469}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:07,469]\u001b[0m Trial 322 finished with value: 0.8213190525441944 and parameters: {'n_estimators': 900, 'learning_rate': 0.07884020998453416, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:10,201]\u001b[0m Trial 323 finished with value: 0.8213048907753858 and parameters: {'n_estimators': 873, 'learning_rate': 0.05651955841915628, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 390}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:14,288]\u001b[0m Trial 324 finished with value: 0.8236354761588537 and parameters: {'n_estimators': 797, 'learning_rate': 0.04283289275517153, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:19,061]\u001b[0m Trial 325 finished with value: 0.8237178532768364 and parameters: {'n_estimators': 839, 'learning_rate': 0.026445856046964186, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:21,690]\u001b[0m Trial 326 finished with value: 0.8178287565659975 and parameters: {'n_estimators': 747, 'learning_rate': 0.06840193137491896, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 483}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:24,144]\u001b[0m Trial 327 finished with value: 0.8228689192773766 and parameters: {'n_estimators': 816, 'learning_rate': 0.07367288665651368, 'max_depth': 12, 'max_bin': 219, 'num_leaves': 456}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:27,217]\u001b[0m Trial 328 finished with value: 0.8179805953203474 and parameters: {'n_estimators': 861, 'learning_rate': 0.04918468471101478, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 345}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:30,129]\u001b[0m Trial 329 finished with value: 0.8261213069755646 and parameters: {'n_estimators': 884, 'learning_rate': 0.05996939676659661, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:33,174]\u001b[0m Trial 330 finished with value: 0.8181685827138111 and parameters: {'n_estimators': 852, 'learning_rate': 0.05342218376339054, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 533}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:08:35,512]\u001b[0m Trial 331 finished with value: 0.8232412227670123 and parameters: {'n_estimators': 784, 'learning_rate': 0.06592085649195926, 'max_depth': 11, 'max_bin': 204, 'num_leaves': 467}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:37,872]\u001b[0m Trial 332 finished with value: 0.8235350566935299 and parameters: {'n_estimators': 875, 'learning_rate': 0.07173362652178786, 'max_depth': 12, 'max_bin': 188, 'num_leaves': 364}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:40,264]\u001b[0m Trial 333 finished with value: 0.8184155981440417 and parameters: {'n_estimators': 885, 'learning_rate': 0.08333491010478458, 'max_depth': 12, 'max_bin': 224, 'num_leaves': 420}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:43,214]\u001b[0m Trial 334 finished with value: 0.8238851828102038 and parameters: {'n_estimators': 832, 'learning_rate': 0.05907666071745443, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 407}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:44,955]\u001b[0m Trial 335 finished with value: 0.8132968248703506 and parameters: {'n_estimators': 72, 'learning_rate': 0.0775957424077659, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 499}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:47,888]\u001b[0m Trial 336 finished with value: 0.8204180815343548 and parameters: {'n_estimators': 899, 'learning_rate': 0.06357216721234187, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 435}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:51,585]\u001b[0m Trial 337 finished with value: 0.8248978619747257 and parameters: {'n_estimators': 859, 'learning_rate': 0.046464992095206874, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:54,400]\u001b[0m Trial 338 finished with value: 0.8179726365491582 and parameters: {'n_estimators': 872, 'learning_rate': 0.06746318043591419, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 475}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:08:57,402]\u001b[0m Trial 339 finished with value: 0.8185705689629966 and parameters: {'n_estimators': 850, 'learning_rate': 0.055887437125131195, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:00,163]\u001b[0m Trial 340 finished with value: 0.8207278195440539 and parameters: {'n_estimators': 900, 'learning_rate': 0.061439442282717915, 'max_depth': 11, 'max_bin': 191, 'num_leaves': 459}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:03,179]\u001b[0m Trial 341 finished with value: 0.8185103486003495 and parameters: {'n_estimators': 809, 'learning_rate': 0.05185129206992458, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 516}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:05,880]\u001b[0m Trial 342 finished with value: 0.8179431077896503 and parameters: {'n_estimators': 839, 'learning_rate': 0.06985862216520906, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 441}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:08,314]\u001b[0m Trial 343 finished with value: 0.8188541468791444 and parameters: {'n_estimators': 872, 'learning_rate': 0.08646229491498979, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 409}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:11,004]\u001b[0m Trial 344 finished with value: 0.8207133605102201 and parameters: {'n_estimators': 886, 'learning_rate': 0.0652183300585283, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 491}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:13,497]\u001b[0m Trial 345 finished with value: 0.8193712991065658 and parameters: {'n_estimators': 861, 'learning_rate': 0.07467002615585201, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 385}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:16,521]\u001b[0m Trial 346 finished with value: 0.8178949279587384 and parameters: {'n_estimators': 825, 'learning_rate': 0.056681923930120295, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 420}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:19,300]\u001b[0m Trial 347 finished with value: 0.8184991644304447 and parameters: {'n_estimators': 884, 'learning_rate': 0.0609285324236663, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 447}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:21,812]\u001b[0m Trial 348 finished with value: 0.8231682475773573 and parameters: {'n_estimators': 844, 'learning_rate': 0.07082522737779794, 'max_depth': 11, 'max_bin': 201, 'num_leaves': 321}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:24,229]\u001b[0m Trial 349 finished with value: 0.8218202492067777 and parameters: {'n_estimators': 871, 'learning_rate': 0.07866226967349671, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 464}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 350.0\n",
      "\tBest value (f1_score): 0.848338\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_6 = lambda trial: objective_lgbm_CV(trial, X_trainSet6, Y_trainSet6, Y_trainSet6_class)\n",
    "study_lgbm.optimize(func_lgbm_6, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.6f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d232cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:13:24.224389Z",
     "iopub.status.busy": "2023-01-15T14:13:24.224239Z",
     "iopub.status.idle": "2023-01-15T14:13:24.495814Z",
     "shell.execute_reply": "2023-01-15T14:13:24.495381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4        Set5        Set6  \n",
      "0   342.000000  339.000000  327.000000  \n",
      "1   160.000000  176.000000  171.000000  \n",
      "2    65.000000   49.000000   61.000000  \n",
      "3    28.000000   31.000000   36.000000  \n",
      "4     0.843697    0.865546    0.836975  \n",
      "5     0.840295    0.873711    0.842784  \n",
      "6     0.924324    0.916216    0.900826  \n",
      "7     0.711100    0.782200    0.737100  \n",
      "8     0.880309    0.894459    0.870839  \n",
      "9     0.840418    0.864342    0.835046  \n",
      "10    0.827564    0.854637    0.824941  \n",
      "11    0.817718    0.849219    0.818948  \n",
      "12    0.662808    0.711081    0.653199  \n",
      "13    0.851100    0.850200    0.826100  \n",
      "14    0.817718    0.849219    0.818948  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_6 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet6, Y_testSet6)]\n",
    "optimized_lgbm_6.fit(X_trainSet6,\n",
    "                Y_trainSet6,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_6 = optimized_lgbm_6.predict(X_testSet6)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet6, y_pred_lgbm_6)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet6, y_pred_lgbm_6)\n",
    "Precision = precision_score(Y_testSet6, y_pred_lgbm_6)\n",
    "Sensitivity = recall_score(Y_testSet6, y_pred_lgbm_6)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet6, y_pred_lgbm_6)      \n",
    "f1_scores_W = f1_score(Y_testSet6, y_pred_lgbm_6, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet6, y_pred_lgbm_6, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet6, y_pred_lgbm_6)\n",
    "MCC = matthews_corrcoef(Y_testSet6, y_pred_lgbm_6)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet6, y_pred_lgbm_6)\n",
    "\n",
    "\n",
    "Set6 = pd.DataFrame({ 'Set6':[ np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set6'] = Set6\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a5d4959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:13:24.497736Z",
     "iopub.status.busy": "2023-01-15T14:13:24.497464Z",
     "iopub.status.idle": "2023-01-15T14:14:53.033944Z",
     "shell.execute_reply": "2023-01-15T14:14:53.033608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:09:27,877]\u001b[0m Trial 350 finished with value: 0.818162324526074 and parameters: {'n_estimators': 717, 'learning_rate': 0.052015492626806235, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 430}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:30,599]\u001b[0m Trial 351 finished with value: 0.8162283644911617 and parameters: {'n_estimators': 858, 'learning_rate': 0.06514720370530541, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 396}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:33,717]\u001b[0m Trial 352 finished with value: 0.8181280618846578 and parameters: {'n_estimators': 887, 'learning_rate': 0.05810619110545241, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 476}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:36,749]\u001b[0m Trial 353 finished with value: 0.8182316827967939 and parameters: {'n_estimators': 845, 'learning_rate': 0.0737131432966234, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 448}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:39,571]\u001b[0m Trial 354 finished with value: 0.816482046148014 and parameters: {'n_estimators': 825, 'learning_rate': 0.062338363432886304, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 418}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:42,421]\u001b[0m Trial 355 finished with value: 0.8232934747126175 and parameters: {'n_estimators': 870, 'learning_rate': 0.06773147485008532, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:45,932]\u001b[0m Trial 356 finished with value: 0.8218612671274632 and parameters: {'n_estimators': 900, 'learning_rate': 0.04796837464445879, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:49,098]\u001b[0m Trial 357 finished with value: 0.8220975895351026 and parameters: {'n_estimators': 859, 'learning_rate': 0.05556493025959276, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 406}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:51,699]\u001b[0m Trial 358 finished with value: 0.8188513482074423 and parameters: {'n_estimators': 877, 'learning_rate': 0.08001942439018941, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 552}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:54,467]\u001b[0m Trial 359 finished with value: 0.8202058673421145 and parameters: {'n_estimators': 841, 'learning_rate': 0.07027045622652875, 'max_depth': 11, 'max_bin': 221, 'num_leaves': 432}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:09:57,601]\u001b[0m Trial 360 finished with value: 0.8250880721799071 and parameters: {'n_estimators': 884, 'learning_rate': 0.06078507432919811, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 452}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:00,308]\u001b[0m Trial 361 finished with value: 0.8151023191544035 and parameters: {'n_estimators': 798, 'learning_rate': 0.07500911815292033, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 486}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:02,677]\u001b[0m Trial 362 finished with value: 0.8164373348198755 and parameters: {'n_estimators': 861, 'learning_rate': 0.06485369166377492, 'max_depth': 8, 'max_bin': 184, 'num_leaves': 503}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:06,011]\u001b[0m Trial 363 finished with value: 0.8235249517557406 and parameters: {'n_estimators': 900, 'learning_rate': 0.05490401855555646, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 368}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:08,888]\u001b[0m Trial 364 finished with value: 0.8180998691194992 and parameters: {'n_estimators': 821, 'learning_rate': 0.059585757490212214, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 417}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:11,156]\u001b[0m Trial 365 finished with value: 0.8250319112872149 and parameters: {'n_estimators': 875, 'learning_rate': 0.09755627994302299, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 286}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:13,763]\u001b[0m Trial 366 finished with value: 0.8192911564223193 and parameters: {'n_estimators': 858, 'learning_rate': 0.06835965636670932, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 449}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:16,495]\u001b[0m Trial 367 finished with value: 0.8190275661655072 and parameters: {'n_estimators': 840, 'learning_rate': 0.05082929429528682, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 434}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:18,980]\u001b[0m Trial 368 finished with value: 0.8234686927481117 and parameters: {'n_estimators': 888, 'learning_rate': 0.08213584768366819, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 524}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:21,989]\u001b[0m Trial 369 finished with value: 0.8239444038406312 and parameters: {'n_estimators': 870, 'learning_rate': 0.06445591956023576, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 396}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:24,554]\u001b[0m Trial 370 finished with value: 0.8169616828288314 and parameters: {'n_estimators': 850, 'learning_rate': 0.07210386867218982, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:27,858]\u001b[0m Trial 371 finished with value: 0.8202154602880872 and parameters: {'n_estimators': 775, 'learning_rate': 0.04406241013795472, 'max_depth': 11, 'max_bin': 215, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:30,516]\u001b[0m Trial 372 finished with value: 0.816317096849561 and parameters: {'n_estimators': 900, 'learning_rate': 0.05798836356413509, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 473}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:32,929]\u001b[0m Trial 373 finished with value: 0.8191034782450813 and parameters: {'n_estimators': 809, 'learning_rate': 0.07773268015778421, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 441}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:35,772]\u001b[0m Trial 374 finished with value: 0.8181017251476647 and parameters: {'n_estimators': 882, 'learning_rate': 0.0626343375411217, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 410}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:39,113]\u001b[0m Trial 375 finished with value: 0.818173193006649 and parameters: {'n_estimators': 829, 'learning_rate': 0.05397619602419909, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 385}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:41,427]\u001b[0m Trial 376 finished with value: 0.8180748010239626 and parameters: {'n_estimators': 865, 'learning_rate': 0.06716101468264635, 'max_depth': 7, 'max_bin': 205, 'num_leaves': 452}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:43,860]\u001b[0m Trial 377 finished with value: 0.8213490404228571 and parameters: {'n_estimators': 884, 'learning_rate': 0.07270404081764525, 'max_depth': 12, 'max_bin': 224, 'num_leaves': 426}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:46,680]\u001b[0m Trial 378 finished with value: 0.8175320104034742 and parameters: {'n_estimators': 493, 'learning_rate': 0.060012340169818976, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 483}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:49,334]\u001b[0m Trial 379 finished with value: 0.8229753691110198 and parameters: {'n_estimators': 844, 'learning_rate': 0.06850067830343161, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 441}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:52,455]\u001b[0m Trial 380 finished with value: 0.8231803822528623 and parameters: {'n_estimators': 862, 'learning_rate': 0.049357641194444524, 'max_depth': 11, 'max_bin': 213, 'num_leaves': 237}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:10:54,685]\u001b[0m Trial 381 finished with value: 0.8261517202103553 and parameters: {'n_estimators': 885, 'learning_rate': 0.08744095239502114, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 462}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:10:57,583]\u001b[0m Trial 382 finished with value: 0.8189519749310117 and parameters: {'n_estimators': 854, 'learning_rate': 0.05645513959879336, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:00,416]\u001b[0m Trial 383 finished with value: 0.8189292308666369 and parameters: {'n_estimators': 833, 'learning_rate': 0.07511550475618799, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 508}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:03,394]\u001b[0m Trial 384 finished with value: 0.8181431125314169 and parameters: {'n_estimators': 900, 'learning_rate': 0.06399139522524422, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 418}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:05,671]\u001b[0m Trial 385 finished with value: 0.8209635815396371 and parameters: {'n_estimators': 873, 'learning_rate': 0.1100171688293394, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 436}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:08,579]\u001b[0m Trial 386 finished with value: 0.8191011465258324 and parameters: {'n_estimators': 872, 'learning_rate': 0.06016710061826309, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 457}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:10,635]\u001b[0m Trial 387 finished with value: 0.8130403314460446 and parameters: {'n_estimators': 848, 'learning_rate': 0.07053291982470736, 'max_depth': 5, 'max_bin': 199, 'num_leaves': 471}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:13,933]\u001b[0m Trial 388 finished with value: 0.8192618586024514 and parameters: {'n_estimators': 886, 'learning_rate': 0.05350801604280693, 'max_depth': 12, 'max_bin': 187, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:16,841]\u001b[0m Trial 389 finished with value: 0.8204644224886912 and parameters: {'n_estimators': 734, 'learning_rate': 0.06362688193984184, 'max_depth': 11, 'max_bin': 212, 'num_leaves': 490}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:19,534]\u001b[0m Trial 390 finished with value: 0.8229622980253151 and parameters: {'n_estimators': 808, 'learning_rate': 0.0669266594559032, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 378}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:22,204]\u001b[0m Trial 391 finished with value: 0.81855969601748 and parameters: {'n_estimators': 860, 'learning_rate': 0.07650296144290432, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 416}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:24,321]\u001b[0m Trial 392 finished with value: 0.8169129373314707 and parameters: {'n_estimators': 185, 'learning_rate': 0.08239928511157217, 'max_depth': 9, 'max_bin': 216, 'num_leaves': 533}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:26,991]\u001b[0m Trial 393 finished with value: 0.8169818032534744 and parameters: {'n_estimators': 837, 'learning_rate': 0.05700558954385145, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:29,951]\u001b[0m Trial 394 finished with value: 0.8165888033820525 and parameters: {'n_estimators': 871, 'learning_rate': 0.04696880916790455, 'max_depth': 12, 'max_bin': 220, 'num_leaves': 163}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:32,604]\u001b[0m Trial 395 finished with value: 0.8159234686738894 and parameters: {'n_estimators': 756, 'learning_rate': 0.06225774049275909, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 425}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:34,926]\u001b[0m Trial 396 finished with value: 0.8203306949175999 and parameters: {'n_estimators': 823, 'learning_rate': 0.07237560093016882, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 396}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:37,424]\u001b[0m Trial 397 finished with value: 0.8164596206707676 and parameters: {'n_estimators': 383, 'learning_rate': 0.06619022942853192, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:40,311]\u001b[0m Trial 398 finished with value: 0.8169553511781558 and parameters: {'n_estimators': 900, 'learning_rate': 0.05165669186898, 'max_depth': 11, 'max_bin': 206, 'num_leaves': 465}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:42,969]\u001b[0m Trial 399 finished with value: 0.8143171146928092 and parameters: {'n_estimators': 850, 'learning_rate': 0.05889367402402155, 'max_depth': 12, 'max_bin': 227, 'num_leaves': 411}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 400.0\n",
      "\tBest value (f1_score): 0.8483381\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_7 = lambda trial: objective_lgbm_CV(trial, X_trainSet7, Y_trainSet7, Y_trainSet7_class)\n",
    "study_lgbm.optimize(func_lgbm_7, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.7f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20febb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:14:53.035788Z",
     "iopub.status.busy": "2023-01-15T14:14:53.035511Z",
     "iopub.status.idle": "2023-01-15T14:14:53.295205Z",
     "shell.execute_reply": "2023-01-15T14:14:53.294831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4        Set5        Set6        Set7  \n",
      "0   342.000000  339.000000  327.000000  334.000000  \n",
      "1   160.000000  176.000000  171.000000  175.000000  \n",
      "2    65.000000   49.000000   61.000000   46.000000  \n",
      "3    28.000000   31.000000   36.000000   40.000000  \n",
      "4     0.843697    0.865546    0.836975    0.855462  \n",
      "5     0.840295    0.873711    0.842784    0.878947  \n",
      "6     0.924324    0.916216    0.900826    0.893048  \n",
      "7     0.711100    0.782200    0.737100    0.791900  \n",
      "8     0.880309    0.894459    0.870839    0.885942  \n",
      "9     0.840418    0.864342    0.835046    0.855043  \n",
      "10    0.827564    0.854637    0.824941    0.844347  \n",
      "11    0.817718    0.849219    0.818948    0.842452  \n",
      "12    0.662808    0.711081    0.653199    0.688890  \n",
      "13    0.851100    0.850200    0.826100    0.814000  \n",
      "14    0.817718    0.849219    0.818948    0.842452  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_7 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet7, Y_testSet7)]\n",
    "optimized_lgbm_7.fit(X_trainSet7,\n",
    "                Y_trainSet7,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_7 = optimized_lgbm_7.predict(X_testSet7)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet7, y_pred_lgbm_7)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet7, y_pred_lgbm_7)\n",
    "Precision = precision_score(Y_testSet7, y_pred_lgbm_7)\n",
    "Sensitivity = recall_score(Y_testSet7, y_pred_lgbm_7)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet7, y_pred_lgbm_7)      \n",
    "f1_scores_W = f1_score(Y_testSet7, y_pred_lgbm_7, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet7, y_pred_lgbm_7, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet7, y_pred_lgbm_7)\n",
    "MCC = matthews_corrcoef(Y_testSet7, y_pred_lgbm_7)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet7, y_pred_lgbm_7)\n",
    "\n",
    "\n",
    "Set7 = pd.DataFrame({ 'Set7':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set7'] = Set7\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2858184a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:14:53.296780Z",
     "iopub.status.busy": "2023-01-15T14:14:53.296660Z",
     "iopub.status.idle": "2023-01-15T14:16:32.486663Z",
     "shell.execute_reply": "2023-01-15T14:16:32.486318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:11:46,216]\u001b[0m Trial 400 finished with value: 0.829980288185044 and parameters: {'n_estimators': 885, 'learning_rate': 0.0775681066216226, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:49,146]\u001b[0m Trial 401 finished with value: 0.8248061921456911 and parameters: {'n_estimators': 873, 'learning_rate': 0.0689306923851994, 'max_depth': 12, 'max_bin': 210, 'num_leaves': 494}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:52,290]\u001b[0m Trial 402 finished with value: 0.8266372757940935 and parameters: {'n_estimators': 861, 'learning_rate': 0.05461843821161467, 'max_depth': 12, 'max_bin': 167, 'num_leaves': 476}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:55,524]\u001b[0m Trial 403 finished with value: 0.83115741451254 and parameters: {'n_estimators': 795, 'learning_rate': 0.06264024167821139, 'max_depth': 12, 'max_bin': 190, 'num_leaves': 430}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:11:58,498]\u001b[0m Trial 404 finished with value: 0.8351968505935501 and parameters: {'n_estimators': 834, 'learning_rate': 0.058242451823311774, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 358}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:01,546]\u001b[0m Trial 405 finished with value: 0.8317939763649024 and parameters: {'n_estimators': 886, 'learning_rate': 0.07026043573311547, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 445}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:04,771]\u001b[0m Trial 406 finished with value: 0.8342230657057679 and parameters: {'n_estimators': 850, 'learning_rate': 0.0651055635365175, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 516}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:06,843]\u001b[0m Trial 407 finished with value: 0.8326875600770057 and parameters: {'n_estimators': 868, 'learning_rate': 0.12777072934588016, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 401}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:09,619]\u001b[0m Trial 408 finished with value: 0.8318265612890805 and parameters: {'n_estimators': 888, 'learning_rate': 0.07506048558403396, 'max_depth': 11, 'max_bin': 212, 'num_leaves': 458}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:12,257]\u001b[0m Trial 409 finished with value: 0.8329304526746819 and parameters: {'n_estimators': 900, 'learning_rate': 0.0851868656554002, 'max_depth': 12, 'max_bin': 196, 'num_leaves': 424}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:15,616]\u001b[0m Trial 410 finished with value: 0.8302319351252162 and parameters: {'n_estimators': 818, 'learning_rate': 0.05015329511441892, 'max_depth': 12, 'max_bin': 216, 'num_leaves': 544}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:18,328]\u001b[0m Trial 411 finished with value: 0.8235356102441239 and parameters: {'n_estimators': 858, 'learning_rate': 0.08087146177041979, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 440}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:21,748]\u001b[0m Trial 412 finished with value: 0.8365430675815485 and parameters: {'n_estimators': 317, 'learning_rate': 0.04173428299473606, 'max_depth': 12, 'max_bin': 222, 'num_leaves': 384}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:24,740]\u001b[0m Trial 413 finished with value: 0.8291003848367817 and parameters: {'n_estimators': 874, 'learning_rate': 0.06089616538901034, 'max_depth': 12, 'max_bin': 176, 'num_leaves': 475}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:27,922]\u001b[0m Trial 414 finished with value: 0.82993857467794 and parameters: {'n_estimators': 842, 'learning_rate': 0.05619349596365475, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 423}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:30,948]\u001b[0m Trial 415 finished with value: 0.8281059604360493 and parameters: {'n_estimators': 883, 'learning_rate': 0.06706050256886724, 'max_depth': 12, 'max_bin': 192, 'num_leaves': 410}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:33,213]\u001b[0m Trial 416 finished with value: 0.8325661360327292 and parameters: {'n_estimators': 134, 'learning_rate': 0.07300821720913404, 'max_depth': 11, 'max_bin': 202, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:40,658]\u001b[0m Trial 417 finished with value: 0.8305813756455838 and parameters: {'n_estimators': 900, 'learning_rate': 0.015973610079614176, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 438}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:43,846]\u001b[0m Trial 418 finished with value: 0.8293489482087752 and parameters: {'n_estimators': 862, 'learning_rate': 0.06266971852925043, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 465}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:46,906]\u001b[0m Trial 419 finished with value: 0.8303198197770124 and parameters: {'n_estimators': 828, 'learning_rate': 0.05223869039277503, 'max_depth': 12, 'max_bin': 259, 'num_leaves': 502}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:49,667]\u001b[0m Trial 420 finished with value: 0.8288371669450999 and parameters: {'n_estimators': 876, 'learning_rate': 0.06999432507470399, 'max_depth': 12, 'max_bin': 254, 'num_leaves': 447}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:52,827]\u001b[0m Trial 421 finished with value: 0.829098497446233 and parameters: {'n_estimators': 849, 'learning_rate': 0.059039936049140304, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 484}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:56,617]\u001b[0m Trial 422 finished with value: 0.8274949318249488 and parameters: {'n_estimators': 868, 'learning_rate': 0.04579632099724334, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 393}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:12:58,487]\u001b[0m Trial 423 finished with value: 0.8164391375087835 and parameters: {'n_estimators': 886, 'learning_rate': 0.06555395173734954, 'max_depth': 4, 'max_bin': 210, 'num_leaves': 416}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:02,122]\u001b[0m Trial 424 finished with value: 0.8344028662283653 and parameters: {'n_estimators': 787, 'learning_rate': 0.055182576883733084, 'max_depth': 12, 'max_bin': 195, 'num_leaves': 431}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:05,075]\u001b[0m Trial 425 finished with value: 0.8323923106891401 and parameters: {'n_estimators': 413, 'learning_rate': 0.07855696296310216, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 464}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:08,123]\u001b[0m Trial 426 finished with value: 0.8377884365223178 and parameters: {'n_estimators': 840, 'learning_rate': 0.061347587413871675, 'max_depth': 11, 'max_bin': 217, 'num_leaves': 372}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:11,051]\u001b[0m Trial 427 finished with value: 0.8360864697921796 and parameters: {'n_estimators': 251, 'learning_rate': 0.07141140507602985, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 338}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:13,278]\u001b[0m Trial 428 finished with value: 0.8282817639527279 and parameters: {'n_estimators': 810, 'learning_rate': 0.09256357723482662, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 442}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:16,183]\u001b[0m Trial 429 finished with value: 0.8360838160348949 and parameters: {'n_estimators': 861, 'learning_rate': 0.06840326011721197, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 423}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:19,476]\u001b[0m Trial 430 finished with value: 0.8278355721894197 and parameters: {'n_estimators': 885, 'learning_rate': 0.05732142332251623, 'max_depth': 12, 'max_bin': 187, 'num_leaves': 400}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:13:22,243]\u001b[0m Trial 431 finished with value: 0.8324881253996415 and parameters: {'n_estimators': 900, 'learning_rate': 0.07509480391001157, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:25,480]\u001b[0m Trial 432 finished with value: 0.8349435323583393 and parameters: {'n_estimators': 848, 'learning_rate': 0.06460870948677172, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 480}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:28,929]\u001b[0m Trial 433 finished with value: 0.8332158429876071 and parameters: {'n_estimators': 872, 'learning_rate': 0.053154872972291316, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 411}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:31,883]\u001b[0m Trial 434 finished with value: 0.8282035861348274 and parameters: {'n_estimators': 828, 'learning_rate': 0.059393752159721445, 'max_depth': 12, 'max_bin': 221, 'num_leaves': 434}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:35,195]\u001b[0m Trial 435 finished with value: 0.8263484387993097 and parameters: {'n_estimators': 858, 'learning_rate': 0.04804906017973707, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 452}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:37,229]\u001b[0m Trial 436 finished with value: 0.8249939642569425 and parameters: {'n_estimators': 882, 'learning_rate': 0.06678196074476403, 'max_depth': 6, 'max_bin': 196, 'num_leaves': 494}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:39,968]\u001b[0m Trial 437 finished with value: 0.826470273293688 and parameters: {'n_estimators': 768, 'learning_rate': 0.08091270037656287, 'max_depth': 11, 'max_bin': 192, 'num_leaves': 513}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:42,628]\u001b[0m Trial 438 finished with value: 0.8384093880541592 and parameters: {'n_estimators': 872, 'learning_rate': 0.0633042599421221, 'max_depth': 12, 'max_bin': 270, 'num_leaves': 471}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:45,242]\u001b[0m Trial 439 finished with value: 0.8395742955733072 and parameters: {'n_estimators': 835, 'learning_rate': 0.0715371421030934, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:47,544]\u001b[0m Trial 440 finished with value: 0.8326164858940583 and parameters: {'n_estimators': 811, 'learning_rate': 0.07639556076461596, 'max_depth': 9, 'max_bin': 205, 'num_leaves': 442}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:50,090]\u001b[0m Trial 441 finished with value: 0.8281427898181777 and parameters: {'n_estimators': 828, 'learning_rate': 0.07248710475108538, 'max_depth': 12, 'max_bin': 286, 'num_leaves': 529}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:52,941]\u001b[0m Trial 442 finished with value: 0.8291642398874824 and parameters: {'n_estimators': 800, 'learning_rate': 0.07417043894489328, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:55,868]\u001b[0m Trial 443 finished with value: 0.8341008340514516 and parameters: {'n_estimators': 845, 'learning_rate': 0.06963868165697451, 'max_depth': 12, 'max_bin': 182, 'num_leaves': 459}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:13:58,536]\u001b[0m Trial 444 finished with value: 0.8273981770380864 and parameters: {'n_estimators': 827, 'learning_rate': 0.07835715833293926, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 437}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:01,594]\u001b[0m Trial 445 finished with value: 0.8330968260206388 and parameters: {'n_estimators': 845, 'learning_rate': 0.0691387038382066, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 415}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:04,246]\u001b[0m Trial 446 finished with value: 0.8274966797740912 and parameters: {'n_estimators': 815, 'learning_rate': 0.08227440766350434, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 428}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:06,848]\u001b[0m Trial 447 finished with value: 0.8299637606254775 and parameters: {'n_estimators': 857, 'learning_rate': 0.07278246370918381, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:09,986]\u001b[0m Trial 448 finished with value: 0.830663246757649 and parameters: {'n_estimators': 780, 'learning_rate': 0.05595213343896218, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 470}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:12,543]\u001b[0m Trial 449 finished with value: 0.8280307816257071 and parameters: {'n_estimators': 900, 'learning_rate': 0.08572340993448492, 'max_depth': 11, 'max_bin': 207, 'num_leaves': 554}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 450.0\n",
      "\tBest value (f1_score): 0.84833806\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_8 = lambda trial: objective_lgbm_CV(trial, X_trainSet8, Y_trainSet8, Y_trainSet8_class)\n",
    "study_lgbm.optimize(func_lgbm_8, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.8f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd869ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:16:32.488344Z",
     "iopub.status.busy": "2023-01-15T14:16:32.488125Z",
     "iopub.status.idle": "2023-01-15T14:16:32.733719Z",
     "shell.execute_reply": "2023-01-15T14:16:32.733422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8  \n",
      "0   342.000000  339.000000  327.000000  334.000000  333.000000  \n",
      "1   160.000000  176.000000  171.000000  175.000000  166.000000  \n",
      "2    65.000000   49.000000   61.000000   46.000000   61.000000  \n",
      "3    28.000000   31.000000   36.000000   40.000000   35.000000  \n",
      "4     0.843697    0.865546    0.836975    0.855462    0.838655  \n",
      "5     0.840295    0.873711    0.842784    0.878947    0.845178  \n",
      "6     0.924324    0.916216    0.900826    0.893048    0.904891  \n",
      "7     0.711100    0.782200    0.737100    0.791900    0.731300  \n",
      "8     0.880309    0.894459    0.870839    0.885942    0.874016  \n",
      "9     0.840418    0.864342    0.835046    0.855043    0.836507  \n",
      "10    0.827564    0.854637    0.824941    0.844347    0.824858  \n",
      "11    0.817718    0.849219    0.818948    0.842452    0.818084  \n",
      "12    0.662808    0.711081    0.653199    0.688890    0.653376  \n",
      "13    0.851100    0.850200    0.826100    0.814000    0.825900  \n",
      "14    0.817718    0.849219    0.818948    0.842452    0.818084  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_8 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet8, Y_testSet8)]\n",
    "optimized_lgbm_8.fit(X_trainSet8,\n",
    "                Y_trainSet8,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_8 = optimized_lgbm_8.predict(X_testSet8)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet8, y_pred_lgbm_8)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet8, y_pred_lgbm_8)\n",
    "Precision = precision_score(Y_testSet8, y_pred_lgbm_8)\n",
    "Sensitivity = recall_score(Y_testSet8, y_pred_lgbm_8)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet8, y_pred_lgbm_8)      \n",
    "f1_scores_W = f1_score(Y_testSet8, y_pred_lgbm_8, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet8, y_pred_lgbm_8, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet8, y_pred_lgbm_8)\n",
    "MCC = matthews_corrcoef(Y_testSet8, y_pred_lgbm_8)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet8, y_pred_lgbm_8)\n",
    "\n",
    "\n",
    "Set8 = pd.DataFrame({ 'Set8':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set8'] = Set8\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d97912a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:16:32.735086Z",
     "iopub.status.busy": "2023-01-15T14:16:32.734976Z",
     "iopub.status.idle": "2023-01-15T14:18:26.799971Z",
     "shell.execute_reply": "2023-01-15T14:18:26.799648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:14:15,294]\u001b[0m Trial 450 finished with value: 0.8220486858751631 and parameters: {'n_estimators': 838, 'learning_rate': 0.06494632091675356, 'max_depth': 8, 'max_bin': 211, 'num_leaves': 458}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:18,526]\u001b[0m Trial 451 finished with value: 0.8179752743237041 and parameters: {'n_estimators': 863, 'learning_rate': 0.04982130821980466, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:21,079]\u001b[0m Trial 452 finished with value: 0.8216063994169763 and parameters: {'n_estimators': 882, 'learning_rate': 0.06068290684362414, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 420}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:22,729]\u001b[0m Trial 453 finished with value: 0.804548621426094 and parameters: {'n_estimators': 848, 'learning_rate': 0.06749304459224753, 'max_depth': 3, 'max_bin': 214, 'num_leaves': 486}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:25,400]\u001b[0m Trial 454 finished with value: 0.8203076764402468 and parameters: {'n_estimators': 867, 'learning_rate': 0.07590981984305724, 'max_depth': 12, 'max_bin': 189, 'num_leaves': 436}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:27,652]\u001b[0m Trial 455 finished with value: 0.816523899755493 and parameters: {'n_estimators': 827, 'learning_rate': 0.07098587747487135, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 463}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:30,382]\u001b[0m Trial 456 finished with value: 0.8168694476067018 and parameters: {'n_estimators': 884, 'learning_rate': 0.05458914902701753, 'max_depth': 12, 'max_bin': 194, 'num_leaves': 413}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:33,138]\u001b[0m Trial 457 finished with value: 0.8252565829196434 and parameters: {'n_estimators': 858, 'learning_rate': 0.059604560260208925, 'max_depth': 12, 'max_bin': 200, 'num_leaves': 446}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:35,237]\u001b[0m Trial 458 finished with value: 0.8224479290951404 and parameters: {'n_estimators': 838, 'learning_rate': 0.08847991050944223, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 505}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:37,740]\u001b[0m Trial 459 finished with value: 0.8242820388660125 and parameters: {'n_estimators': 874, 'learning_rate': 0.06459355717126916, 'max_depth': 11, 'max_bin': 212, 'num_leaves': 431}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:39,773]\u001b[0m Trial 460 finished with value: 0.8263632337886776 and parameters: {'n_estimators': 800, 'learning_rate': 0.1209486412521712, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 478}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:42,337]\u001b[0m Trial 461 finished with value: 0.8214540402088689 and parameters: {'n_estimators': 887, 'learning_rate': 0.08039821622084048, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 409}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:45,549]\u001b[0m Trial 462 finished with value: 0.8197322576005519 and parameters: {'n_estimators': 900, 'learning_rate': 0.04332392822654963, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 456}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:48,073]\u001b[0m Trial 463 finished with value: 0.8196188889162782 and parameters: {'n_estimators': 857, 'learning_rate': 0.06820230135713917, 'max_depth': 12, 'max_bin': 197, 'num_leaves': 427}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:50,572]\u001b[0m Trial 464 finished with value: 0.826360529508937 and parameters: {'n_estimators': 817, 'learning_rate': 0.07425846271510317, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 393}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:53,845]\u001b[0m Trial 465 finished with value: 0.8231963592299174 and parameters: {'n_estimators': 873, 'learning_rate': 0.05124074176330894, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 444}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:56,974]\u001b[0m Trial 466 finished with value: 0.8225029077041637 and parameters: {'n_estimators': 835, 'learning_rate': 0.0580305177823788, 'max_depth': 12, 'max_bin': 202, 'num_leaves': 523}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:14:59,561]\u001b[0m Trial 467 finished with value: 0.8190334281208195 and parameters: {'n_estimators': 702, 'learning_rate': 0.06388800530347528, 'max_depth': 12, 'max_bin': 218, 'num_leaves': 468}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:02,008]\u001b[0m Trial 468 finished with value: 0.8192555284906726 and parameters: {'n_estimators': 854, 'learning_rate': 0.07179274348955796, 'max_depth': 11, 'max_bin': 185, 'num_leaves': 424}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:04,566]\u001b[0m Trial 469 finished with value: 0.8221871197428687 and parameters: {'n_estimators': 887, 'learning_rate': 0.07772277608720034, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 451}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:07,654]\u001b[0m Trial 470 finished with value: 0.812562491211442 and parameters: {'n_estimators': 870, 'learning_rate': 0.06193815302645001, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 408}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:11,669]\u001b[0m Trial 471 finished with value: 0.8144051209564033 and parameters: {'n_estimators': 900, 'learning_rate': 0.03853081385382608, 'max_depth': 12, 'max_bin': 205, 'num_leaves': 494}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:13,985]\u001b[0m Trial 472 finished with value: 0.8248395479407202 and parameters: {'n_estimators': 727, 'learning_rate': 0.09725511853608104, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 436}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:16,966]\u001b[0m Trial 473 finished with value: 0.8237726010582997 and parameters: {'n_estimators': 847, 'learning_rate': 0.055729667753678304, 'max_depth': 12, 'max_bin': 193, 'num_leaves': 476}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:19,627]\u001b[0m Trial 474 finished with value: 0.8220753640745999 and parameters: {'n_estimators': 872, 'learning_rate': 0.06751618737398409, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 460}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:21,831]\u001b[0m Trial 475 finished with value: 0.8270395387108131 and parameters: {'n_estimators': 447, 'learning_rate': 0.10293293111525083, 'max_depth': 12, 'max_bin': 219, 'num_leaves': 419}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:24,147]\u001b[0m Trial 476 finished with value: 0.8207423483347489 and parameters: {'n_estimators': 831, 'learning_rate': 0.060762102861739116, 'max_depth': 7, 'max_bin': 210, 'num_leaves': 438}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:27,400]\u001b[0m Trial 477 finished with value: 0.8192740820884181 and parameters: {'n_estimators': 886, 'learning_rate': 0.04606728198175232, 'max_depth': 12, 'max_bin': 224, 'num_leaves': 389}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:30,006]\u001b[0m Trial 478 finished with value: 0.8236923031692236 and parameters: {'n_estimators': 854, 'learning_rate': 0.07190069780464352, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 450}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:33,184]\u001b[0m Trial 479 finished with value: 0.8189609931023565 and parameters: {'n_estimators': 812, 'learning_rate': 0.05263592393683216, 'max_depth': 12, 'max_bin': 206, 'num_leaves': 570}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:36,191]\u001b[0m Trial 480 finished with value: 0.8145595291910709 and parameters: {'n_estimators': 867, 'learning_rate': 0.06483558549326116, 'max_depth': 12, 'max_bin': 213, 'num_leaves': 542}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:15:39,029]\u001b[0m Trial 481 finished with value: 0.823848221029656 and parameters: {'n_estimators': 884, 'learning_rate': 0.057756756149648605, 'max_depth': 12, 'max_bin': 209, 'num_leaves': 403}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:41,199]\u001b[0m Trial 482 finished with value: 0.8222684838963424 and parameters: {'n_estimators': 846, 'learning_rate': 0.08393294234520542, 'max_depth': 11, 'max_bin': 190, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:43,421]\u001b[0m Trial 483 finished with value: 0.8185653131796716 and parameters: {'n_estimators': 865, 'learning_rate': 0.07606262892000905, 'max_depth': 12, 'max_bin': 198, 'num_leaves': 466}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:46,080]\u001b[0m Trial 484 finished with value: 0.8240594666974715 and parameters: {'n_estimators': 827, 'learning_rate': 0.06733688218287442, 'max_depth': 12, 'max_bin': 203, 'num_leaves': 423}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:48,925]\u001b[0m Trial 485 finished with value: 0.8224001765676198 and parameters: {'n_estimators': 884, 'learning_rate': 0.06277945783788848, 'max_depth': 12, 'max_bin': 215, 'num_leaves': 354}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:51,497]\u001b[0m Trial 486 finished with value: 0.8219170123994411 and parameters: {'n_estimators': 749, 'learning_rate': 0.07006615026267629, 'max_depth': 12, 'max_bin': 211, 'num_leaves': 505}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:54,366]\u001b[0m Trial 487 finished with value: 0.8178335254123796 and parameters: {'n_estimators': 786, 'learning_rate': 0.04936792070427172, 'max_depth': 12, 'max_bin': 207, 'num_leaves': 448}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:15:57,480]\u001b[0m Trial 488 finished with value: 0.8162017854524735 and parameters: {'n_estimators': 858, 'learning_rate': 0.05784219432330077, 'max_depth': 12, 'max_bin': 219, 'num_leaves': 433}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:00,750]\u001b[0m Trial 489 finished with value: 0.8203248574970626 and parameters: {'n_estimators': 843, 'learning_rate': 0.05407043554657922, 'max_depth': 12, 'max_bin': 204, 'num_leaves': 481}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:03,162]\u001b[0m Trial 490 finished with value: 0.8199871576977535 and parameters: {'n_estimators': 876, 'learning_rate': 0.07913708472452334, 'max_depth': 11, 'max_bin': 194, 'num_leaves': 409}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:05,542]\u001b[0m Trial 491 finished with value: 0.8188075636383498 and parameters: {'n_estimators': 898, 'learning_rate': 0.07341837617165138, 'max_depth': 12, 'max_bin': 212, 'num_leaves': 460}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:08,410]\u001b[0m Trial 492 finished with value: 0.8195917853730362 and parameters: {'n_estimators': 900, 'learning_rate': 0.06087934217498789, 'max_depth': 12, 'max_bin': 199, 'num_leaves': 370}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:11,216]\u001b[0m Trial 493 finished with value: 0.8184795473919626 and parameters: {'n_estimators': 868, 'learning_rate': 0.06626292704255753, 'max_depth': 12, 'max_bin': 275, 'num_leaves': 443}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:13,850]\u001b[0m Trial 494 finished with value: 0.8225551230487829 and parameters: {'n_estimators': 820, 'learning_rate': 0.06951012628643158, 'max_depth': 12, 'max_bin': 152, 'num_leaves': 424}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:16,825]\u001b[0m Trial 495 finished with value: 0.8220528935646552 and parameters: {'n_estimators': 842, 'learning_rate': 0.06314334216312835, 'max_depth': 12, 'max_bin': 217, 'num_leaves': 521}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:20,035]\u001b[0m Trial 496 finished with value: 0.8232074125091133 and parameters: {'n_estimators': 881, 'learning_rate': 0.05663413149625731, 'max_depth': 12, 'max_bin': 208, 'num_leaves': 473}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:22,415]\u001b[0m Trial 497 finished with value: 0.8196406358686719 and parameters: {'n_estimators': 857, 'learning_rate': 0.07624520254442618, 'max_depth': 11, 'max_bin': 196, 'num_leaves': 454}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:24,826]\u001b[0m Trial 498 finished with value: 0.8191281667486752 and parameters: {'n_estimators': 872, 'learning_rate': 0.06642333769850425, 'max_depth': 12, 'max_bin': 214, 'num_leaves': 401}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:16:27,680]\u001b[0m Trial 499 finished with value: 0.8173587262282229 and parameters: {'n_estimators': 805, 'learning_rate': 0.05173443750004958, 'max_depth': 12, 'max_bin': 201, 'num_leaves': 107}. Best is trial 113 with value: 0.8483380594061133.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.848338059\n",
      "\tBest params:\n",
      "\t\tn_estimators: 817\n",
      "\t\tlearning_rate: 0.051638143204308144\n",
      "\t\tmax_depth: 12\n",
      "\t\tmax_bin: 211\n",
      "\t\tnum_leaves: 491\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "#study_lgbm_1 = optuna.create_study(direction='maximize', study_name=\"LGBMClassifier_1\")\n",
    "func_lgbm_9 = lambda trial: objective_lgbm_CV(trial, X_trainSet9, Y_trainSet9, Y_trainSet9_class)\n",
    "study_lgbm.optimize(func_lgbm_9, n_trials=50)  \n",
    "print(f\"\\tNumber of trials: {len(study_lgbm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_lgbm.best_value:.9f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a422861a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:26.801684Z",
     "iopub.status.busy": "2023-01-15T14:18:26.801550Z",
     "iopub.status.idle": "2023-01-15T14:18:27.041275Z",
     "shell.execute_reply": "2023-01-15T14:18:27.040918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
      "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
      "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
      "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
      "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
      "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
      "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
      "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
      "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
      "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
      "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
      "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
      "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
      "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
      "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8        Set9  \n",
      "0   342.000000  339.000000  327.000000  334.000000  333.000000  347.000000  \n",
      "1   160.000000  176.000000  171.000000  175.000000  166.000000  162.000000  \n",
      "2    65.000000   49.000000   61.000000   46.000000   61.000000   47.000000  \n",
      "3    28.000000   31.000000   36.000000   40.000000   35.000000   39.000000  \n",
      "4     0.843697    0.865546    0.836975    0.855462    0.838655    0.855462  \n",
      "5     0.840295    0.873711    0.842784    0.878947    0.845178    0.880711  \n",
      "6     0.924324    0.916216    0.900826    0.893048    0.904891    0.898964  \n",
      "7     0.711100    0.782200    0.737100    0.791900    0.731300    0.775100  \n",
      "8     0.880309    0.894459    0.870839    0.885942    0.874016    0.889744  \n",
      "9     0.840418    0.864342    0.835046    0.855043    0.836507    0.854793  \n",
      "10    0.827564    0.854637    0.824941    0.844347    0.824858    0.839994  \n",
      "11    0.817718    0.849219    0.818948    0.842452    0.818084    0.837042  \n",
      "12    0.662808    0.711081    0.653199    0.688890    0.653376    0.680353  \n",
      "13    0.851100    0.850200    0.826100    0.814000    0.825900    0.806000  \n",
      "14    0.817718    0.849219    0.818948    0.842452    0.818084    0.837042  \n"
     ]
    }
   ],
   "source": [
    "optimized_lgbm_9 = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "#learn\n",
    "eval_set = [(X_testSet9, Y_testSet9)]\n",
    "optimized_lgbm_9.fit(X_trainSet9,\n",
    "                Y_trainSet9,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "        \n",
    "\n",
    "#predict        \n",
    "y_pred_lgbm_9 = optimized_lgbm_9.predict(X_testSet9)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet9, y_pred_lgbm_9)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet9, y_pred_lgbm_9)\n",
    "Precision = precision_score(Y_testSet9, y_pred_lgbm_9)\n",
    "Sensitivity = recall_score(Y_testSet9, y_pred_lgbm_9)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet9, y_pred_lgbm_9)      \n",
    "f1_scores_W = f1_score(Y_testSet9, y_pred_lgbm_9, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet9, y_pred_lgbm_9, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet9, y_pred_lgbm_9)\n",
    "MCC = matthews_corrcoef(Y_testSet9, y_pred_lgbm_9)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet9, y_pred_lgbm_9)\n",
    "\n",
    "\n",
    "Set9 = pd.DataFrame({ 'Set9':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_lgbm_test['Set9'] = Set9\n",
    "print(mat_met_lgbm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "812c9364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:27.043021Z",
     "iopub.status.busy": "2023-01-15T14:18:27.042860Z",
     "iopub.status.idle": "2023-01-15T14:18:27.173962Z",
     "shell.execute_reply": "2023-01-15T14:18:27.173621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study_lgbm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7929aa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:27.175608Z",
     "iopub.status.busy": "2023-01-15T14:18:27.175441Z",
     "iopub.status.idle": "2023-01-15T14:18:45.530245Z",
     "shell.execute_reply": "2023-01-15T14:18:45.529851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "plot_param_importances(study_lgbm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea89ec31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:45.531991Z",
     "iopub.status.busy": "2023-01-15T14:18:45.531803Z",
     "iopub.status.idle": "2023-01-15T14:18:48.002848Z",
     "shell.execute_reply": "2023-01-15T14:18:48.002489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       165.700000     7.846443\n",
      "1                    TN        87.200000     7.083627\n",
      "2                    FP        26.200000     2.936362\n",
      "3                    FN        18.000000     3.231787\n",
      "4              Accuracy         0.851230     0.013703\n",
      "5             Precision         0.863424     0.014346\n",
      "6           Sensitivity         0.901822     0.018415\n",
      "7           Specificity         0.768380     0.028162\n",
      "8              F1 score         0.882089     0.012513\n",
      "9   F1 score (weighted)         0.850016     0.013779\n",
      "10     F1 score (macro)         0.839671     0.014505\n",
      "11    Balanced Accuracy         0.835099     0.014691\n",
      "12                  MCC         0.681257     0.028806\n",
      "13                  NPV         0.829140     0.025158\n",
      "14              ROC_AUC         0.835099     0.014691\n"
     ]
    }
   ],
   "source": [
    "detailed_objective_lgbm_cv(study_lgbm.best_trial, X, Y, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4e16369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:48.004579Z",
     "iopub.status.busy": "2023-01-15T14:18:48.004444Z",
     "iopub.status.idle": "2023-01-15T14:18:48.017637Z",
     "shell.execute_reply": "2023-01-15T14:18:48.017314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Set0</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Set3</th>\n",
       "      <th>Set4</th>\n",
       "      <th>Set5</th>\n",
       "      <th>Set6</th>\n",
       "      <th>Set7</th>\n",
       "      <th>Set8</th>\n",
       "      <th>Set9</th>\n",
       "      <th>ave</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>333.400000</td>\n",
       "      <td>7.848567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>168.100000</td>\n",
       "      <td>5.743595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>7.908505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>6.363088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.853782</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.843697</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.836975</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.838655</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.015038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.871728</td>\n",
       "      <td>0.827848</td>\n",
       "      <td>0.844327</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>0.873711</td>\n",
       "      <td>0.842784</td>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.845178</td>\n",
       "      <td>0.880711</td>\n",
       "      <td>0.856120</td>\n",
       "      <td>0.018754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.905817</td>\n",
       "      <td>0.862534</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.924324</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.893048</td>\n",
       "      <td>0.904891</td>\n",
       "      <td>0.898964</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0.016723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.746600</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.750250</td>\n",
       "      <td>0.030302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.884462</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.871391</td>\n",
       "      <td>0.880309</td>\n",
       "      <td>0.894459</td>\n",
       "      <td>0.870839</td>\n",
       "      <td>0.885942</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.889744</td>\n",
       "      <td>0.876957</td>\n",
       "      <td>0.012447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.853009</td>\n",
       "      <td>0.825711</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.834113</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>0.864342</td>\n",
       "      <td>0.835046</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.836507</td>\n",
       "      <td>0.854793</td>\n",
       "      <td>0.841341</td>\n",
       "      <td>0.015342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.842689</td>\n",
       "      <td>0.815028</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.821210</td>\n",
       "      <td>0.827564</td>\n",
       "      <td>0.854637</td>\n",
       "      <td>0.824941</td>\n",
       "      <td>0.844347</td>\n",
       "      <td>0.824858</td>\n",
       "      <td>0.839994</td>\n",
       "      <td>0.829693</td>\n",
       "      <td>0.015758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.839412</td>\n",
       "      <td>0.807609</td>\n",
       "      <td>0.799570</td>\n",
       "      <td>0.817153</td>\n",
       "      <td>0.817718</td>\n",
       "      <td>0.849219</td>\n",
       "      <td>0.818948</td>\n",
       "      <td>0.842452</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.837042</td>\n",
       "      <td>0.824721</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.686036</td>\n",
       "      <td>0.636177</td>\n",
       "      <td>0.603661</td>\n",
       "      <td>0.643473</td>\n",
       "      <td>0.662808</td>\n",
       "      <td>0.711081</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>0.688890</td>\n",
       "      <td>0.653376</td>\n",
       "      <td>0.680353</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.030935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.821600</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.763900</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.851100</td>\n",
       "      <td>0.850200</td>\n",
       "      <td>0.826100</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.825900</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.818590</td>\n",
       "      <td>0.025685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.839412</td>\n",
       "      <td>0.807609</td>\n",
       "      <td>0.799570</td>\n",
       "      <td>0.817153</td>\n",
       "      <td>0.817718</td>\n",
       "      <td>0.849219</td>\n",
       "      <td>0.818948</td>\n",
       "      <td>0.842452</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.837042</td>\n",
       "      <td>0.824721</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric        Set0        Set1        Set2        Set3  \\\n",
       "0                    TP  333.000000  327.000000  320.000000  332.000000   \n",
       "1                    TN  175.000000  166.000000  165.000000  165.000000   \n",
       "2                    FP   49.000000   68.000000   59.000000   56.000000   \n",
       "3                    FN   38.000000   34.000000   51.000000   42.000000   \n",
       "4              Accuracy    0.853782    0.828571    0.815126    0.835294   \n",
       "5             Precision    0.871728    0.827848    0.844327    0.855670   \n",
       "6           Sensitivity    0.897574    0.905817    0.862534    0.887701   \n",
       "7           Specificity    0.781200    0.709400    0.736600    0.746600   \n",
       "8              F1 score    0.884462    0.865079    0.853333    0.871391   \n",
       "9   F1 score (weighted)    0.853009    0.825711    0.814431    0.834113   \n",
       "10     F1 score (macro)    0.842689    0.815028    0.801667    0.821210   \n",
       "11    Balanced Accuracy    0.839412    0.807609    0.799570    0.817153   \n",
       "12                  MCC    0.686036    0.636177    0.603661    0.643473   \n",
       "13                  NPV    0.821600    0.830000    0.763900    0.797100   \n",
       "14              ROC_AUC    0.839412    0.807609    0.799570    0.817153   \n",
       "\n",
       "          Set4        Set5        Set6        Set7        Set8        Set9  \\\n",
       "0   342.000000  339.000000  327.000000  334.000000  333.000000  347.000000   \n",
       "1   160.000000  176.000000  171.000000  175.000000  166.000000  162.000000   \n",
       "2    65.000000   49.000000   61.000000   46.000000   61.000000   47.000000   \n",
       "3    28.000000   31.000000   36.000000   40.000000   35.000000   39.000000   \n",
       "4     0.843697    0.865546    0.836975    0.855462    0.838655    0.855462   \n",
       "5     0.840295    0.873711    0.842784    0.878947    0.845178    0.880711   \n",
       "6     0.924324    0.916216    0.900826    0.893048    0.904891    0.898964   \n",
       "7     0.711100    0.782200    0.737100    0.791900    0.731300    0.775100   \n",
       "8     0.880309    0.894459    0.870839    0.885942    0.874016    0.889744   \n",
       "9     0.840418    0.864342    0.835046    0.855043    0.836507    0.854793   \n",
       "10    0.827564    0.854637    0.824941    0.844347    0.824858    0.839994   \n",
       "11    0.817718    0.849219    0.818948    0.842452    0.818084    0.837042   \n",
       "12    0.662808    0.711081    0.653199    0.688890    0.653376    0.680353   \n",
       "13    0.851100    0.850200    0.826100    0.814000    0.825900    0.806000   \n",
       "14    0.817718    0.849219    0.818948    0.842452    0.818084    0.837042   \n",
       "\n",
       "           ave       std  \n",
       "0   333.400000  7.848567  \n",
       "1   168.100000  5.743595  \n",
       "2    56.100000  7.908505  \n",
       "3    37.400000  6.363088  \n",
       "4     0.842857  0.015038  \n",
       "5     0.856120  0.018754  \n",
       "6     0.899190  0.016723  \n",
       "7     0.750250  0.030302  \n",
       "8     0.876957  0.012447  \n",
       "9     0.841341  0.015342  \n",
       "10    0.829693  0.015758  \n",
       "11    0.824721  0.016300  \n",
       "12    0.661905  0.030935  \n",
       "13    0.818590  0.025685  \n",
       "14    0.824721  0.016300  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_met_lgbm_test['ave'] = mat_met_lgbm_test.iloc[:,1:11].mean(axis='columns', numeric_only=True)\n",
    "mat_met_lgbm_test['std'] = mat_met_lgbm_test.iloc[:,1:11].std(axis='columns', numeric_only=True)\n",
    "mat_met_lgbm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7c3c24b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:18:48.019185Z",
     "iopub.status.busy": "2023-01-15T14:18:48.019024Z",
     "iopub.status.idle": "2023-01-15T14:19:00.872160Z",
     "shell.execute_reply": "2023-01-15T14:19:00.871772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test_idx0</th>\n",
       "      <th>y_test0</th>\n",
       "      <th>y_pred_lgbm0</th>\n",
       "      <th>y_pred_lgbm1</th>\n",
       "      <th>y_pred_lgbm2</th>\n",
       "      <th>y_pred_lgbm3</th>\n",
       "      <th>y_pred_lgbm4</th>\n",
       "      <th>y_pred_lgbm_ave</th>\n",
       "      <th>y_pred_lgbm_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test_idx0  y_test0  y_pred_lgbm0  y_pred_lgbm1  y_pred_lgbm2  \\\n",
       "0               0      1.0           1.0           0.0           1.0   \n",
       "1               1      1.0           1.0           1.0           1.0   \n",
       "2               2      0.0           0.0           0.0           0.0   \n",
       "3               3      0.0           1.0           1.0           1.0   \n",
       "4               4      0.0           1.0           1.0           1.0   \n",
       "...           ...      ...           ...           ...           ...   \n",
       "2966         2966      1.0           1.0           1.0           1.0   \n",
       "2967         2967      1.0           1.0           1.0           1.0   \n",
       "2968         2968      0.0           1.0           1.0           1.0   \n",
       "2969         2969      1.0           1.0           0.0           1.0   \n",
       "2970         2970      1.0           0.0           0.0           0.0   \n",
       "\n",
       "      y_pred_lgbm3  y_pred_lgbm4  y_pred_lgbm_ave  y_pred_lgbm_std  \n",
       "0              1.0           1.0              0.8         0.400000  \n",
       "1              1.0           1.0              1.0         0.000000  \n",
       "2              0.0           0.0              0.0         0.000000  \n",
       "3              1.0           1.0              1.0         0.000000  \n",
       "4              1.0           1.0              1.0         0.000000  \n",
       "...            ...           ...              ...              ...  \n",
       "2966           1.0           1.0              1.0         0.000000  \n",
       "2967           1.0           1.0              1.0         0.000000  \n",
       "2968           1.0           1.0              1.0         0.000000  \n",
       "2969           0.0           1.0              0.6         0.489898  \n",
       "2970           0.0           0.0              0.0         0.000000  \n",
       "\n",
       "[2971 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to fit into these X values \n",
    "\n",
    "TP = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "\n",
    "\n",
    "Accuracy_outer = []\n",
    "Precision_outer = [] #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity_outer = [] # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity_outer = [] #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores_outer = []\n",
    "f1_scores_W_outer = []\n",
    "f1_scores_M_outer = []\n",
    "BA_scores_outer = []\n",
    "MCC_outer = []\n",
    "NPV_outer = []\n",
    "ROC_AUC_outer = []\n",
    "\n",
    "NUM_TRIALS = 5\n",
    "random_state= [687266, 98656, 56, 280189, 76543] # \n",
    "data_lgbm=pd.DataFrame()\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    cv_change = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state[i])\n",
    "    data_inner = pd.DataFrame({'y_test_idx': pd.Series(dtype='int'),\n",
    "                   'y_test': pd.Series(dtype='float'),\n",
    "                   'y_pred': pd.Series(dtype='float')})\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv_change.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        optimizedCV_lgbm = lgbm.LGBMClassifier(objective=\"binary\", \n",
    "                                      random_state=1121218, \n",
    "                                      boosting_type =\"gbdt\", \n",
    "                                      subsample=0.8, # also called bagging_fraction\n",
    "                                      subsample_freq=10,\n",
    "                                      n_estimators=study_lgbm.best_params['n_estimators'],\n",
    "                                      learning_rate=study_lgbm.best_params['learning_rate'],\n",
    "                                      max_depth = study_lgbm.best_params['max_depth'],\n",
    "                                      max_bin=study_lgbm.best_params['max_bin'],\n",
    "                                      #lambda_l1 = study_lgbm.best_params['lambda_l1'],\n",
    "                                      #lambda_l2= study_lgbm.best_params['lambda_l2'],\n",
    "                                      num_leaves=study_lgbm.best_params['num_leaves'],\n",
    "                                      #min_child_samples = study_lgbm.best_params['min_child_samples'],\n",
    "                                      #bagging_fraction = study_lgbm.best_params['bagging_fraction'],\n",
    "                                      #bagging_freq = study_lgbm.best_params['bagging_freq'],\n",
    "                                        \n",
    "                                        )\n",
    "\n",
    "\n",
    "        #learn\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        optimizedCV_lgbm.fit(X_train,\n",
    "                y_train,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric=\"binary_logloss\",     \n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False,\n",
    "                )\n",
    "                          \n",
    "                  \n",
    "        #print(test_idx)\n",
    "        y_pred_optimized_lgbm = optimizedCV_lgbm.predict(X_test) \n",
    "        data_inner = data_inner.append(pd.DataFrame({'y_test_idx': test_idx, 'y_test': y_test, 'y_pred_lgbm': y_pred_optimized_lgbm } ), )\n",
    "        data_inner.reset_index(inplace=True, drop=True) \n",
    "        data_inner.sort_values(by='y_test_idx', inplace=True) \n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimized_lgbm)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        \n",
    "       \n",
    "        Accuracy_outer.append(accuracy_score(y_test, y_pred_optimized_lgbm))\n",
    "        Precision_outer.append(precision_score(y_test, y_pred_optimized_lgbm))\n",
    "        Sensitivity_outer.append(recall_score(y_test, y_pred_optimized_lgbm))\n",
    "        Specificity_outer.append(round( TN[idx] / (TN[idx]+FP[idx]),4 ))\n",
    "        f1_scores_outer.append(f1_score(y_test, y_pred_optimized_lgbm))\n",
    "        f1_scores_W_outer.append(f1_score(y_test, y_pred_optimized_lgbm, average=\"weighted\"))\n",
    "        f1_scores_M_outer.append(f1_score(y_test, y_pred_optimized_lgbm, average=\"macro\"))\n",
    "        BA_scores_outer.append(balanced_accuracy_score(y_test, y_pred_optimized_lgbm))\n",
    "        MCC_outer.append(matthews_corrcoef(y_test, y_pred_optimized_lgbm))\n",
    "        NPV_outer.append(round( TN[idx] / (TN[idx]+FN[idx]),4 ))\n",
    "        ROC_AUC_outer.append(roc_auc_score(y_test, y_pred_optimized_lgbm))\n",
    "        \n",
    "    data_lgbm['y_test_idx' + str(i)] = data_inner['y_test_idx']\n",
    "    data_lgbm['y_test' + str(i)] = data_inner['y_test']\n",
    "    data_lgbm['y_pred_lgbm' + str(i)] = data_inner['y_pred_lgbm']\n",
    "   # data_lgbm['correct' + str(i)] = correct_value\n",
    "   # data_lgbm['pred' + str(i)] = y_pred_optimized_lgbm\n",
    "\n",
    "mat_met_optimized_lgbm = pd.DataFrame({'Metric':['Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(Accuracy_outer),np.mean(Precision_outer),\n",
    "                                           np.mean(Sensitivity_outer),np.mean(Specificity_outer),np.mean(f1_scores_outer),\n",
    "                                           np.mean(f1_scores_W_outer), np.mean(f1_scores_M_outer), np.mean(BA_scores_outer), \n",
    "                                           np.mean(MCC_outer),np.mean(NPV_outer),np.mean(ROC_AUC_outer)],\n",
    "                        'Value (std)': [ np.std(Accuracy_outer, ddof=1),np.std(Precision_outer, ddof=1),\n",
    "                                        np.std(Sensitivity_outer,ddof=1),np.std(Specificity_outer,ddof=1),np.std(f1_scores_outer, ddof=1),\n",
    "                                        np.std(f1_scores_W_outer, ddof=1),np.std(f1_scores_M_outer, ddof=1), np.std(BA_scores_outer, ddof=1), \n",
    "                                        np.std(MCC_outer, ddof=1),np.std(NPV_outer, ddof=1),np.std(ROC_AUC_outer, ddof=1)]\n",
    "                       }) \n",
    "\n",
    "\n",
    "lgbm_run0 = data_lgbm[['y_test_idx0', 'y_test0', 'y_pred_lgbm0']]\n",
    "lgbm_run0.sort_values(by='y_test_idx0', inplace=True)\n",
    "lgbm_run0.reset_index(inplace=True, drop=True)\n",
    "lgbm_run1 = data_lgbm[['y_test_idx1', 'y_test1', 'y_pred_lgbm1']]\n",
    "lgbm_run1.sort_values(by='y_test_idx1', inplace=True)\n",
    "lgbm_run1.reset_index(inplace=True, drop=True)\n",
    "lgbm_run2 = data_lgbm[['y_test_idx2', 'y_test2', 'y_pred_lgbm2']]\n",
    "lgbm_run2.sort_values(by='y_test_idx2', inplace=True)\n",
    "lgbm_run2.reset_index(inplace=True, drop=True)\n",
    "lgbm_run3 = data_lgbm[['y_test_idx3', 'y_test3', 'y_pred_lgbm3']]\n",
    "lgbm_run3.sort_values(by='y_test_idx3', inplace=True)\n",
    "lgbm_run3.reset_index(inplace=True, drop=True)\n",
    "lgbm_run4 = data_lgbm[['y_test_idx4', 'y_test4', 'y_pred_lgbm4']]\n",
    "lgbm_run4.sort_values(by='y_test_idx4', inplace=True)\n",
    "lgbm_run4.reset_index(inplace=True, drop=True)\n",
    "lgbm_5preds = pd.concat([lgbm_run0, lgbm_run1, lgbm_run2, lgbm_run3, lgbm_run4], axis=1)\n",
    "lgbm_5preds = lgbm_5preds[['y_test_idx0', 'y_test0', 'y_pred_lgbm0', 'y_pred_lgbm1', 'y_pred_lgbm2', 'y_pred_lgbm3', 'y_pred_lgbm4']]\n",
    "lgbm_5preds['y_pred_lgbm_ave'] = lgbm_5preds.iloc[:,2:11].mean(axis='columns', numeric_only=True)\n",
    "lgbm_5preds['y_pred_lgbm_std'] = lgbm_5preds.iloc[:,2:].std(axis='columns', numeric_only=True)\n",
    "# maybe also calculate the std for each value\n",
    "lgbm_5preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c16510fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:00.874079Z",
     "iopub.status.busy": "2023-01-15T14:19:00.873876Z",
     "iopub.status.idle": "2023-01-15T14:19:00.890700Z",
     "shell.execute_reply": "2023-01-15T14:19:00.890286Z"
    }
   },
   "outputs": [],
   "source": [
    "mat_met_optimized_lgbm.to_csv('mat_met_lgbm_opt.csv')\n",
    "lgbm_5preds.to_csv('lgbm_5test_CV_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62e03bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:00.892591Z",
     "iopub.status.busy": "2023-01-15T14:19:00.892377Z",
     "iopub.status.idle": "2023-01-15T14:19:10.503675Z",
     "shell.execute_reply": "2023-01-15T14:19:10.503295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM baseline model f1_score 0.8347 with a standard deviation of 0.0242\n",
      "LightGBM optimized model f1_score 0.8389 with a standard deviation of 0.0214\n"
     ]
    }
   ],
   "source": [
    "#cross valide using this optimized LightGBM \n",
    "fit_params={'early_stopping_rounds': 50, \n",
    "        'eval_set': [(X_tr, Y_tr), (X_te, Y_te)],\n",
    "            'verbose':False,\n",
    "           }\n",
    "#cross valide using this optimized LightGBM \n",
    "lgbm_baseline_CVscore = cross_val_score(lgbm_clf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "#f1_cv_lgbm_opt_testSet = cross_val_score(optimized_lgbm, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "f1_cv_lgbm_opt = cross_val_score(optimizedCV_lgbm, X, Y, cv=10, scoring=\"f1_macro\", fit_params=fit_params)\n",
    "print(\"LightGBM baseline model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(lgbm_baseline_CVscore), np.std(lgbm_baseline_CVscore, ddof=1)))\n",
    "#print(\"LightGBM optimized model (tested on Y_te)f1_score %0.4f with a standard deviation of %0.4f\" % (f1_cv_lgbm_opt_testSet.mean(), f1_cv_lgbm_opt_testSet.std()))\n",
    "print(\"LightGBM optimized model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(f1_cv_lgbm_opt), np.std(f1_cv_lgbm_opt, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3cbf6f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:10.505348Z",
     "iopub.status.busy": "2023-01-15T14:19:10.505183Z",
     "iopub.status.idle": "2023-01-15T14:19:10.517401Z",
     "shell.execute_reply": "2023-01-15T14:19:10.517087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optimizedCV_lgbm_clf.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgbm_clf, \"./lgbm_clf.joblib\")\n",
    "#joblib.dump(optimized_lgbm, \"./optimized_lgbm.joblib\")\n",
    "joblib.dump(optimizedCV_lgbm, \"./optimizedCV_lgbm_clf.joblib\") \n",
    "#loaded_rf = joblib.load(\"./optimized_rf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e710905",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc6f6189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:10.518963Z",
     "iopub.status.busy": "2023-01-15T14:19:10.518818Z",
     "iopub.status.idle": "2023-01-15T14:19:12.582539Z",
     "shell.execute_reply": "2023-01-15T14:19:12.582151Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       164.200000     8.966605\n",
      "1                    TN        86.000000     7.717225\n",
      "2                    FP        27.400000     4.993329\n",
      "3                    FN        19.500000     5.542763\n",
      "4              Accuracy         0.842145     0.027572\n",
      "5             Precision         0.857047     0.024609\n",
      "6           Sensitivity         0.893658     0.030436\n",
      "7           Specificity         0.758040     0.044164\n",
      "8              F1 score         0.874737     0.023095\n",
      "9   F1 score (weighted)         0.840897     0.027610\n",
      "10     F1 score (macro)         0.830024     0.029181\n",
      "11    Balanced Accuracy         0.825851     0.028877\n",
      "12                  MCC         0.662291     0.058339\n",
      "13                  NPV         0.816130     0.045606\n",
      "14              ROC_AUC         0.825851     0.028877\n",
      "CPU times: user 29.1 s, sys: 40 ms, total: 29.1 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "TP =np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "Accuracy = np.empty(10)\n",
    "Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores = np.empty(10)\n",
    "f1_scores_W = np.empty(10)\n",
    "f1_scores_M = np.empty(10)\n",
    "BA_scores = np.empty(10)\n",
    "MCC = np.empty(10)\n",
    "NPV = np.empty(10)\n",
    "ROC_AUC= np.empty(10)\n",
    "\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=1121218,\n",
    "    #n_estimators=10000,  \n",
    "    tree_method=\"hist\",  # enable histogram binning in XGB\n",
    "    subsample=0.8, \n",
    "    n_jobs=16,\n",
    "    )\n",
    "    \n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    xgb_clf.fit(X_train,\n",
    "                y_train,\n",
    "    \n",
    "    eval_set=eval_set,\n",
    "    eval_metric=\"logloss\",\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False,  # Disable logs\n",
    "               )\n",
    "\n",
    "    y_pred = xgb_clf.predict(X_test) \n",
    "    \n",
    "    #calculate the evaluation results\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TP[idx] = conf_matrix[1][1]\n",
    "    TN[idx] = conf_matrix[0][0]\n",
    "    FP[idx] = conf_matrix[0][1] \n",
    "    FN[idx] = conf_matrix[1][0]\n",
    "    Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "    Precision[idx] = precision_score(y_test, y_pred)\n",
    "    Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "    Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "    f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "    f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "    MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "    NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "    ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })   \n",
    "    \n",
    "print(mat_met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a7452d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:12.584496Z",
     "iopub.status.busy": "2023-01-15T14:19:12.584337Z",
     "iopub.status.idle": "2023-01-15T14:19:12.588479Z",
     "shell.execute_reply": "2023-01-15T14:19:12.588176Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_xgb_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 900),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-6, 0.1),  \n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 12),  \n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 1, step=1e-04),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1,40),\n",
    "        #\"alpha\": trial.suggest_float(\"alpha\", 0, 1.0),\n",
    "        #\"lambda\": trial.suggest_float(\"lambda\", 1e-8, 40.0),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 250, 500),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    cv_scores=np.empty(10)\n",
    "    #y_comb=pd.DataFrame()\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=1121218, booster =\"gbtree\", tree_method='hist',\n",
    "                                  **param_grid,  n_jobs=16, subsample=0.8, )\n",
    "    \n",
    "        eval_set = [(X_test, y_test)]\n",
    "        xgb_model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=\"logloss\",    \n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False)\n",
    "    \n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        cv_scores[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38d38cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:12.589801Z",
     "iopub.status.busy": "2023-01-15T14:19:12.589664Z",
     "iopub.status.idle": "2023-01-15T14:19:12.598207Z",
     "shell.execute_reply": "2023-01-15T14:19:12.597908Z"
    }
   },
   "outputs": [],
   "source": [
    "def detailed_objective_xgb_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 900),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-6, 0.1),  \n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 12),  \n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 1, step=1e-04),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1,40),\n",
    "        #\"alpha\": trial.suggest_float(\"alpha\", 0, 1.0),\n",
    "        #\"lambda\": trial.suggest_float(\"lambda\", 1e-8, 40.0),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 250, 500),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    TP=np.empty(10)\n",
    "    TN = np.empty(10)\n",
    "    FP= np.empty(10)\n",
    "    FN= np.empty(10)\n",
    "    Accuracy = np.empty(10)\n",
    "    Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "    Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "    Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "    f1_scores = np.empty(10)\n",
    "    f1_scores_W=np.empty(10)\n",
    "    f1_scores_M=np.empty(10)\n",
    "    BA_scores = np.empty(10)\n",
    "    MCC = np.empty(10)\n",
    "    NPV = np.empty(10)\n",
    "    ROC_AUC= np.empty(10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=1121218, booster =\"gbtree\", tree_method='hist',\n",
    "                                  **param_grid,  n_jobs=16, subsample=0.8, )\n",
    "    \n",
    "        eval_set = [(X_test, y_test)]\n",
    "        xgb_model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=\"logloss\",    \n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False)\n",
    "        \n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        \n",
    "       \n",
    "           \n",
    "        #calculate parameters\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)      \n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })   \n",
    "    \n",
    "    return (mat_met)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec6a49a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:19:12.599686Z",
     "iopub.status.busy": "2023-01-15T14:19:12.599572Z",
     "iopub.status.idle": "2023-01-15T14:27:19.061324Z",
     "shell.execute_reply": "2023-01-15T14:27:19.060984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:17:24,839]\u001b[0m A new study created in memory with name: XGBClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:17:29,129]\u001b[0m Trial 0 finished with value: 0.8067180765963563 and parameters: {'n_estimators': 191, 'eta': 0.028140490593225966, 'max_depth': 7, 'alpha': 0.31120000000000003, 'lambda': 25.702880836288813, 'max_bin': 496}. Best is trial 0 with value: 0.8067180765963563.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:17:39,768]\u001b[0m Trial 1 finished with value: 0.8280489208151878 and parameters: {'n_estimators': 679, 'eta': 0.038780834065647286, 'max_depth': 9, 'alpha': 0.44220000000000004, 'lambda': 14.795654371655333, 'max_bin': 251}. Best is trial 1 with value: 0.8280489208151878.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:17:49,028]\u001b[0m Trial 2 finished with value: 0.8288080672012985 and parameters: {'n_estimators': 381, 'eta': 0.05476739217368376, 'max_depth': 12, 'alpha': 0.22660000000000002, 'lambda': 38.34961203674462, 'max_bin': 304}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:00,009]\u001b[0m Trial 3 finished with value: 0.8183481205386496 and parameters: {'n_estimators': 591, 'eta': 0.02854589273414569, 'max_depth': 6, 'alpha': 0.0158, 'lambda': 22.293144622725556, 'max_bin': 300}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:06,246]\u001b[0m Trial 4 finished with value: 0.8277866806165134 and parameters: {'n_estimators': 238, 'eta': 0.08073920926870912, 'max_depth': 12, 'alpha': 0.1316, 'lambda': 36.86893661867859, 'max_bin': 264}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:10,385]\u001b[0m Trial 5 finished with value: 0.8110699223314157 and parameters: {'n_estimators': 247, 'eta': 0.050918795328985925, 'max_depth': 5, 'alpha': 0.2886, 'lambda': 15.950143704783699, 'max_bin': 410}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:14,924]\u001b[0m Trial 6 finished with value: 0.8186616938127477 and parameters: {'n_estimators': 154, 'eta': 0.05786582466901259, 'max_depth': 12, 'alpha': 0.8382000000000001, 'lambda': 36.06057536318879, 'max_bin': 416}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:22,527]\u001b[0m Trial 7 finished with value: 0.8247092680678973 and parameters: {'n_estimators': 796, 'eta': 0.08142667866215905, 'max_depth': 7, 'alpha': 0.0932, 'lambda': 14.635130472150442, 'max_bin': 320}. Best is trial 2 with value: 0.8288080672012985.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:33,676]\u001b[0m Trial 8 finished with value: 0.8295765783491115 and parameters: {'n_estimators': 433, 'eta': 0.028395686134625092, 'max_depth': 12, 'alpha': 0.5973, 'lambda': 10.871196904122977, 'max_bin': 282}. Best is trial 8 with value: 0.8295765783491115.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:38,855]\u001b[0m Trial 9 finished with value: 0.8308468383833645 and parameters: {'n_estimators': 689, 'eta': 0.07054387240720855, 'max_depth': 12, 'alpha': 0.2624, 'lambda': 4.7178295876804155, 'max_bin': 423}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:42,827]\u001b[0m Trial 10 finished with value: 0.8285521337585872 and parameters: {'n_estimators': 826, 'eta': 0.09573205856358726, 'max_depth': 10, 'alpha': 0.6522, 'lambda': 1.3851962823769681, 'max_bin': 491}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:18:58,485]\u001b[0m Trial 11 finished with value: 0.8102276532781806 and parameters: {'n_estimators': 538, 'eta': 0.002087686940524764, 'max_depth': 10, 'alpha': 0.6134000000000001, 'lambda': 3.309726099534963, 'max_bin': 375}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:11,379]\u001b[0m Trial 12 finished with value: 0.8239583983197265 and parameters: {'n_estimators': 430, 'eta': 0.008329260131381355, 'max_depth': 11, 'alpha': 0.9840000000000001, 'lambda': 8.140256008846706, 'max_bin': 366}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:17,881]\u001b[0m Trial 13 finished with value: 0.8296071143284778 and parameters: {'n_estimators': 645, 'eta': 0.06933060226581614, 'max_depth': 10, 'alpha': 0.4446, 'lambda': 9.100986117942503, 'max_bin': 441}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:24,485]\u001b[0m Trial 14 finished with value: 0.8307443412597207 and parameters: {'n_estimators': 700, 'eta': 0.07187209456373561, 'max_depth': 10, 'alpha': 0.3749, 'lambda': 7.450091094547966, 'max_bin': 449}. Best is trial 9 with value: 0.8308468383833645.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:30,251]\u001b[0m Trial 15 finished with value: 0.83302449792732 and parameters: {'n_estimators': 727, 'eta': 0.071566985982668, 'max_depth': 9, 'alpha': 0.37310000000000004, 'lambda': 5.572881768266146, 'max_bin': 456}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:36,825]\u001b[0m Trial 16 finished with value: 0.8287776674050285 and parameters: {'n_estimators': 746, 'eta': 0.09589064240246113, 'max_depth': 8, 'alpha': 0.1627, 'lambda': 27.388491461019687, 'max_bin': 465}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:42,998]\u001b[0m Trial 17 finished with value: 0.8310355336873296 and parameters: {'n_estimators': 860, 'eta': 0.06415255575574103, 'max_depth': 8, 'alpha': 0.514, 'lambda': 4.558383842072677, 'max_bin': 406}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:50,372]\u001b[0m Trial 18 finished with value: 0.8227586877351694 and parameters: {'n_estimators': 884, 'eta': 0.08402534263264945, 'max_depth': 8, 'alpha': 0.7641, 'lambda': 19.025929346960957, 'max_bin': 341}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:57,632]\u001b[0m Trial 19 finished with value: 0.8288056847123757 and parameters: {'n_estimators': 858, 'eta': 0.06257678119957959, 'max_depth': 9, 'alpha': 0.5561, 'lambda': 12.246981513030166, 'max_bin': 395}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:19:59,498]\u001b[0m Trial 20 finished with value: 0.8169489917264423 and parameters: {'n_estimators': 76, 'eta': 0.08652437735270085, 'max_depth': 7, 'alpha': 0.7206, 'lambda': 5.014761941301824, 'max_bin': 472}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:05,533]\u001b[0m Trial 21 finished with value: 0.8299144282767397 and parameters: {'n_estimators': 756, 'eta': 0.06891214649165035, 'max_depth': 8, 'alpha': 0.4949, 'lambda': 5.023395691692244, 'max_bin': 429}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:11,772]\u001b[0m Trial 22 finished with value: 0.8306689056314529 and parameters: {'n_estimators': 567, 'eta': 0.04520625015100508, 'max_depth': 11, 'alpha': 0.37310000000000004, 'lambda': 1.4929063618075018, 'max_bin': 398}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:17,955]\u001b[0m Trial 23 finished with value: 0.8275110629710636 and parameters: {'n_estimators': 766, 'eta': 0.0740055047907483, 'max_depth': 9, 'alpha': 0.24150000000000002, 'lambda': 6.8111965110325805, 'max_bin': 457}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:25,238]\u001b[0m Trial 24 finished with value: 0.8260740040899343 and parameters: {'n_estimators': 627, 'eta': 0.06212152498961871, 'max_depth': 6, 'alpha': 0.3768, 'lambda': 11.061690021822194, 'max_bin': 430}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:33,390]\u001b[0m Trial 25 finished with value: 0.8305709410757952 and parameters: {'n_estimators': 719, 'eta': 0.042857155744873546, 'max_depth': 11, 'alpha': 0.4753, 'lambda': 4.413347084157268, 'max_bin': 355}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:40,787]\u001b[0m Trial 26 finished with value: 0.8207447265332138 and parameters: {'n_estimators': 521, 'eta': 0.06329131457651804, 'max_depth': 6, 'alpha': 0.3114, 'lambda': 18.168758469250932, 'max_bin': 390}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:48,908]\u001b[0m Trial 27 finished with value: 0.8240335254490884 and parameters: {'n_estimators': 895, 'eta': 0.07726259382522598, 'max_depth': 9, 'alpha': 0.5232, 'lambda': 30.813176691984726, 'max_bin': 478}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:20:52,969]\u001b[0m Trial 28 finished with value: 0.8249352537343716 and parameters: {'n_estimators': 813, 'eta': 0.09071911672556937, 'max_depth': 8, 'alpha': 0.0047, 'lambda': 1.3608288018298182, 'max_bin': 419}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:21:03,127]\u001b[0m Trial 29 finished with value: 0.818241390747055 and parameters: {'n_estimators': 656, 'eta': 0.03537898247725962, 'max_depth': 5, 'alpha': 0.1971, 'lambda': 21.933951812760426, 'max_bin': 441}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:11,816]\u001b[0m Trial 30 finished with value: 0.8270683957612844 and parameters: {'n_estimators': 842, 'eta': 0.05206235598972771, 'max_depth': 7, 'alpha': 0.29860000000000003, 'lambda': 12.371920148612517, 'max_bin': 495}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:17,752]\u001b[0m Trial 31 finished with value: 0.8321737677874026 and parameters: {'n_estimators': 711, 'eta': 0.07063579323175939, 'max_depth': 10, 'alpha': 0.39430000000000004, 'lambda': 7.591296896097035, 'max_bin': 451}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:23,852]\u001b[0m Trial 32 finished with value: 0.826955425715717 and parameters: {'n_estimators': 706, 'eta': 0.0670431516191481, 'max_depth': 11, 'alpha': 0.36260000000000003, 'lambda': 6.256257597583854, 'max_bin': 456}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:29,955]\u001b[0m Trial 33 finished with value: 0.8282301902587159 and parameters: {'n_estimators': 615, 'eta': 0.07584628133328086, 'max_depth': 9, 'alpha': 0.4279, 'lambda': 9.35755046475407, 'max_bin': 433}. Best is trial 15 with value: 0.83302449792732.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:35,578]\u001b[0m Trial 34 finished with value: 0.8335754258652356 and parameters: {'n_estimators': 793, 'eta': 0.05773545670449077, 'max_depth': 10, 'alpha': 0.2707, 'lambda': 3.7905719704649736, 'max_bin': 408}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:41,816]\u001b[0m Trial 35 finished with value: 0.8271159960022828 and parameters: {'n_estimators': 790, 'eta': 0.05796931719089544, 'max_depth': 10, 'alpha': 0.44620000000000004, 'lambda': 3.14963242272211, 'max_bin': 407}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:48,226]\u001b[0m Trial 36 finished with value: 0.8250946443861741 and parameters: {'n_estimators': 304, 'eta': 0.05653777160328763, 'max_depth': 9, 'alpha': 0.06960000000000001, 'lambda': 14.27978488604423, 'max_bin': 478}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:21:56,506]\u001b[0m Trial 37 finished with value: 0.830642642665795 and parameters: {'n_estimators': 895, 'eta': 0.045655152116779237, 'max_depth': 10, 'alpha': 0.3421, 'lambda': 9.483200664319005, 'max_bin': 384}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:09,275]\u001b[0m Trial 38 finished with value: 0.8248714556608647 and parameters: {'n_estimators': 750, 'eta': 0.03499381485619714, 'max_depth': 8, 'alpha': 0.20650000000000002, 'lambda': 25.269128283220475, 'max_bin': 410}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:16,819]\u001b[0m Trial 39 finished with value: 0.8269982971049451 and parameters: {'n_estimators': 824, 'eta': 0.07978797458802292, 'max_depth': 9, 'alpha': 0.5458000000000001, 'lambda': 16.88762741106002, 'max_bin': 342}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:30,217]\u001b[0m Trial 40 finished with value: 0.8280764245614998 and parameters: {'n_estimators': 584, 'eta': 0.019443920591511874, 'max_depth': 11, 'alpha': 0.4248, 'lambda': 5.951915343509157, 'max_bin': 442}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:34,824]\u001b[0m Trial 41 finished with value: 0.8290510452617001 and parameters: {'n_estimators': 670, 'eta': 0.06383673000223128, 'max_depth': 12, 'alpha': 0.2516, 'lambda': 2.9683465104862723, 'max_bin': 427}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:39,973]\u001b[0m Trial 42 finished with value: 0.8293191217690976 and parameters: {'n_estimators': 716, 'eta': 0.05459107081471378, 'max_depth': 10, 'alpha': 0.264, 'lambda': 3.4254503132614684, 'max_bin': 420}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:45,654]\u001b[0m Trial 43 finished with value: 0.8330509848991279 and parameters: {'n_estimators': 782, 'eta': 0.07259469312785279, 'max_depth': 11, 'alpha': 0.33440000000000003, 'lambda': 7.359961255307533, 'max_bin': 399}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:50,344]\u001b[0m Trial 44 finished with value: 0.8258786778461296 and parameters: {'n_estimators': 854, 'eta': 0.08927179896651181, 'max_depth': 11, 'alpha': 0.31930000000000003, 'lambda': 7.686348998386455, 'max_bin': 375}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:22:57,827]\u001b[0m Trial 45 finished with value: 0.8316546393790712 and parameters: {'n_estimators': 787, 'eta': 0.0593124260456183, 'max_depth': 10, 'alpha': 0.4158, 'lambda': 13.189323319336777, 'max_bin': 403}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:05,899]\u001b[0m Trial 46 finished with value: 0.8256629428603766 and parameters: {'n_estimators': 790, 'eta': 0.04926641364092148, 'max_depth': 10, 'alpha': 0.4063, 'lambda': 13.34374297422696, 'max_bin': 383}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:12,918]\u001b[0m Trial 47 finished with value: 0.8304470508603483 and parameters: {'n_estimators': 471, 'eta': 0.05856140137984488, 'max_depth': 11, 'alpha': 0.1423, 'lambda': 9.640376265582749, 'max_bin': 360}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:19,336]\u001b[0m Trial 48 finished with value: 0.8325764609449962 and parameters: {'n_estimators': 786, 'eta': 0.07306616168681851, 'max_depth': 10, 'alpha': 0.19160000000000002, 'lambda': 10.703941543657248, 'max_bin': 253}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:24,945]\u001b[0m Trial 49 finished with value: 0.8258927143273569 and parameters: {'n_estimators': 340, 'eta': 0.07904393352462158, 'max_depth': 10, 'alpha': 0.08700000000000001, 'lambda': 10.669900893391999, 'max_bin': 283}. Best is trial 34 with value: 0.8335754258652356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 50.0\n",
      "\tBest value (f1_score): 0.8336\n",
      "\tBest params:\n",
      "\t\tn_estimators: 793\n",
      "\t\teta: 0.05773545670449077\n",
      "\t\tmax_depth: 10\n",
      "\t\talpha: 0.2707\n",
      "\t\tlambda: 3.7905719704649736\n",
      "\t\tmax_bin: 408\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "study_xgb = optuna.create_study(direction='maximize', study_name=\"XGBClassifier\")\n",
    "func_xgb_0 = lambda trial: objective_xgb_CV(trial, X_trainSet0, Y_trainSet0, Y_trainSet0_class)\n",
    "study_xgb.optimize(func_xgb_0, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "584eb50e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:27:19.063082Z",
     "iopub.status.busy": "2023-01-15T14:27:19.062907Z",
     "iopub.status.idle": "2023-01-15T14:27:19.726498Z",
     "shell.execute_reply": "2023-01-15T14:27:19.725969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0\n",
      "0                    TP  335.000000\n",
      "1                    TN  175.000000\n",
      "2                    FP   49.000000\n",
      "3                    FN   36.000000\n",
      "4              Accuracy    0.857143\n",
      "5             Precision    0.872396\n",
      "6           Sensitivity    0.902965\n",
      "7           Specificity    0.781200\n",
      "8              F1 score    0.887417\n",
      "9   F1 score (weighted)    0.856238\n",
      "10     F1 score (macro)    0.846007\n",
      "11    Balanced Accuracy    0.842107\n",
      "12                  MCC    0.692942\n",
      "13                  NPV    0.829400\n",
      "14              ROC_AUC    0.842107\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_xgb_0 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    #learn\n",
    "eval_set = [(X_testSet0, Y_testSet0)]\n",
    "\n",
    "optimized_xgb_0.fit(X_trainSet0,Y_trainSet0, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "   \n",
    "y_pred_xgb_0 = optimized_xgb_0.predict(X_testSet0)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet0, y_pred_xgb_0)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet0, y_pred_xgb_0)\n",
    "Precision = precision_score(Y_testSet0, y_pred_xgb_0)\n",
    "Sensitivity = recall_score(Y_testSet0, y_pred_xgb_0)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet0, y_pred_xgb_0)      \n",
    "f1_scores_W = f1_score(Y_testSet0, y_pred_xgb_0, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet0, y_pred_xgb_0, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet0, y_pred_xgb_0)\n",
    "MCC = matthews_corrcoef(Y_testSet0, y_pred_xgb_0)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet0, y_pred_xgb_0)\n",
    "    \n",
    "\n",
    "mat_met_xgb_test = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Set0':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })    \n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2278de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:27:19.728553Z",
     "iopub.status.busy": "2023-01-15T14:27:19.728196Z",
     "iopub.status.idle": "2023-01-15T14:31:58.146064Z",
     "shell.execute_reply": "2023-01-15T14:31:58.145695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:23:32,102]\u001b[0m Trial 50 finished with value: 0.8337445265986982 and parameters: {'n_estimators': 739, 'eta': 0.07254967908733163, 'max_depth': 11, 'alpha': 0.1998, 'lambda': 15.444338695379454, 'max_bin': 258}. Best is trial 50 with value: 0.8337445265986982.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:39,182]\u001b[0m Trial 51 finished with value: 0.8323364204419293 and parameters: {'n_estimators': 741, 'eta': 0.07179388369004094, 'max_depth': 11, 'alpha': 0.186, 'lambda': 15.657911105810765, 'max_bin': 255}. Best is trial 50 with value: 0.8337445265986982.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:45,885]\u001b[0m Trial 52 finished with value: 0.8348282925347196 and parameters: {'n_estimators': 746, 'eta': 0.07364768215394632, 'max_depth': 12, 'alpha': 0.1822, 'lambda': 15.21727872169691, 'max_bin': 250}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:52,055]\u001b[0m Trial 53 finished with value: 0.8337465793890331 and parameters: {'n_estimators': 670, 'eta': 0.0820184711779485, 'max_depth': 12, 'alpha': 0.0641, 'lambda': 16.711801889529152, 'max_bin': 284}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:23:58,080]\u001b[0m Trial 54 finished with value: 0.831206369161858 and parameters: {'n_estimators': 673, 'eta': 0.08428093587896211, 'max_depth': 12, 'alpha': 0.11230000000000001, 'lambda': 19.898494905391495, 'max_bin': 278}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:03,314]\u001b[0m Trial 55 finished with value: 0.831826000800213 and parameters: {'n_estimators': 621, 'eta': 0.09302557251879624, 'max_depth': 12, 'alpha': 0.048, 'lambda': 16.810781156486428, 'max_bin': 272}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:09,346]\u001b[0m Trial 56 finished with value: 0.8308638357307838 and parameters: {'n_estimators': 733, 'eta': 0.0819367287726579, 'max_depth': 12, 'alpha': 0.1361, 'lambda': 21.44103478561065, 'max_bin': 295}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:16,297]\u001b[0m Trial 57 finished with value: 0.8335058653330091 and parameters: {'n_estimators': 686, 'eta': 0.06615447584780718, 'max_depth': 12, 'alpha': 0.036000000000000004, 'lambda': 18.18530550132671, 'max_bin': 316}. Best is trial 52 with value: 0.8348282925347196.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:21,547]\u001b[0m Trial 58 finished with value: 0.8364659119780098 and parameters: {'n_estimators': 648, 'eta': 0.09944137812730486, 'max_depth': 12, 'alpha': 0.0429, 'lambda': 17.46791001309951, 'max_bin': 324}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:26,956]\u001b[0m Trial 59 finished with value: 0.8345954674485258 and parameters: {'n_estimators': 513, 'eta': 0.09976170894336796, 'max_depth': 12, 'alpha': 0.0509, 'lambda': 23.84744739710641, 'max_bin': 314}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:32,271]\u001b[0m Trial 60 finished with value: 0.8319881482866552 and parameters: {'n_estimators': 534, 'eta': 0.09960711522311283, 'max_depth': 12, 'alpha': 0.1058, 'lambda': 23.947563966008673, 'max_bin': 311}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:37,424]\u001b[0m Trial 61 finished with value: 0.8284476192255902 and parameters: {'n_estimators': 475, 'eta': 0.09812101926915208, 'max_depth': 12, 'alpha': 0.0413, 'lambda': 18.065428530768084, 'max_bin': 330}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:43,581]\u001b[0m Trial 62 finished with value: 0.8316712720758203 and parameters: {'n_estimators': 404, 'eta': 0.09475422794358093, 'max_depth': 12, 'alpha': 0.0262, 'lambda': 26.905863483453654, 'max_bin': 293}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:50,648]\u001b[0m Trial 63 finished with value: 0.8347451506112786 and parameters: {'n_estimators': 564, 'eta': 0.0879158153531711, 'max_depth': 12, 'alpha': 0.162, 'lambda': 29.742135506498236, 'max_bin': 309}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:24:58,064]\u001b[0m Trial 64 finished with value: 0.8314900707931931 and parameters: {'n_estimators': 509, 'eta': 0.08826757465511012, 'max_depth': 12, 'alpha': 0.1607, 'lambda': 32.07338125010581, 'max_bin': 261}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:04,769]\u001b[0m Trial 65 finished with value: 0.8323359629516311 and parameters: {'n_estimators': 558, 'eta': 0.09246825644656813, 'max_depth': 12, 'alpha': 0.0726, 'lambda': 29.745062084463882, 'max_bin': 303}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:12,410]\u001b[0m Trial 66 finished with value: 0.8301277235012134 and parameters: {'n_estimators': 598, 'eta': 0.08587257801489727, 'max_depth': 11, 'alpha': 0.1231, 'lambda': 34.5949320423868, 'max_bin': 327}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:19,101]\u001b[0m Trial 67 finished with value: 0.8314504764762735 and parameters: {'n_estimators': 651, 'eta': 0.09715087338311779, 'max_depth': 12, 'alpha': 0.0688, 'lambda': 23.19854775749366, 'max_bin': 271}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:26,123]\u001b[0m Trial 68 finished with value: 0.8318800012894467 and parameters: {'n_estimators': 497, 'eta': 0.09084035374687877, 'max_depth': 11, 'alpha': 0.1647, 'lambda': 38.58408413256474, 'max_bin': 288}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:33,067]\u001b[0m Trial 69 finished with value: 0.8292027833592008 and parameters: {'n_estimators': 641, 'eta': 0.07668754165201569, 'max_depth': 11, 'alpha': 0.0016, 'lambda': 20.69709513916522, 'max_bin': 270}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:40,165]\u001b[0m Trial 70 finished with value: 0.8290581366105375 and parameters: {'n_estimators': 584, 'eta': 0.08244971805037532, 'max_depth': 12, 'alpha': 0.23270000000000002, 'lambda': 28.815542738275617, 'max_bin': 258}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:47,087]\u001b[0m Trial 71 finished with value: 0.8294008460390467 and parameters: {'n_estimators': 670, 'eta': 0.06764269009718536, 'max_depth': 12, 'alpha': 0.0424, 'lambda': 18.798578220129293, 'max_bin': 313}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:54,349]\u001b[0m Trial 72 finished with value: 0.8337392780204684 and parameters: {'n_estimators': 549, 'eta': 0.06638859055475087, 'max_depth': 12, 'alpha': 0.0824, 'lambda': 15.722648928909729, 'max_bin': 313}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:25:59,821]\u001b[0m Trial 73 finished with value: 0.8322453075500951 and parameters: {'n_estimators': 446, 'eta': 0.09360515327746095, 'max_depth': 12, 'alpha': 0.1041, 'lambda': 15.968627330890051, 'max_bin': 326}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:05,326]\u001b[0m Trial 74 finished with value: 0.8302549910419549 and parameters: {'n_estimators': 563, 'eta': 0.0874064270819976, 'max_depth': 12, 'alpha': 0.2803, 'lambda': 14.79949023373527, 'max_bin': 306}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:11,910]\u001b[0m Trial 75 finished with value: 0.8325299134189755 and parameters: {'n_estimators': 547, 'eta': 0.07561587370634536, 'max_depth': 11, 'alpha': 0.1371, 'lambda': 19.87662504958196, 'max_bin': 344}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:17,873]\u001b[0m Trial 76 finished with value: 0.8343914055339633 and parameters: {'n_estimators': 601, 'eta': 0.07919452101880187, 'max_depth': 12, 'alpha': 0.2185, 'lambda': 17.21636142757283, 'max_bin': 297}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:24,000]\u001b[0m Trial 77 finished with value: 0.834226322891862 and parameters: {'n_estimators': 620, 'eta': 0.07885414840373392, 'max_depth': 12, 'alpha': 0.2248, 'lambda': 17.00012858397699, 'max_bin': 294}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:29,809]\u001b[0m Trial 78 finished with value: 0.8329207452689911 and parameters: {'n_estimators': 633, 'eta': 0.08389718064421964, 'max_depth': 12, 'alpha': 0.9163, 'lambda': 17.315649790986228, 'max_bin': 295}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:26:35,402]\u001b[0m Trial 79 finished with value: 0.832031209461596 and parameters: {'n_estimators': 607, 'eta': 0.07844929628242395, 'max_depth': 11, 'alpha': 0.2149, 'lambda': 14.392433853546299, 'max_bin': 266}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:42,496]\u001b[0m Trial 80 finished with value: 0.8343089606172814 and parameters: {'n_estimators': 696, 'eta': 0.08087318153001752, 'max_depth': 12, 'alpha': 0.16590000000000002, 'lambda': 22.90505299552212, 'max_bin': 250}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:48,703]\u001b[0m Trial 81 finished with value: 0.831461317032376 and parameters: {'n_estimators': 696, 'eta': 0.08558915959395488, 'max_depth': 12, 'alpha': 0.1641, 'lambda': 23.108294467412716, 'max_bin': 250}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:26:55,296]\u001b[0m Trial 82 finished with value: 0.8321137986053856 and parameters: {'n_estimators': 579, 'eta': 0.08123043051966314, 'max_depth': 12, 'alpha': 0.2298, 'lambda': 21.051218765523572, 'max_bin': 278}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:01,904]\u001b[0m Trial 83 finished with value: 0.8323368417539498 and parameters: {'n_estimators': 657, 'eta': 0.0907813544663117, 'max_depth': 12, 'alpha': 0.16840000000000002, 'lambda': 25.323673794650407, 'max_bin': 288}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:08,508]\u001b[0m Trial 84 finished with value: 0.8320785009710775 and parameters: {'n_estimators': 763, 'eta': 0.07475952946513462, 'max_depth': 12, 'alpha': 0.2071, 'lambda': 19.54296726680478, 'max_bin': 263}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:14,100]\u001b[0m Trial 85 finished with value: 0.8285445591291225 and parameters: {'n_estimators': 607, 'eta': 0.07959218096802767, 'max_depth': 12, 'alpha': 0.1865, 'lambda': 13.166977999213685, 'max_bin': 277}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:19,722]\u001b[0m Trial 86 finished with value: 0.8319480766806493 and parameters: {'n_estimators': 523, 'eta': 0.09972261814466475, 'max_depth': 11, 'alpha': 0.1414, 'lambda': 17.040117963856837, 'max_bin': 321}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:26,007]\u001b[0m Trial 87 finished with value: 0.8349086497888573 and parameters: {'n_estimators': 695, 'eta': 0.09590328015583736, 'max_depth': 12, 'alpha': 0.2929, 'lambda': 22.336709618818574, 'max_bin': 307}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:32,192]\u001b[0m Trial 88 finished with value: 0.8329138510323816 and parameters: {'n_estimators': 693, 'eta': 0.09676470667685634, 'max_depth': 12, 'alpha': 0.058, 'lambda': 24.3511050713125, 'max_bin': 300}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:38,974]\u001b[0m Trial 89 finished with value: 0.8317741209806435 and parameters: {'n_estimators': 633, 'eta': 0.09506140359874952, 'max_depth': 12, 'alpha': 0.2877, 'lambda': 26.645615882764314, 'max_bin': 307}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:45,394]\u001b[0m Trial 90 finished with value: 0.8347064014492022 and parameters: {'n_estimators': 708, 'eta': 0.08726751013802897, 'max_depth': 12, 'alpha': 0.2421, 'lambda': 22.284184478650985, 'max_bin': 332}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:51,828]\u001b[0m Trial 91 finished with value: 0.834022290785499 and parameters: {'n_estimators': 720, 'eta': 0.09048065703157898, 'max_depth': 12, 'alpha': 0.2561, 'lambda': 22.559264744317733, 'max_bin': 334}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:27:58,229]\u001b[0m Trial 92 finished with value: 0.8356291164541523 and parameters: {'n_estimators': 712, 'eta': 0.08930655727678907, 'max_depth': 12, 'alpha': 0.2404, 'lambda': 23.058926370183052, 'max_bin': 340}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:03,266]\u001b[0m Trial 93 finished with value: 0.8326268512150176 and parameters: {'n_estimators': 198, 'eta': 0.08774259822312465, 'max_depth': 12, 'alpha': 0.24730000000000002, 'lambda': 21.916523193199836, 'max_bin': 350}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:09,714]\u001b[0m Trial 94 finished with value: 0.8341768756048303 and parameters: {'n_estimators': 765, 'eta': 0.09247335905417024, 'max_depth': 12, 'alpha': 0.3196, 'lambda': 28.33002416006695, 'max_bin': 318}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:17,199]\u001b[0m Trial 95 finished with value: 0.8352236454621836 and parameters: {'n_estimators': 703, 'eta': 0.09623887471940365, 'max_depth': 12, 'alpha': 0.2238, 'lambda': 39.735515286452426, 'max_bin': 299}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:22,813]\u001b[0m Trial 96 finished with value: 0.8319188297455125 and parameters: {'n_estimators': 710, 'eta': 0.09799228721196683, 'max_depth': 11, 'alpha': 0.2967, 'lambda': 24.276032181137147, 'max_bin': 334}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:29,237]\u001b[0m Trial 97 finished with value: 0.8313411239851574 and parameters: {'n_estimators': 689, 'eta': 0.09491668456478365, 'max_depth': 12, 'alpha': 0.3487, 'lambda': 39.962629796271806, 'max_bin': 324}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:35,894]\u001b[0m Trial 98 finished with value: 0.8347870397741272 and parameters: {'n_estimators': 729, 'eta': 0.08896131112147605, 'max_depth': 12, 'alpha': 0.1764, 'lambda': 32.466838170666676, 'max_bin': 335}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:42,429]\u001b[0m Trial 99 finished with value: 0.8310729039313856 and parameters: {'n_estimators': 725, 'eta': 0.09073044841925415, 'max_depth': 12, 'alpha': 0.2755, 'lambda': 33.74682840870879, 'max_bin': 335}. Best is trial 58 with value: 0.8364659119780098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 100.0\n",
      "\tBest value (f1_score): 0.8365\n",
      "\tBest params:\n",
      "\t\tn_estimators: 648\n",
      "\t\teta: 0.09944137812730486\n",
      "\t\tmax_depth: 12\n",
      "\t\talpha: 0.0429\n",
      "\t\tlambda: 17.46791001309951\n",
      "\t\tmax_bin: 324\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_xgb_1 = lambda trial: objective_xgb_CV(trial, X_trainSet1, Y_trainSet1, Y_trainSet1_class)\n",
    "study_xgb.optimize(func_xgb_1, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "565b2677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:31:58.147834Z",
     "iopub.status.busy": "2023-01-15T14:31:58.147676Z",
     "iopub.status.idle": "2023-01-15T14:31:58.619209Z",
     "shell.execute_reply": "2023-01-15T14:31:58.618788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1\n",
      "0                    TP  335.000000  338.000000\n",
      "1                    TN  175.000000  166.000000\n",
      "2                    FP   49.000000   68.000000\n",
      "3                    FN   36.000000   23.000000\n",
      "4              Accuracy    0.857143    0.847059\n",
      "5             Precision    0.872396    0.832512\n",
      "6           Sensitivity    0.902965    0.936288\n",
      "7           Specificity    0.781200    0.709400\n",
      "8              F1 score    0.887417    0.881356\n",
      "9   F1 score (weighted)    0.856238    0.843410\n",
      "10     F1 score (macro)    0.846007    0.833113\n",
      "11    Balanced Accuracy    0.842107    0.822845\n",
      "12                  MCC    0.692942    0.677472\n",
      "13                  NPV    0.829400    0.878300\n",
      "14              ROC_AUC    0.842107    0.822845\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_1 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet1, Y_testSet1)]\n",
    "optimized_xgb_1.fit(X_trainSet1,Y_trainSet1, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_1 = optimized_xgb_1.predict(X_testSet1)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet1, y_pred_xgb_1)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet1, y_pred_xgb_1)\n",
    "Precision = precision_score(Y_testSet1, y_pred_xgb_1)\n",
    "Sensitivity = recall_score(Y_testSet1, y_pred_xgb_1)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet1, y_pred_xgb_1)      \n",
    "f1_scores_W = f1_score(Y_testSet1, y_pred_xgb_1, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet1, y_pred_xgb_1, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet1, y_pred_xgb_1)\n",
    "MCC = matthews_corrcoef(Y_testSet1, y_pred_xgb_1)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet1, y_pred_xgb_1)\n",
    "\n",
    "\n",
    "set1 = pd.DataFrame({ 'Set1':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set1'] =set1\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33fb1804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:31:58.620883Z",
     "iopub.status.busy": "2023-01-15T14:31:58.620710Z",
     "iopub.status.idle": "2023-01-15T14:36:23.300914Z",
     "shell.execute_reply": "2023-01-15T14:36:23.300490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:28:48,891]\u001b[0m Trial 100 finished with value: 0.8465060225018014 and parameters: {'n_estimators': 823, 'eta': 0.09979824828479529, 'max_depth': 11, 'alpha': 0.2462, 'lambda': 31.25792079291824, 'max_bin': 366}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:28:55,507]\u001b[0m Trial 101 finished with value: 0.8444117669937123 and parameters: {'n_estimators': 812, 'eta': 0.09919444710692936, 'max_depth': 12, 'alpha': 0.2363, 'lambda': 36.340247953005886, 'max_bin': 349}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:01,835]\u001b[0m Trial 102 finished with value: 0.8417523736419369 and parameters: {'n_estimators': 875, 'eta': 0.0996038711392165, 'max_depth': 11, 'alpha': 0.2454, 'lambda': 35.79219020689391, 'max_bin': 363}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:08,544]\u001b[0m Trial 103 finished with value: 0.8431790267764162 and parameters: {'n_estimators': 810, 'eta': 0.09696673622189153, 'max_depth': 11, 'alpha': 0.2515, 'lambda': 36.16328041833729, 'max_bin': 363}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:15,155]\u001b[0m Trial 104 finished with value: 0.8406053270251453 and parameters: {'n_estimators': 871, 'eta': 0.09573519318172408, 'max_depth': 11, 'alpha': 0.2631, 'lambda': 37.465904602250134, 'max_bin': 364}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:21,947]\u001b[0m Trial 105 finished with value: 0.8421251766231774 and parameters: {'n_estimators': 811, 'eta': 0.0962354460868717, 'max_depth': 11, 'alpha': 0.265, 'lambda': 36.98893904487307, 'max_bin': 364}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:28,765]\u001b[0m Trial 106 finished with value: 0.8419171143349956 and parameters: {'n_estimators': 879, 'eta': 0.09627613083903114, 'max_depth': 11, 'alpha': 0.30110000000000003, 'lambda': 36.5360384745166, 'max_bin': 367}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:35,885]\u001b[0m Trial 107 finished with value: 0.8416795932078003 and parameters: {'n_estimators': 876, 'eta': 0.09651788536716917, 'max_depth': 11, 'alpha': 0.3054, 'lambda': 36.50115334778784, 'max_bin': 366}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:42,603]\u001b[0m Trial 108 finished with value: 0.8403804414295534 and parameters: {'n_estimators': 874, 'eta': 0.09825046307592995, 'max_depth': 11, 'alpha': 0.3262, 'lambda': 36.44564177321091, 'max_bin': 367}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:48,816]\u001b[0m Trial 109 finished with value: 0.8421151105400393 and parameters: {'n_estimators': 876, 'eta': 0.09847100666769365, 'max_depth': 11, 'alpha': 0.2606, 'lambda': 36.687175758575826, 'max_bin': 367}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:29:55,772]\u001b[0m Trial 110 finished with value: 0.8441222898249994 and parameters: {'n_estimators': 875, 'eta': 0.09893899598768643, 'max_depth': 11, 'alpha': 0.39030000000000004, 'lambda': 36.685128984567996, 'max_bin': 367}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:03,187]\u001b[0m Trial 111 finished with value: 0.8427756736953187 and parameters: {'n_estimators': 879, 'eta': 0.09854889856252645, 'max_depth': 11, 'alpha': 0.32170000000000004, 'lambda': 36.66081222980433, 'max_bin': 367}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:11,379]\u001b[0m Trial 112 finished with value: 0.8395104545434317 and parameters: {'n_estimators': 870, 'eta': 0.09823940792592484, 'max_depth': 11, 'alpha': 0.3902, 'lambda': 36.60120863170626, 'max_bin': 365}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:18,649]\u001b[0m Trial 113 finished with value: 0.8438323344668568 and parameters: {'n_estimators': 842, 'eta': 0.09358191908204254, 'max_depth': 11, 'alpha': 0.33080000000000004, 'lambda': 35.57318398334765, 'max_bin': 369}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:26,274]\u001b[0m Trial 114 finished with value: 0.839832449486529 and parameters: {'n_estimators': 837, 'eta': 0.09340304953850158, 'max_depth': 11, 'alpha': 0.3518, 'lambda': 37.59553721766896, 'max_bin': 380}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:33,639]\u001b[0m Trial 115 finished with value: 0.8435260313015608 and parameters: {'n_estimators': 809, 'eta': 0.09416504657440294, 'max_depth': 11, 'alpha': 0.3044, 'lambda': 35.08487872088929, 'max_bin': 368}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:41,348]\u001b[0m Trial 116 finished with value: 0.8400620173988834 and parameters: {'n_estimators': 817, 'eta': 0.09367194538888157, 'max_depth': 11, 'alpha': 0.30860000000000004, 'lambda': 35.192860640547714, 'max_bin': 372}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:49,046]\u001b[0m Trial 117 finished with value: 0.8407942329009706 and parameters: {'n_estimators': 899, 'eta': 0.09242905250576972, 'max_depth': 11, 'alpha': 0.3645, 'lambda': 35.05432302712002, 'max_bin': 356}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:30:55,993]\u001b[0m Trial 118 finished with value: 0.8418308487033835 and parameters: {'n_estimators': 841, 'eta': 0.09724842653711677, 'max_depth': 10, 'alpha': 0.3383, 'lambda': 35.64670467700551, 'max_bin': 388}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:02,723]\u001b[0m Trial 119 finished with value: 0.8416719673708515 and parameters: {'n_estimators': 848, 'eta': 0.09985278530705512, 'max_depth': 10, 'alpha': 0.3383, 'lambda': 33.809773574388345, 'max_bin': 389}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:10,273]\u001b[0m Trial 120 finished with value: 0.8440356235037016 and parameters: {'n_estimators': 811, 'eta': 0.09770866670214909, 'max_depth': 10, 'alpha': 0.3886, 'lambda': 38.609462483667464, 'max_bin': 372}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:18,261]\u001b[0m Trial 121 finished with value: 0.8387503068028183 and parameters: {'n_estimators': 810, 'eta': 0.09795355537160343, 'max_depth': 10, 'alpha': 0.38170000000000004, 'lambda': 38.687205385923065, 'max_bin': 371}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:25,213]\u001b[0m Trial 122 finished with value: 0.8406850356492306 and parameters: {'n_estimators': 836, 'eta': 0.09493264229751, 'max_depth': 11, 'alpha': 0.4777, 'lambda': 37.900334860851984, 'max_bin': 378}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:32,489]\u001b[0m Trial 123 finished with value: 0.8416921161311246 and parameters: {'n_estimators': 808, 'eta': 0.09986671053020849, 'max_depth': 10, 'alpha': 0.4072, 'lambda': 35.35431353778449, 'max_bin': 352}. Best is trial 100 with value: 0.8465060225018014.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:39,413]\u001b[0m Trial 124 finished with value: 0.8466250622978458 and parameters: {'n_estimators': 856, 'eta': 0.09745988533979955, 'max_depth': 11, 'alpha': 0.44160000000000005, 'lambda': 35.791026988624694, 'max_bin': 358}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:31:46,729]\u001b[0m Trial 125 finished with value: 0.8403550552030602 and parameters: {'n_estimators': 854, 'eta': 0.092069585589874, 'max_depth': 11, 'alpha': 0.4496, 'lambda': 34.084350102572756, 'max_bin': 388}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:09,835]\u001b[0m Trial 126 finished with value: 0.8353212822712622 and parameters: {'n_estimators': 830, 'eta': 0.012706904677106404, 'max_depth': 11, 'alpha': 0.43010000000000004, 'lambda': 32.78858889327328, 'max_bin': 358}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:17,195]\u001b[0m Trial 127 finished with value: 0.8377802142422898 and parameters: {'n_estimators': 807, 'eta': 0.09417237893101985, 'max_depth': 10, 'alpha': 0.3312, 'lambda': 38.90532055971475, 'max_bin': 372}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:24,478]\u001b[0m Trial 128 finished with value: 0.8402792305461964 and parameters: {'n_estimators': 891, 'eta': 0.097105744817977, 'max_depth': 11, 'alpha': 0.4511, 'lambda': 36.041992211045, 'max_bin': 349}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:32:30,964]\u001b[0m Trial 129 finished with value: 0.841866424767764 and parameters: {'n_estimators': 855, 'eta': 0.09701949792703493, 'max_depth': 10, 'alpha': 0.3635, 'lambda': 33.21746913702682, 'max_bin': 394}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:37,478]\u001b[0m Trial 130 finished with value: 0.8443145966021776 and parameters: {'n_estimators': 858, 'eta': 0.09187159686827594, 'max_depth': 11, 'alpha': 0.3699, 'lambda': 31.23639784247885, 'max_bin': 396}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:44,030]\u001b[0m Trial 131 finished with value: 0.8438953907445266 and parameters: {'n_estimators': 860, 'eta': 0.09441153273104833, 'max_depth': 11, 'alpha': 0.3667, 'lambda': 30.904553341145725, 'max_bin': 360}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:50,743]\u001b[0m Trial 132 finished with value: 0.8410132303904693 and parameters: {'n_estimators': 776, 'eta': 0.09142818854380548, 'max_depth': 11, 'alpha': 0.39440000000000003, 'lambda': 37.19765928842561, 'max_bin': 361}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:32:57,280]\u001b[0m Trial 133 finished with value: 0.8417866348860205 and parameters: {'n_estimators': 824, 'eta': 0.09357151148831988, 'max_depth': 11, 'alpha': 0.274, 'lambda': 31.634608539711188, 'max_bin': 377}. Best is trial 124 with value: 0.8466250622978458.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:03,744]\u001b[0m Trial 134 finished with value: 0.8466591551930043 and parameters: {'n_estimators': 800, 'eta': 0.09523263614439825, 'max_depth': 11, 'alpha': 0.47040000000000004, 'lambda': 31.295709075795422, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:10,540]\u001b[0m Trial 135 finished with value: 0.8383030297073948 and parameters: {'n_estimators': 801, 'eta': 0.09471469103859115, 'max_depth': 11, 'alpha': 0.46690000000000004, 'lambda': 31.091834524462943, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:18,120]\u001b[0m Trial 136 finished with value: 0.8396375732326241 and parameters: {'n_estimators': 860, 'eta': 0.09108493106188038, 'max_depth': 11, 'alpha': 0.5078, 'lambda': 34.40211358091503, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:26,137]\u001b[0m Trial 137 finished with value: 0.8396785812729796 and parameters: {'n_estimators': 823, 'eta': 0.08959030262506036, 'max_depth': 11, 'alpha': 0.4198, 'lambda': 38.16943228432105, 'max_bin': 384}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:33,416]\u001b[0m Trial 138 finished with value: 0.8393790452429396 and parameters: {'n_estimators': 790, 'eta': 0.09402307867463006, 'max_depth': 11, 'alpha': 0.5313, 'lambda': 37.19107434962633, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:39,999]\u001b[0m Trial 139 finished with value: 0.8458615674052149 and parameters: {'n_estimators': 897, 'eta': 0.09815736407641297, 'max_depth': 11, 'alpha': 0.4874, 'lambda': 29.948213847560705, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:46,303]\u001b[0m Trial 140 finished with value: 0.8412650796209666 and parameters: {'n_estimators': 845, 'eta': 0.09566445905384788, 'max_depth': 11, 'alpha': 0.4958, 'lambda': 30.276932246692695, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:52,565]\u001b[0m Trial 141 finished with value: 0.8431030818702023 and parameters: {'n_estimators': 892, 'eta': 0.0999212850962828, 'max_depth': 11, 'alpha': 0.4667, 'lambda': 31.40316032657754, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:33:59,752]\u001b[0m Trial 142 finished with value: 0.8452886748317437 and parameters: {'n_estimators': 887, 'eta': 0.09808318753466534, 'max_depth': 11, 'alpha': 0.5847, 'lambda': 31.28606853698805, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:06,520]\u001b[0m Trial 143 finished with value: 0.8417055699310559 and parameters: {'n_estimators': 892, 'eta': 0.097903554884053, 'max_depth': 11, 'alpha': 0.5720000000000001, 'lambda': 28.75654699541444, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:13,837]\u001b[0m Trial 144 finished with value: 0.8425703696638625 and parameters: {'n_estimators': 900, 'eta': 0.0923502690900582, 'max_depth': 11, 'alpha': 0.6231, 'lambda': 31.58149923322322, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:20,077]\u001b[0m Trial 145 finished with value: 0.8449464946713039 and parameters: {'n_estimators': 862, 'eta': 0.09998928475908679, 'max_depth': 11, 'alpha': 0.6718000000000001, 'lambda': 30.53662576196829, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:26,915]\u001b[0m Trial 146 finished with value: 0.8437538884410569 and parameters: {'n_estimators': 866, 'eta': 0.09977297486346304, 'max_depth': 11, 'alpha': 0.7315, 'lambda': 30.159154798888682, 'max_bin': 340}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:43,450]\u001b[0m Trial 147 finished with value: 0.8391630849151446 and parameters: {'n_estimators': 859, 'eta': 0.031282890817554344, 'max_depth': 11, 'alpha': 0.7030000000000001, 'lambda': 30.66748089699456, 'max_bin': 339}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:50,506]\u001b[0m Trial 148 finished with value: 0.8423088614557759 and parameters: {'n_estimators': 832, 'eta': 0.09454944568376068, 'max_depth': 10, 'alpha': 0.7342000000000001, 'lambda': 29.787715101809848, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:34:57,172]\u001b[0m Trial 149 finished with value: 0.8389546487171538 and parameters: {'n_estimators': 859, 'eta': 0.0961307300219303, 'max_depth': 11, 'alpha': 0.6767000000000001, 'lambda': 28.145727555854847, 'max_bin': 348}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 150.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_2 = lambda trial: objective_xgb_CV(trial, X_trainSet2, Y_trainSet2, Y_trainSet2_class)\n",
    "study_xgb.optimize(func_xgb_2, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c671e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:36:23.302499Z",
     "iopub.status.busy": "2023-01-15T14:36:23.302381Z",
     "iopub.status.idle": "2023-01-15T14:36:23.678275Z",
     "shell.execute_reply": "2023-01-15T14:36:23.677794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2\n",
      "0                    TP  335.000000  338.000000  320.000000\n",
      "1                    TN  175.000000  166.000000  175.000000\n",
      "2                    FP   49.000000   68.000000   49.000000\n",
      "3                    FN   36.000000   23.000000   51.000000\n",
      "4              Accuracy    0.857143    0.847059    0.831933\n",
      "5             Precision    0.872396    0.832512    0.867209\n",
      "6           Sensitivity    0.902965    0.936288    0.862534\n",
      "7           Specificity    0.781200    0.709400    0.781200\n",
      "8              F1 score    0.887417    0.881356    0.864865\n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079\n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321\n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892\n",
      "12                  MCC    0.692942    0.677472    0.642663\n",
      "13                  NPV    0.829400    0.878300    0.774300\n",
      "14              ROC_AUC    0.842107    0.822845    0.821892\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_2 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet2, Y_testSet2)]\n",
    "optimized_xgb_2.fit(X_trainSet2,Y_trainSet2, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_2 = optimized_xgb_2.predict(X_testSet2)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet2, y_pred_xgb_2)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet2, y_pred_xgb_2)\n",
    "Precision = precision_score(Y_testSet2, y_pred_xgb_2)\n",
    "Sensitivity = recall_score(Y_testSet2, y_pred_xgb_2)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet2, y_pred_xgb_2)      \n",
    "f1_scores_W = f1_score(Y_testSet2, y_pred_xgb_2, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet2, y_pred_xgb_2, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet2, y_pred_xgb_2)\n",
    "MCC = matthews_corrcoef(Y_testSet2, y_pred_xgb_2)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet2, y_pred_xgb_2)\n",
    "\n",
    "\n",
    "Set2 = pd.DataFrame({ 'Set2':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set2'] =Set2\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c547ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:36:23.679767Z",
     "iopub.status.busy": "2023-01-15T14:36:23.679651Z",
     "iopub.status.idle": "2023-01-15T14:41:06.397055Z",
     "shell.execute_reply": "2023-01-15T14:41:06.396631Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:35:03,802]\u001b[0m Trial 150 finished with value: 0.8343796811684621 and parameters: {'n_estimators': 776, 'eta': 0.09980100230702509, 'max_depth': 11, 'alpha': 0.7571, 'lambda': 33.16171557552811, 'max_bin': 376}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:10,316]\u001b[0m Trial 151 finished with value: 0.8344961466940306 and parameters: {'n_estimators': 840, 'eta': 0.09991222781230953, 'max_depth': 11, 'alpha': 0.7829, 'lambda': 31.882966941777344, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:16,419]\u001b[0m Trial 152 finished with value: 0.8338932857552379 and parameters: {'n_estimators': 863, 'eta': 0.09750705173718062, 'max_depth': 11, 'alpha': 0.541, 'lambda': 29.3565252691507, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:22,283]\u001b[0m Trial 153 finished with value: 0.8294140110677288 and parameters: {'n_estimators': 887, 'eta': 0.09364116440822827, 'max_depth': 11, 'alpha': 0.5805, 'lambda': 31.020175291555283, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:28,644]\u001b[0m Trial 154 finished with value: 0.8349523298040673 and parameters: {'n_estimators': 822, 'eta': 0.09769967934883801, 'max_depth': 11, 'alpha': 0.47440000000000004, 'lambda': 32.64657681028612, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:31,420]\u001b[0m Trial 155 finished with value: 0.8359711604551677 and parameters: {'n_estimators': 95, 'eta': 0.09550743601253354, 'max_depth': 11, 'alpha': 0.8095, 'lambda': 29.980777364539207, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:38,613]\u001b[0m Trial 156 finished with value: 0.8326412538410481 and parameters: {'n_estimators': 900, 'eta': 0.09170156096048751, 'max_depth': 11, 'alpha': 0.4375, 'lambda': 31.089853072326157, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:45,345]\u001b[0m Trial 157 finished with value: 0.8328442274755462 and parameters: {'n_estimators': 852, 'eta': 0.097702227774424, 'max_depth': 11, 'alpha': 0.6455000000000001, 'lambda': 34.79171356473335, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:35:51,186]\u001b[0m Trial 158 finished with value: 0.8372039167314476 and parameters: {'n_estimators': 796, 'eta': 0.09997758187019769, 'max_depth': 11, 'alpha': 0.45990000000000003, 'lambda': 33.5810124169572, 'max_bin': 340}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:11,307]\u001b[0m Trial 159 finished with value: 0.8334954378831014 and parameters: {'n_estimators': 836, 'eta': 0.022528867992248937, 'max_depth': 10, 'alpha': 0.5148, 'lambda': 31.934668732323175, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:19,250]\u001b[0m Trial 160 finished with value: 0.8256613739776546 and parameters: {'n_estimators': 866, 'eta': 0.0896255573375452, 'max_depth': 5, 'alpha': 0.6816, 'lambda': 27.57941005248111, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:26,456]\u001b[0m Trial 161 finished with value: 0.8333622814640792 and parameters: {'n_estimators': 881, 'eta': 0.09825431953328341, 'max_depth': 11, 'alpha': 0.398, 'lambda': 39.400527335333244, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:33,465]\u001b[0m Trial 162 finished with value: 0.8372086864137686 and parameters: {'n_estimators': 884, 'eta': 0.09553053804584068, 'max_depth': 11, 'alpha': 0.3678, 'lambda': 29.342456264894594, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:40,503]\u001b[0m Trial 163 finished with value: 0.8337433525768503 and parameters: {'n_estimators': 844, 'eta': 0.09313805308697175, 'max_depth': 11, 'alpha': 0.4162, 'lambda': 34.411079034566505, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:47,977]\u001b[0m Trial 164 finished with value: 0.8344040972724922 and parameters: {'n_estimators': 818, 'eta': 0.09849359147714264, 'max_depth': 11, 'alpha': 0.38780000000000003, 'lambda': 35.819230210555006, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:36:53,994]\u001b[0m Trial 165 finished with value: 0.8357445997654155 and parameters: {'n_estimators': 867, 'eta': 0.09998230732626516, 'max_depth': 11, 'alpha': 0.4796, 'lambda': 30.32398990287865, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:00,247]\u001b[0m Trial 166 finished with value: 0.8327431226644192 and parameters: {'n_estimators': 799, 'eta': 0.09585405610035655, 'max_depth': 11, 'alpha': 0.3536, 'lambda': 32.72041513562458, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:07,360]\u001b[0m Trial 167 finished with value: 0.8313496857443002 and parameters: {'n_estimators': 882, 'eta': 0.09443827353908049, 'max_depth': 11, 'alpha': 0.6128, 'lambda': 37.79402936834141, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:14,173]\u001b[0m Trial 168 finished with value: 0.8313218832818559 and parameters: {'n_estimators': 828, 'eta': 0.09709387727318414, 'max_depth': 11, 'alpha': 0.43870000000000003, 'lambda': 31.51336870427537, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:21,535]\u001b[0m Trial 169 finished with value: 0.8295142780448279 and parameters: {'n_estimators': 850, 'eta': 0.09214847966310803, 'max_depth': 7, 'alpha': 0.4965, 'lambda': 26.130708930665076, 'max_bin': 414}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:27,824]\u001b[0m Trial 170 finished with value: 0.8347411037367513 and parameters: {'n_estimators': 777, 'eta': 0.09835970633998098, 'max_depth': 11, 'alpha': 0.3153, 'lambda': 34.92708794492498, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:35,276]\u001b[0m Trial 171 finished with value: 0.8344095377022059 and parameters: {'n_estimators': 888, 'eta': 0.0927409554408542, 'max_depth': 11, 'alpha': 0.6377, 'lambda': 30.831648852450243, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:37:57,619]\u001b[0m Trial 172 finished with value: 0.7783204327031632 and parameters: {'n_estimators': 874, 'eta': 0.0010225047049762861, 'max_depth': 11, 'alpha': 0.6241, 'lambda': 32.08644711218745, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:04,842]\u001b[0m Trial 173 finished with value: 0.8332466655425488 and parameters: {'n_estimators': 899, 'eta': 0.09626026032768858, 'max_depth': 11, 'alpha': 0.6053000000000001, 'lambda': 29.21966781127991, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:10,772]\u001b[0m Trial 174 finished with value: 0.8342119880896485 and parameters: {'n_estimators': 859, 'eta': 0.09390176430866466, 'max_depth': 9, 'alpha': 0.5616, 'lambda': 30.55251268501127, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:17,738]\u001b[0m Trial 175 finished with value: 0.8319553549834307 and parameters: {'n_estimators': 840, 'eta': 0.0914612650697038, 'max_depth': 11, 'alpha': 0.3784, 'lambda': 33.23205798207567, 'max_bin': 344}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:25,094]\u001b[0m Trial 176 finished with value: 0.8275508526518293 and parameters: {'n_estimators': 814, 'eta': 0.09980920170976729, 'max_depth': 11, 'alpha': 0.6777000000000001, 'lambda': 31.570668959974828, 'max_bin': 384}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:32,290]\u001b[0m Trial 177 finished with value: 0.8349305402254525 and parameters: {'n_estimators': 876, 'eta': 0.09703039624593432, 'max_depth': 11, 'alpha': 0.5889, 'lambda': 35.68592079271464, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:38,807]\u001b[0m Trial 178 finished with value: 0.835660859554129 and parameters: {'n_estimators': 853, 'eta': 0.0950109923757459, 'max_depth': 11, 'alpha': 0.661, 'lambda': 27.746173243930016, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:38:46,516]\u001b[0m Trial 179 finished with value: 0.8330073626506362 and parameters: {'n_estimators': 899, 'eta': 0.08593516612459254, 'max_depth': 11, 'alpha': 0.4209, 'lambda': 38.51127669375342, 'max_bin': 338}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:53,070]\u001b[0m Trial 180 finished with value: 0.8313774058458842 and parameters: {'n_estimators': 900, 'eta': 0.08963082984146516, 'max_depth': 10, 'alpha': 0.6982, 'lambda': 32.103514145295456, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:38:58,826]\u001b[0m Trial 181 finished with value: 0.8310685077706621 and parameters: {'n_estimators': 828, 'eta': 0.09456274491682629, 'max_depth': 9, 'alpha': 0.7344, 'lambda': 30.06787404248494, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:05,015]\u001b[0m Trial 182 finished with value: 0.8361878213481383 and parameters: {'n_estimators': 832, 'eta': 0.09819430475278254, 'max_depth': 10, 'alpha': 0.7064, 'lambda': 28.568640462042076, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:12,247]\u001b[0m Trial 183 finished with value: 0.8321639433238955 and parameters: {'n_estimators': 867, 'eta': 0.09578315867286409, 'max_depth': 11, 'alpha': 0.7341000000000001, 'lambda': 31.43434871800317, 'max_bin': 351}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:19,201]\u001b[0m Trial 184 finished with value: 0.8322100086137795 and parameters: {'n_estimators': 799, 'eta': 0.09274391619656189, 'max_depth': 10, 'alpha': 0.7651, 'lambda': 29.986334438915765, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:25,347]\u001b[0m Trial 185 finished with value: 0.8326701517023194 and parameters: {'n_estimators': 843, 'eta': 0.09993660777518945, 'max_depth': 11, 'alpha': 0.7352000000000001, 'lambda': 33.791910234961556, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:31,423]\u001b[0m Trial 186 finished with value: 0.8345676519383545 and parameters: {'n_estimators': 865, 'eta': 0.09710702255799018, 'max_depth': 11, 'alpha': 0.31880000000000003, 'lambda': 29.49877040173357, 'max_bin': 376}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:38,368]\u001b[0m Trial 187 finished with value: 0.8318193894705141 and parameters: {'n_estimators': 758, 'eta': 0.09430855064816665, 'max_depth': 10, 'alpha': 0.34540000000000004, 'lambda': 36.344811748853026, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:45,130]\u001b[0m Trial 188 finished with value: 0.8316768526360783 and parameters: {'n_estimators': 820, 'eta': 0.09752168679517136, 'max_depth': 11, 'alpha': 0.4874, 'lambda': 37.26333936534074, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:51,839]\u001b[0m Trial 189 finished with value: 0.8298161165534159 and parameters: {'n_estimators': 881, 'eta': 0.09111670486446574, 'max_depth': 8, 'alpha': 0.4606, 'lambda': 32.674850755132944, 'max_bin': 372}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:39:58,686]\u001b[0m Trial 190 finished with value: 0.8322988759834683 and parameters: {'n_estimators': 849, 'eta': 0.09524018473822328, 'max_depth': 11, 'alpha': 0.29450000000000004, 'lambda': 30.731350058445425, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:05,938]\u001b[0m Trial 191 finished with value: 0.8322660949822336 and parameters: {'n_estimators': 807, 'eta': 0.09644538731390796, 'max_depth': 11, 'alpha': 0.2661, 'lambda': 38.02746998621381, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:19,450]\u001b[0m Trial 192 finished with value: 0.8318692754262387 and parameters: {'n_estimators': 789, 'eta': 0.039794659453618084, 'max_depth': 11, 'alpha': 0.2806, 'lambda': 36.85522401621839, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:25,713]\u001b[0m Trial 193 finished with value: 0.8328976488173758 and parameters: {'n_estimators': 272, 'eta': 0.09836382552206463, 'max_depth': 11, 'alpha': 0.4036, 'lambda': 35.07882950387521, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:32,640]\u001b[0m Trial 194 finished with value: 0.8280602950596968 and parameters: {'n_estimators': 813, 'eta': 0.09997256673054752, 'max_depth': 11, 'alpha': 0.36510000000000004, 'lambda': 35.873851976483444, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:40,822]\u001b[0m Trial 195 finished with value: 0.8336396185447574 and parameters: {'n_estimators': 831, 'eta': 0.09317320201210712, 'max_depth': 11, 'alpha': 0.33180000000000004, 'lambda': 37.05971705405186, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:47,873]\u001b[0m Trial 196 finished with value: 0.8287212919678097 and parameters: {'n_estimators': 865, 'eta': 0.09614275060163416, 'max_depth': 11, 'alpha': 0.4373, 'lambda': 39.02547625807401, 'max_bin': 374}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:40:54,405]\u001b[0m Trial 197 finished with value: 0.8383223727725604 and parameters: {'n_estimators': 369, 'eta': 0.09821621875232904, 'max_depth': 11, 'alpha': 0.6607000000000001, 'lambda': 31.38864466402017, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:01,136]\u001b[0m Trial 198 finished with value: 0.8310947404345708 and parameters: {'n_estimators': 883, 'eta': 0.09420851200179077, 'max_depth': 11, 'alpha': 0.24930000000000002, 'lambda': 34.324844784710805, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:08,036]\u001b[0m Trial 199 finished with value: 0.8303543634207831 and parameters: {'n_estimators': 845, 'eta': 0.09605906913409917, 'max_depth': 11, 'alpha': 0.8505, 'lambda': 29.02602754307836, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 200.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_3 = lambda trial: objective_xgb_CV(trial, X_trainSet3, Y_trainSet3, Y_trainSet3_class)\n",
    "study_xgb.optimize(func_xgb_3, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0b40dc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:41:06.398853Z",
     "iopub.status.busy": "2023-01-15T14:41:06.398738Z",
     "iopub.status.idle": "2023-01-15T14:41:06.880866Z",
     "shell.execute_reply": "2023-01-15T14:41:06.880441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000\n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000\n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000\n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000\n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782\n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321\n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134\n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000\n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318\n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177\n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320\n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083\n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123\n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600\n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_3 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet3, Y_testSet3)]\n",
    "optimized_xgb_3.fit(X_trainSet3,Y_trainSet3, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_3 = optimized_xgb_3.predict(X_testSet3)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet3, y_pred_xgb_3)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet3, y_pred_xgb_3)\n",
    "Precision = precision_score(Y_testSet3, y_pred_xgb_3)\n",
    "Sensitivity = recall_score(Y_testSet3, y_pred_xgb_3)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet3, y_pred_xgb_3)      \n",
    "f1_scores_W = f1_score(Y_testSet3, y_pred_xgb_3, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet3, y_pred_xgb_3, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet3, y_pred_xgb_3)\n",
    "MCC = matthews_corrcoef(Y_testSet3, y_pred_xgb_3)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet3, y_pred_xgb_3)\n",
    "\n",
    "\n",
    "Set3 = pd.DataFrame({ 'Set3':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set3'] =Set3\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5e7f6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:41:06.882612Z",
     "iopub.status.busy": "2023-01-15T14:41:06.882494Z",
     "iopub.status.idle": "2023-01-15T14:45:44.121136Z",
     "shell.execute_reply": "2023-01-15T14:45:44.120697Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:41:15,711]\u001b[0m Trial 200 finished with value: 0.8272587913384444 and parameters: {'n_estimators': 829, 'eta': 0.09223570008511958, 'max_depth': 11, 'alpha': 0.2848, 'lambda': 30.29634774989512, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:21,778]\u001b[0m Trial 201 finished with value: 0.8292641889829712 and parameters: {'n_estimators': 879, 'eta': 0.09847607065563564, 'max_depth': 11, 'alpha': 0.2626, 'lambda': 36.9597390085256, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:27,969]\u001b[0m Trial 202 finished with value: 0.8301877916721357 and parameters: {'n_estimators': 860, 'eta': 0.09764396052257097, 'max_depth': 11, 'alpha': 0.2058, 'lambda': 36.315423457297264, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:34,271]\u001b[0m Trial 203 finished with value: 0.8297910009646955 and parameters: {'n_estimators': 888, 'eta': 0.09986854963787065, 'max_depth': 11, 'alpha': 0.5194, 'lambda': 37.85550405414695, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:41,181]\u001b[0m Trial 204 finished with value: 0.8299653719627667 and parameters: {'n_estimators': 847, 'eta': 0.09530133393341791, 'max_depth': 11, 'alpha': 0.3022, 'lambda': 35.84373275056189, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:47,370]\u001b[0m Trial 205 finished with value: 0.8297888900035387 and parameters: {'n_estimators': 809, 'eta': 0.09726121549487404, 'max_depth': 11, 'alpha': 0.6334000000000001, 'lambda': 32.26330133034441, 'max_bin': 402}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:41:53,663]\u001b[0m Trial 206 finished with value: 0.8248125043514307 and parameters: {'n_estimators': 873, 'eta': 0.09396197762320753, 'max_depth': 11, 'alpha': 0.3865, 'lambda': 35.45548586235397, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:00,081]\u001b[0m Trial 207 finished with value: 0.8312263531372258 and parameters: {'n_estimators': 896, 'eta': 0.09801312271259177, 'max_depth': 11, 'alpha': 0.26130000000000003, 'lambda': 36.72085666003904, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:06,739]\u001b[0m Trial 208 finished with value: 0.8290416874470026 and parameters: {'n_estimators': 785, 'eta': 0.09998064057551156, 'max_depth': 11, 'alpha': 0.21830000000000002, 'lambda': 30.79341779989276, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:13,639]\u001b[0m Trial 209 finished with value: 0.8319327840776598 and parameters: {'n_estimators': 862, 'eta': 0.09593093986622299, 'max_depth': 11, 'alpha': 0.22990000000000002, 'lambda': 38.68612719817716, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:20,209]\u001b[0m Trial 210 finished with value: 0.817862591023389 and parameters: {'n_estimators': 828, 'eta': 0.09081037325838386, 'max_depth': 6, 'alpha': 0.3205, 'lambda': 29.71816461010248, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:27,438]\u001b[0m Trial 211 finished with value: 0.8271644995553162 and parameters: {'n_estimators': 879, 'eta': 0.09610652712851271, 'max_depth': 11, 'alpha': 0.2822, 'lambda': 36.48405918018674, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:34,209]\u001b[0m Trial 212 finished with value: 0.8281583864207697 and parameters: {'n_estimators': 898, 'eta': 0.09784591535855611, 'max_depth': 11, 'alpha': 0.3048, 'lambda': 37.50474531676571, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:40,093]\u001b[0m Trial 213 finished with value: 0.8257243672042266 and parameters: {'n_estimators': 874, 'eta': 0.09307844250902486, 'max_depth': 11, 'alpha': 0.3511, 'lambda': 35.30030150488693, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:46,278]\u001b[0m Trial 214 finished with value: 0.8310705197492123 and parameters: {'n_estimators': 851, 'eta': 0.09526311997156342, 'max_depth': 11, 'alpha': 0.23820000000000002, 'lambda': 34.37942189794684, 'max_bin': 351}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:52,868]\u001b[0m Trial 215 finished with value: 0.8284627770158843 and parameters: {'n_estimators': 841, 'eta': 0.09997155125466958, 'max_depth': 11, 'alpha': 0.7150000000000001, 'lambda': 36.36932450254217, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:42:59,552]\u001b[0m Trial 216 finished with value: 0.8291560565210621 and parameters: {'n_estimators': 865, 'eta': 0.097118787911535, 'max_depth': 11, 'alpha': 0.33480000000000004, 'lambda': 37.593466556370764, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:06,044]\u001b[0m Trial 217 finished with value: 0.8296441984237356 and parameters: {'n_estimators': 883, 'eta': 0.09448643077553054, 'max_depth': 11, 'alpha': 0.758, 'lambda': 31.45365825782639, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:12,604]\u001b[0m Trial 218 finished with value: 0.832012117936977 and parameters: {'n_estimators': 900, 'eta': 0.09805864468178417, 'max_depth': 11, 'alpha': 0.45640000000000003, 'lambda': 32.82958776065352, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:19,298]\u001b[0m Trial 219 finished with value: 0.8241204163844458 and parameters: {'n_estimators': 819, 'eta': 0.08814313682775418, 'max_depth': 11, 'alpha': 0.29250000000000004, 'lambda': 38.27587890949086, 'max_bin': 350}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:25,342]\u001b[0m Trial 220 finished with value: 0.8267143620269428 and parameters: {'n_estimators': 804, 'eta': 0.09640843289896574, 'max_depth': 9, 'alpha': 0.3608, 'lambda': 30.569003517526717, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:31,942]\u001b[0m Trial 221 finished with value: 0.8290591532388879 and parameters: {'n_estimators': 855, 'eta': 0.09818182681775196, 'max_depth': 10, 'alpha': 0.5007, 'lambda': 33.59789409975174, 'max_bin': 394}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:38,451]\u001b[0m Trial 222 finished with value: 0.8270101277933604 and parameters: {'n_estimators': 861, 'eta': 0.09634859861915188, 'max_depth': 10, 'alpha': 0.3778, 'lambda': 34.733553131356075, 'max_bin': 397}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:45,398]\u001b[0m Trial 223 finished with value: 0.8295965881265236 and parameters: {'n_estimators': 839, 'eta': 0.09352205674035927, 'max_depth': 10, 'alpha': 0.4068, 'lambda': 33.31657246146005, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:51,961]\u001b[0m Trial 224 finished with value: 0.8304298144468374 and parameters: {'n_estimators': 874, 'eta': 0.09810621225705135, 'max_depth': 10, 'alpha': 0.3703, 'lambda': 32.0663558412882, 'max_bin': 390}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:43:58,395]\u001b[0m Trial 225 finished with value: 0.8306163379412193 and parameters: {'n_estimators': 855, 'eta': 0.09521855850408142, 'max_depth': 11, 'alpha': 0.31370000000000003, 'lambda': 31.359556850125415, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:04,509]\u001b[0m Trial 226 finished with value: 0.8270792098339872 and parameters: {'n_estimators': 831, 'eta': 0.09987911303475853, 'max_depth': 11, 'alpha': 0.2543, 'lambda': 36.02511926789669, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:10,764]\u001b[0m Trial 227 finished with value: 0.8289342889993179 and parameters: {'n_estimators': 883, 'eta': 0.09204399335307978, 'max_depth': 10, 'alpha': 0.34790000000000004, 'lambda': 35.278961093716994, 'max_bin': 384}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:17,216]\u001b[0m Trial 228 finished with value: 0.832706345509797 and parameters: {'n_estimators': 817, 'eta': 0.09627940130479215, 'max_depth': 11, 'alpha': 0.4732, 'lambda': 29.799911759282644, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:44:23,577]\u001b[0m Trial 229 finished with value: 0.8312896727599158 and parameters: {'n_estimators': 772, 'eta': 0.09821742278381843, 'max_depth': 11, 'alpha': 0.7861, 'lambda': 32.58827114419487, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:29,378]\u001b[0m Trial 230 finished with value: 0.8310413383152344 and parameters: {'n_estimators': 795, 'eta': 0.0939782370630402, 'max_depth': 11, 'alpha': 0.4228, 'lambda': 36.89301137233637, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:35,376]\u001b[0m Trial 231 finished with value: 0.8290480187676985 and parameters: {'n_estimators': 839, 'eta': 0.09691527971914354, 'max_depth': 10, 'alpha': 0.33540000000000003, 'lambda': 35.60486202806809, 'max_bin': 393}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:41,614]\u001b[0m Trial 232 finished with value: 0.830326805471084 and parameters: {'n_estimators': 851, 'eta': 0.09997484795440219, 'max_depth': 10, 'alpha': 0.3305, 'lambda': 36.38487388745563, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:47,810]\u001b[0m Trial 233 finished with value: 0.8310798148533983 and parameters: {'n_estimators': 873, 'eta': 0.09678019997138608, 'max_depth': 10, 'alpha': 0.28040000000000004, 'lambda': 30.879923323181114, 'max_bin': 405}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:44:54,923]\u001b[0m Trial 234 finished with value: 0.8282444429787347 and parameters: {'n_estimators': 838, 'eta': 0.09546566963238425, 'max_depth': 10, 'alpha': 0.3452, 'lambda': 35.00010008962061, 'max_bin': 399}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:20,014]\u001b[0m Trial 235 finished with value: 0.8005910796726858 and parameters: {'n_estimators': 885, 'eta': 0.003995344756112018, 'max_depth': 10, 'alpha': 0.37320000000000003, 'lambda': 36.97714207072349, 'max_bin': 386}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:26,537]\u001b[0m Trial 236 finished with value: 0.831911553637347 and parameters: {'n_estimators': 900, 'eta': 0.09786068939635219, 'max_depth': 11, 'alpha': 0.3083, 'lambda': 31.998887926339936, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:33,143]\u001b[0m Trial 237 finished with value: 0.830595166696974 and parameters: {'n_estimators': 862, 'eta': 0.09287060852893343, 'max_depth': 11, 'alpha': 0.3982, 'lambda': 35.75832598011438, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:39,145]\u001b[0m Trial 238 finished with value: 0.8302968395942161 and parameters: {'n_estimators': 848, 'eta': 0.09458958071832674, 'max_depth': 11, 'alpha': 0.6839000000000001, 'lambda': 34.48054589702708, 'max_bin': 392}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:45,181]\u001b[0m Trial 239 finished with value: 0.8254929579114471 and parameters: {'n_estimators': 818, 'eta': 0.09832025282589317, 'max_depth': 9, 'alpha': 0.275, 'lambda': 33.367788673651766, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:51,657]\u001b[0m Trial 240 finished with value: 0.8291320346484433 and parameters: {'n_estimators': 875, 'eta': 0.09659481995034218, 'max_depth': 11, 'alpha': 0.5474, 'lambda': 30.282637106245673, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:45:58,900]\u001b[0m Trial 241 finished with value: 0.8289764301362244 and parameters: {'n_estimators': 823, 'eta': 0.09022979557160953, 'max_depth': 11, 'alpha': 0.2584, 'lambda': 31.434817879103782, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:05,255]\u001b[0m Trial 242 finished with value: 0.8298267612556478 and parameters: {'n_estimators': 795, 'eta': 0.09372808429803801, 'max_depth': 11, 'alpha': 0.29600000000000004, 'lambda': 31.39380215756957, 'max_bin': 380}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:10,679]\u001b[0m Trial 243 finished with value: 0.8282514690508818 and parameters: {'n_estimators': 832, 'eta': 0.0986502708008089, 'max_depth': 11, 'alpha': 0.2295, 'lambda': 30.580401978062643, 'max_bin': 388}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:16,924]\u001b[0m Trial 244 finished with value: 0.8296128062177794 and parameters: {'n_estimators': 811, 'eta': 0.09183899500232615, 'max_depth': 11, 'alpha': 0.2695, 'lambda': 28.887474360679235, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:23,144]\u001b[0m Trial 245 finished with value: 0.8284752073272481 and parameters: {'n_estimators': 862, 'eta': 0.09550069264457696, 'max_depth': 11, 'alpha': 0.36000000000000004, 'lambda': 32.2336104549086, 'max_bin': 376}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:28,904]\u001b[0m Trial 246 finished with value: 0.8298430896504894 and parameters: {'n_estimators': 846, 'eta': 0.09692771425863896, 'max_depth': 11, 'alpha': 0.3229, 'lambda': 37.555880221490625, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:35,304]\u001b[0m Trial 247 finished with value: 0.8294741836742763 and parameters: {'n_estimators': 884, 'eta': 0.0940096096992607, 'max_depth': 11, 'alpha': 0.6015, 'lambda': 36.330001878704756, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:40,904]\u001b[0m Trial 248 finished with value: 0.8299558136595827 and parameters: {'n_estimators': 825, 'eta': 0.09983740035569878, 'max_depth': 11, 'alpha': 0.7309, 'lambda': 31.67219538146296, 'max_bin': 337}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:46:46,628]\u001b[0m Trial 249 finished with value: 0.8284047380916416 and parameters: {'n_estimators': 867, 'eta': 0.09826201428408209, 'max_depth': 11, 'alpha': 0.24880000000000002, 'lambda': 29.93112001584629, 'max_bin': 401}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 250.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_4 = lambda trial: objective_xgb_CV(trial, X_trainSet4, Y_trainSet4, Y_trainSet4_class)\n",
    "study_xgb.optimize(func_xgb_4, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ea2f04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:45:44.122828Z",
     "iopub.status.busy": "2023-01-15T14:45:44.122711Z",
     "iopub.status.idle": "2023-01-15T14:45:44.573719Z",
     "shell.execute_reply": "2023-01-15T14:45:44.573267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4  \n",
      "0   344.000000  \n",
      "1   161.000000  \n",
      "2    64.000000  \n",
      "3    26.000000  \n",
      "4     0.848739  \n",
      "5     0.843137  \n",
      "6     0.929730  \n",
      "7     0.715600  \n",
      "8     0.884319  \n",
      "9     0.845458  \n",
      "10    0.832936  \n",
      "11    0.822643  \n",
      "12    0.674051  \n",
      "13    0.861000  \n",
      "14    0.822643  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_4 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet4, Y_testSet4)]\n",
    "optimized_xgb_4.fit(X_trainSet4,Y_trainSet4, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_4 = optimized_xgb_4.predict(X_testSet4)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet4, y_pred_xgb_4)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet4, y_pred_xgb_4)\n",
    "Precision = precision_score(Y_testSet4, y_pred_xgb_4)\n",
    "Sensitivity = recall_score(Y_testSet4, y_pred_xgb_4)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet4, y_pred_xgb_4)      \n",
    "f1_scores_W = f1_score(Y_testSet4, y_pred_xgb_4, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet4, y_pred_xgb_4, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet4, y_pred_xgb_4)\n",
    "MCC = matthews_corrcoef(Y_testSet4, y_pred_xgb_4)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet4, y_pred_xgb_4)\n",
    "\n",
    "\n",
    "Set4 = pd.DataFrame({ 'Set4':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set4'] =Set4\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1955a46f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:45:44.575357Z",
     "iopub.status.busy": "2023-01-15T14:45:44.575238Z",
     "iopub.status.idle": "2023-01-15T14:50:05.937275Z",
     "shell.execute_reply": "2023-01-15T14:50:05.936927Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:46:54,842]\u001b[0m Trial 250 finished with value: 0.820671619086777 and parameters: {'n_estimators': 900, 'eta': 0.09638848654036582, 'max_depth': 11, 'alpha': 0.3017, 'lambda': 34.144241362670215, 'max_bin': 372}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:01,085]\u001b[0m Trial 251 finished with value: 0.819514832323328 and parameters: {'n_estimators': 801, 'eta': 0.09996286928683298, 'max_depth': 10, 'alpha': 0.2766, 'lambda': 30.995044442500383, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:07,812]\u001b[0m Trial 252 finished with value: 0.821492912146921 and parameters: {'n_estimators': 848, 'eta': 0.09253607814105583, 'max_depth': 11, 'alpha': 0.4852, 'lambda': 32.92815452855123, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:14,780]\u001b[0m Trial 253 finished with value: 0.8204964610284813 and parameters: {'n_estimators': 832, 'eta': 0.09522756897781645, 'max_depth': 11, 'alpha': 0.3568, 'lambda': 35.868518432101716, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:25,134]\u001b[0m Trial 254 finished with value: 0.8212066613760033 and parameters: {'n_estimators': 866, 'eta': 0.05017305815742309, 'max_depth': 11, 'alpha': 0.322, 'lambda': 38.11656595523101, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:31,961]\u001b[0m Trial 255 finished with value: 0.8221217759069331 and parameters: {'n_estimators': 881, 'eta': 0.0974083932756861, 'max_depth': 11, 'alpha': 0.4358, 'lambda': 37.100529344175065, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:38,928]\u001b[0m Trial 256 finished with value: 0.8187613760464918 and parameters: {'n_estimators': 812, 'eta': 0.0944672350552472, 'max_depth': 11, 'alpha': 0.19970000000000002, 'lambda': 39.596772340433496, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:45,625]\u001b[0m Trial 257 finished with value: 0.8196719618386481 and parameters: {'n_estimators': 852, 'eta': 0.08950060501518928, 'max_depth': 11, 'alpha': 0.3841, 'lambda': 29.457549235658348, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:52,635]\u001b[0m Trial 258 finished with value: 0.8178807557991217 and parameters: {'n_estimators': 884, 'eta': 0.09822796504240137, 'max_depth': 10, 'alpha': 0.5133, 'lambda': 35.35028270576487, 'max_bin': 396}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:47:59,354]\u001b[0m Trial 259 finished with value: 0.8214379992104976 and parameters: {'n_estimators': 789, 'eta': 0.09179735354469701, 'max_depth': 10, 'alpha': 0.6564, 'lambda': 32.00259624480101, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:05,897]\u001b[0m Trial 260 finished with value: 0.8222715314386386 and parameters: {'n_estimators': 829, 'eta': 0.09621810231790867, 'max_depth': 11, 'alpha': 0.4525, 'lambda': 30.65271344754444, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:12,932]\u001b[0m Trial 261 finished with value: 0.823679297876241 and parameters: {'n_estimators': 858, 'eta': 0.09386241065793931, 'max_depth': 11, 'alpha': 0.2398, 'lambda': 36.77207401969977, 'max_bin': 350}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:19,786]\u001b[0m Trial 262 finished with value: 0.8191943360428716 and parameters: {'n_estimators': 842, 'eta': 0.09836774204429433, 'max_depth': 11, 'alpha': 0.33430000000000004, 'lambda': 33.8143497809118, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:26,744]\u001b[0m Trial 263 finished with value: 0.8230152703315573 and parameters: {'n_estimators': 870, 'eta': 0.09997938276726429, 'max_depth': 11, 'alpha': 0.2924, 'lambda': 34.72609362678807, 'max_bin': 331}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:34,436]\u001b[0m Trial 264 finished with value: 0.8266167648946929 and parameters: {'n_estimators': 771, 'eta': 0.09647080449468586, 'max_depth': 11, 'alpha': 0.40240000000000004, 'lambda': 31.198703986611672, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:41,210]\u001b[0m Trial 265 finished with value: 0.8226832138972384 and parameters: {'n_estimators': 812, 'eta': 0.09490483374127907, 'max_depth': 11, 'alpha': 0.3753, 'lambda': 36.343621263451816, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:50,379]\u001b[0m Trial 266 finished with value: 0.8204900986247393 and parameters: {'n_estimators': 891, 'eta': 0.06167987540435376, 'max_depth': 11, 'alpha': 0.2641, 'lambda': 29.91510617198763, 'max_bin': 341}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:48:56,645]\u001b[0m Trial 267 finished with value: 0.8197585075619795 and parameters: {'n_estimators': 836, 'eta': 0.09765038519160282, 'max_depth': 11, 'alpha': 0.4666, 'lambda': 32.62918662753111, 'max_bin': 372}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:03,993]\u001b[0m Trial 268 finished with value: 0.8203083096556008 and parameters: {'n_estimators': 900, 'eta': 0.09273885858725019, 'max_depth': 10, 'alpha': 0.748, 'lambda': 28.256463153377297, 'max_bin': 383}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:11,173]\u001b[0m Trial 269 finished with value: 0.8197992531655798 and parameters: {'n_estimators': 870, 'eta': 0.09645818598703902, 'max_depth': 11, 'alpha': 0.6279, 'lambda': 37.64409708724188, 'max_bin': 412}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:22,653]\u001b[0m Trial 270 finished with value: 0.8213366314972663 and parameters: {'n_estimators': 861, 'eta': 0.047347343233967366, 'max_depth': 11, 'alpha': 0.7021000000000001, 'lambda': 38.74249149670233, 'max_bin': 487}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:29,331]\u001b[0m Trial 271 finished with value: 0.8187202173332941 and parameters: {'n_estimators': 804, 'eta': 0.09987378600201656, 'max_depth': 11, 'alpha': 0.34900000000000003, 'lambda': 35.29107149863962, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:35,901]\u001b[0m Trial 272 finished with value: 0.819708761837789 and parameters: {'n_estimators': 847, 'eta': 0.09095139371624184, 'max_depth': 11, 'alpha': 0.3025, 'lambda': 31.79999778048888, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:42,714]\u001b[0m Trial 273 finished with value: 0.8233962075564423 and parameters: {'n_estimators': 824, 'eta': 0.0939965851791835, 'max_depth': 9, 'alpha': 0.2131, 'lambda': 30.3771783828486, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:49,284]\u001b[0m Trial 274 finished with value: 0.8166839207283093 and parameters: {'n_estimators': 882, 'eta': 0.09805248764592034, 'max_depth': 10, 'alpha': 0.2788, 'lambda': 36.12610712494799, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:49:56,254]\u001b[0m Trial 275 finished with value: 0.8192065943492141 and parameters: {'n_estimators': 788, 'eta': 0.09540739849429292, 'max_depth': 11, 'alpha': 0.7844, 'lambda': 36.776336356141535, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:03,124]\u001b[0m Trial 276 finished with value: 0.8182893446252171 and parameters: {'n_estimators': 853, 'eta': 0.09833872434030094, 'max_depth': 11, 'alpha': 0.4161, 'lambda': 33.407749926956775, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:09,439]\u001b[0m Trial 277 finished with value: 0.8162784508854027 and parameters: {'n_estimators': 751, 'eta': 0.09636650857838469, 'max_depth': 10, 'alpha': 0.2384, 'lambda': 29.260071337554937, 'max_bin': 388}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:16,273]\u001b[0m Trial 278 finished with value: 0.8219683405104071 and parameters: {'n_estimators': 880, 'eta': 0.09998166346098968, 'max_depth': 11, 'alpha': 0.5324, 'lambda': 31.162488339870297, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:50:22,704]\u001b[0m Trial 279 finished with value: 0.8225363742288746 and parameters: {'n_estimators': 833, 'eta': 0.09438812946266935, 'max_depth': 8, 'alpha': 0.5721, 'lambda': 37.64185035741051, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:29,343]\u001b[0m Trial 280 finished with value: 0.8248935683592595 and parameters: {'n_estimators': 863, 'eta': 0.09234346782965297, 'max_depth': 11, 'alpha': 0.3256, 'lambda': 32.525424764349296, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:35,572]\u001b[0m Trial 281 finished with value: 0.8179805186084185 and parameters: {'n_estimators': 847, 'eta': 0.09691793170876242, 'max_depth': 7, 'alpha': 0.4974, 'lambda': 35.70543527089283, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:40,431]\u001b[0m Trial 282 finished with value: 0.8202377941109044 and parameters: {'n_estimators': 196, 'eta': 0.08961817523380974, 'max_depth': 11, 'alpha': 0.38830000000000003, 'lambda': 34.26144057510392, 'max_bin': 374}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:44,673]\u001b[0m Trial 283 finished with value: 0.8184704885322226 and parameters: {'n_estimators': 147, 'eta': 0.09798015525864359, 'max_depth': 11, 'alpha': 0.3579, 'lambda': 38.26580673460146, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:50,846]\u001b[0m Trial 284 finished with value: 0.8210737829169046 and parameters: {'n_estimators': 807, 'eta': 0.0951706725106803, 'max_depth': 11, 'alpha': 0.435, 'lambda': 30.384036061153846, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:50:57,319]\u001b[0m Trial 285 finished with value: 0.8238067157122397 and parameters: {'n_estimators': 884, 'eta': 0.0981495132669172, 'max_depth': 11, 'alpha': 0.2525, 'lambda': 31.832011602869436, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:03,912]\u001b[0m Trial 286 finished with value: 0.8225732899263031 and parameters: {'n_estimators': 900, 'eta': 0.09365403298984838, 'max_depth': 11, 'alpha': 0.3116, 'lambda': 35.20695752396858, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:10,157]\u001b[0m Trial 287 finished with value: 0.8210144125858463 and parameters: {'n_estimators': 821, 'eta': 0.09698305168672205, 'max_depth': 10, 'alpha': 0.8229000000000001, 'lambda': 36.59863616565998, 'max_bin': 393}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:17,327]\u001b[0m Trial 288 finished with value: 0.8180455903236796 and parameters: {'n_estimators': 873, 'eta': 0.092516368778208, 'max_depth': 11, 'alpha': 0.47840000000000005, 'lambda': 37.19998583366488, 'max_bin': 380}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:23,620]\u001b[0m Trial 289 finished with value: 0.8206870874936325 and parameters: {'n_estimators': 842, 'eta': 0.09990365223456524, 'max_depth': 11, 'alpha': 0.33840000000000003, 'lambda': 33.06403031780012, 'max_bin': 340}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:30,401]\u001b[0m Trial 290 finished with value: 0.8202546565685358 and parameters: {'n_estimators': 859, 'eta': 0.09536465475681521, 'max_depth': 11, 'alpha': 0.7208, 'lambda': 31.06583652381174, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:37,809]\u001b[0m Trial 291 finished with value: 0.8226786803298172 and parameters: {'n_estimators': 823, 'eta': 0.09103995053476355, 'max_depth': 11, 'alpha': 0.2846, 'lambda': 35.9526779584412, 'max_bin': 407}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:51:58,865]\u001b[0m Trial 292 finished with value: 0.8146908912094549 and parameters: {'n_estimators': 785, 'eta': 0.015984081831877897, 'max_depth': 11, 'alpha': 0.36110000000000003, 'lambda': 29.755405889691694, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:05,473]\u001b[0m Trial 293 finished with value: 0.8244497369736958 and parameters: {'n_estimators': 871, 'eta': 0.09607219230370279, 'max_depth': 10, 'alpha': 0.2662, 'lambda': 39.250043929068696, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:11,878]\u001b[0m Trial 294 finished with value: 0.8194754098525804 and parameters: {'n_estimators': 838, 'eta': 0.09845393618688032, 'max_depth': 11, 'alpha': 0.684, 'lambda': 34.530295380620636, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:17,904]\u001b[0m Trial 295 finished with value: 0.8242615532228676 and parameters: {'n_estimators': 886, 'eta': 0.09393199924351651, 'max_depth': 11, 'alpha': 0.2214, 'lambda': 28.976677078000304, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:24,140]\u001b[0m Trial 296 finished with value: 0.8252521967868219 and parameters: {'n_estimators': 798, 'eta': 0.09694532917857138, 'max_depth': 11, 'alpha': 0.3125, 'lambda': 32.064188694117526, 'max_bin': 386}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:30,474]\u001b[0m Trial 297 finished with value: 0.8179309918509444 and parameters: {'n_estimators': 853, 'eta': 0.09987295471290213, 'max_depth': 10, 'alpha': 0.9498000000000001, 'lambda': 31.2548411260027, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:46,723]\u001b[0m Trial 298 finished with value: 0.8158553719221526 and parameters: {'n_estimators': 900, 'eta': 0.026464635220243005, 'max_depth': 11, 'alpha': 0.3921, 'lambda': 37.08196681129049, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:52:53,547]\u001b[0m Trial 299 finished with value: 0.8220513869265597 and parameters: {'n_estimators': 817, 'eta': 0.088397967340252, 'max_depth': 11, 'alpha': 0.4524, 'lambda': 30.43131913288783, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 300.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_5 = lambda trial: objective_xgb_CV(trial, X_trainSet5, Y_trainSet5, Y_trainSet5_class)\n",
    "study_xgb.optimize(func_xgb_5, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "072752d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:50:05.938911Z",
     "iopub.status.busy": "2023-01-15T14:50:05.938679Z",
     "iopub.status.idle": "2023-01-15T14:50:06.419246Z",
     "shell.execute_reply": "2023-01-15T14:50:06.418775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4        Set5  \n",
      "0   344.000000  339.000000  \n",
      "1   161.000000  172.000000  \n",
      "2    64.000000   53.000000  \n",
      "3    26.000000   31.000000  \n",
      "4     0.848739    0.858824  \n",
      "5     0.843137    0.864796  \n",
      "6     0.929730    0.916216  \n",
      "7     0.715600    0.764400  \n",
      "8     0.884319    0.889764  \n",
      "9     0.845458    0.857233  \n",
      "10    0.832936    0.846751  \n",
      "11    0.822643    0.840330  \n",
      "12    0.674051    0.696196  \n",
      "13    0.861000    0.847300  \n",
      "14    0.822643    0.840330  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_5 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet5, Y_testSet5)]\n",
    "optimized_xgb_5.fit(X_trainSet5,Y_trainSet5, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_5 = optimized_xgb_5.predict(X_testSet5)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet5, y_pred_xgb_5)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet5, y_pred_xgb_5)\n",
    "Precision = precision_score(Y_testSet5, y_pred_xgb_5)\n",
    "Sensitivity = recall_score(Y_testSet5, y_pred_xgb_5)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet5, y_pred_xgb_5)      \n",
    "f1_scores_W = f1_score(Y_testSet5, y_pred_xgb_5, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet5, y_pred_xgb_5, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet5, y_pred_xgb_5)\n",
    "MCC = matthews_corrcoef(Y_testSet5, y_pred_xgb_5)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet5, y_pred_xgb_5)\n",
    "\n",
    "\n",
    "Set5 = pd.DataFrame({ 'Set5':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set5'] =Set5\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88297c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:50:06.420905Z",
     "iopub.status.busy": "2023-01-15T14:50:06.420725Z",
     "iopub.status.idle": "2023-01-15T14:54:39.213433Z",
     "shell.execute_reply": "2023-01-15T14:54:39.213062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:53:01,153]\u001b[0m Trial 300 finished with value: 0.8266477321257613 and parameters: {'n_estimators': 426, 'eta': 0.09507097407135663, 'max_depth': 9, 'alpha': 0.3447, 'lambda': 35.047204754204046, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:08,345]\u001b[0m Trial 301 finished with value: 0.832201913586462 and parameters: {'n_estimators': 868, 'eta': 0.09789230851764086, 'max_depth': 11, 'alpha': 0.2913, 'lambda': 36.116095679416034, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:16,435]\u001b[0m Trial 302 finished with value: 0.8286482708808608 and parameters: {'n_estimators': 834, 'eta': 0.09255285174470945, 'max_depth': 11, 'alpha': 0.3755, 'lambda': 38.26416431181994, 'max_bin': 400}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:23,229]\u001b[0m Trial 303 finished with value: 0.8260285132728844 and parameters: {'n_estimators': 882, 'eta': 0.09624616333513128, 'max_depth': 11, 'alpha': 0.2489, 'lambda': 33.6034360361663, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:33,315]\u001b[0m Trial 304 finished with value: 0.832095046432733 and parameters: {'n_estimators': 855, 'eta': 0.05558367673791319, 'max_depth': 10, 'alpha': 0.4121, 'lambda': 32.453632739331916, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:39,550]\u001b[0m Trial 305 finished with value: 0.826126192866649 and parameters: {'n_estimators': 773, 'eta': 0.09827529144335008, 'max_depth': 11, 'alpha': 0.5922000000000001, 'lambda': 30.901931762216837, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:46,471]\u001b[0m Trial 306 finished with value: 0.8275888085688529 and parameters: {'n_estimators': 802, 'eta': 0.09473099720590997, 'max_depth': 11, 'alpha': 0.656, 'lambda': 35.639866456477684, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:53:53,737]\u001b[0m Trial 307 finished with value: 0.8280710943030503 and parameters: {'n_estimators': 872, 'eta': 0.09983502554721665, 'max_depth': 10, 'alpha': 0.3136, 'lambda': 37.53904525633386, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:00,221]\u001b[0m Trial 308 finished with value: 0.8261594400200585 and parameters: {'n_estimators': 840, 'eta': 0.09115954426063422, 'max_depth': 11, 'alpha': 0.4902, 'lambda': 29.615571317169838, 'max_bin': 351}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:07,745]\u001b[0m Trial 309 finished with value: 0.8260857030905809 and parameters: {'n_estimators': 818, 'eta': 0.09669809047783168, 'max_depth': 12, 'alpha': 0.279, 'lambda': 39.97730520270236, 'max_bin': 374}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:14,527]\u001b[0m Trial 310 finished with value: 0.8248435102809326 and parameters: {'n_estimators': 857, 'eta': 0.09358711297261703, 'max_depth': 11, 'alpha': 0.3695, 'lambda': 36.49791668353705, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:20,729]\u001b[0m Trial 311 finished with value: 0.825336920735866 and parameters: {'n_estimators': 873, 'eta': 0.09820097287040377, 'max_depth': 11, 'alpha': 0.6123000000000001, 'lambda': 31.408421122717854, 'max_bin': 336}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:27,286]\u001b[0m Trial 312 finished with value: 0.8275701760041896 and parameters: {'n_estimators': 887, 'eta': 0.09557818613251623, 'max_depth': 11, 'alpha': 0.3378, 'lambda': 34.63424055711949, 'max_bin': 383}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:33,590]\u001b[0m Trial 313 finished with value: 0.8304739230062387 and parameters: {'n_estimators': 831, 'eta': 0.09812022300211293, 'max_depth': 11, 'alpha': 0.7472000000000001, 'lambda': 28.34326263524419, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:40,983]\u001b[0m Trial 314 finished with value: 0.8293626574513515 and parameters: {'n_estimators': 851, 'eta': 0.09325133664674061, 'max_depth': 11, 'alpha': 0.8683000000000001, 'lambda': 32.93197891178146, 'max_bin': 391}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:46,844]\u001b[0m Trial 315 finished with value: 0.8261512750029976 and parameters: {'n_estimators': 899, 'eta': 0.09985544356835452, 'max_depth': 11, 'alpha': 0.2341, 'lambda': 34.01209228014856, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:54:53,462]\u001b[0m Trial 316 finished with value: 0.8252981286349513 and parameters: {'n_estimators': 814, 'eta': 0.09663713141046301, 'max_depth': 10, 'alpha': 0.4436, 'lambda': 30.4333276017297, 'max_bin': 348}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:00,394]\u001b[0m Trial 317 finished with value: 0.8271829312657367 and parameters: {'n_estimators': 865, 'eta': 0.08717838718075999, 'max_depth': 11, 'alpha': 0.263, 'lambda': 31.815841097097273, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:07,664]\u001b[0m Trial 318 finished with value: 0.8256927003215294 and parameters: {'n_estimators': 840, 'eta': 0.09038356053984166, 'max_depth': 10, 'alpha': 0.29810000000000003, 'lambda': 37.22683821777878, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:14,143]\u001b[0m Trial 319 finished with value: 0.8210465331460062 and parameters: {'n_estimators': 883, 'eta': 0.09493441996193172, 'max_depth': 11, 'alpha': 0.5131, 'lambda': 35.6354102854447, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:20,676]\u001b[0m Trial 320 finished with value: 0.8283432736596991 and parameters: {'n_estimators': 788, 'eta': 0.09736976652551974, 'max_depth': 12, 'alpha': 0.4703, 'lambda': 29.81717780335236, 'max_bin': 396}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:28,385]\u001b[0m Trial 321 finished with value: 0.8280903698311717 and parameters: {'n_estimators': 831, 'eta': 0.09268103906658562, 'max_depth': 11, 'alpha': 0.4194, 'lambda': 38.310022329657215, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:41,845]\u001b[0m Trial 322 finished with value: 0.8288025667741328 and parameters: {'n_estimators': 855, 'eta': 0.04162281211009857, 'max_depth': 11, 'alpha': 0.7728, 'lambda': 36.385087544357376, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:49,154]\u001b[0m Trial 323 finished with value: 0.828748825033726 and parameters: {'n_estimators': 805, 'eta': 0.09518494435306607, 'max_depth': 11, 'alpha': 0.1879, 'lambda': 32.35117860467375, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:55:55,976]\u001b[0m Trial 324 finished with value: 0.8307301180992648 and parameters: {'n_estimators': 869, 'eta': 0.09832162233873612, 'max_depth': 9, 'alpha': 0.3276, 'lambda': 35.043720743798076, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:02,348]\u001b[0m Trial 325 finished with value: 0.8283915454253575 and parameters: {'n_estimators': 823, 'eta': 0.09663713074102492, 'max_depth': 11, 'alpha': 0.3875, 'lambda': 27.33161346802205, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:09,431]\u001b[0m Trial 326 finished with value: 0.8278312853589254 and parameters: {'n_estimators': 881, 'eta': 0.09393276998151277, 'max_depth': 11, 'alpha': 0.35300000000000004, 'lambda': 30.688164098788235, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:17,071]\u001b[0m Trial 327 finished with value: 0.8278841745502007 and parameters: {'n_estimators': 845, 'eta': 0.09975533439346247, 'max_depth': 10, 'alpha': 0.2706, 'lambda': 31.55510605700986, 'max_bin': 463}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:23,789]\u001b[0m Trial 328 finished with value: 0.825461032172693 and parameters: {'n_estimators': 310, 'eta': 0.09112953639542885, 'max_depth': 11, 'alpha': 0.7013, 'lambda': 36.98919744292701, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:56:31,106]\u001b[0m Trial 329 finished with value: 0.8257479020445091 and parameters: {'n_estimators': 765, 'eta': 0.09656492863153505, 'max_depth': 5, 'alpha': 0.5505, 'lambda': 33.31554046840927, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:37,189]\u001b[0m Trial 330 finished with value: 0.8296721052582805 and parameters: {'n_estimators': 888, 'eta': 0.09821879167489626, 'max_depth': 11, 'alpha': 0.6346, 'lambda': 29.201790061212925, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:44,489]\u001b[0m Trial 331 finished with value: 0.8242480481708393 and parameters: {'n_estimators': 863, 'eta': 0.09514735963891291, 'max_depth': 6, 'alpha': 0.2129, 'lambda': 37.97845226117055, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:51,706]\u001b[0m Trial 332 finished with value: 0.8254305288570066 and parameters: {'n_estimators': 803, 'eta': 0.09289421353721297, 'max_depth': 11, 'alpha': 0.30060000000000003, 'lambda': 35.83358891870701, 'max_bin': 385}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:56:58,249]\u001b[0m Trial 333 finished with value: 0.8276476947612755 and parameters: {'n_estimators': 845, 'eta': 0.09983288300046653, 'max_depth': 12, 'alpha': 0.2431, 'lambda': 30.13477840657558, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:05,521]\u001b[0m Trial 334 finished with value: 0.8273253516765703 and parameters: {'n_estimators': 821, 'eta': 0.08893898888298912, 'max_depth': 11, 'alpha': 0.328, 'lambda': 31.15103945971132, 'max_bin': 344}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:13,834]\u001b[0m Trial 335 finished with value: 0.8298657249094585 and parameters: {'n_estimators': 886, 'eta': 0.09750192998088748, 'max_depth': 11, 'alpha': 0.3669, 'lambda': 39.02088045196722, 'max_bin': 330}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:21,742]\u001b[0m Trial 336 finished with value: 0.8222210259448701 and parameters: {'n_estimators': 900, 'eta': 0.09506186635550555, 'max_depth': 8, 'alpha': 0.4083, 'lambda': 34.06245586932164, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:29,692]\u001b[0m Trial 337 finished with value: 0.8290600886025004 and parameters: {'n_estimators': 864, 'eta': 0.0966909573542299, 'max_depth': 10, 'alpha': 0.2861, 'lambda': 36.4910328616889, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:38,396]\u001b[0m Trial 338 finished with value: 0.8300734213918884 and parameters: {'n_estimators': 835, 'eta': 0.0984318029239329, 'max_depth': 11, 'alpha': 0.6748000000000001, 'lambda': 35.01769683453295, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:46,309]\u001b[0m Trial 339 finished with value: 0.8296404590118345 and parameters: {'n_estimators': 785, 'eta': 0.09369014182465624, 'max_depth': 11, 'alpha': 0.4358, 'lambda': 32.27982834969629, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:57:54,005]\u001b[0m Trial 340 finished with value: 0.8281049047226767 and parameters: {'n_estimators': 871, 'eta': 0.09998490647152553, 'max_depth': 11, 'alpha': 0.45730000000000004, 'lambda': 37.475087630242015, 'max_bin': 379}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:02,230]\u001b[0m Trial 341 finished with value: 0.8256853879305666 and parameters: {'n_estimators': 850, 'eta': 0.09577808875218102, 'max_depth': 11, 'alpha': 0.7228, 'lambda': 30.70397139498141, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:10,442]\u001b[0m Trial 342 finished with value: 0.8299353877467418 and parameters: {'n_estimators': 815, 'eta': 0.09176452271631327, 'max_depth': 10, 'alpha': 0.3467, 'lambda': 31.845710661867756, 'max_bin': 339}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:18,389]\u001b[0m Trial 343 finished with value: 0.831720049708746 and parameters: {'n_estimators': 884, 'eta': 0.09816028007073492, 'max_depth': 11, 'alpha': 0.31880000000000003, 'lambda': 35.825342626916665, 'max_bin': 389}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:26,303]\u001b[0m Trial 344 finished with value: 0.8293466576148104 and parameters: {'n_estimators': 856, 'eta': 0.09633342661125902, 'max_depth': 11, 'alpha': 0.2622, 'lambda': 33.055898421886226, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:32,956]\u001b[0m Trial 345 finished with value: 0.8283563928439135 and parameters: {'n_estimators': 834, 'eta': 0.09352158428298868, 'max_depth': 12, 'alpha': 0.49260000000000004, 'lambda': 36.41077909833721, 'max_bin': 405}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:36,716]\u001b[0m Trial 346 finished with value: 0.8358062842656542 and parameters: {'n_estimators': 799, 'eta': 0.09816175995884943, 'max_depth': 11, 'alpha': 0.39580000000000004, 'lambda': 2.2295179475477234, 'max_bin': 350}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:43,803]\u001b[0m Trial 347 finished with value: 0.8335282820621297 and parameters: {'n_estimators': 872, 'eta': 0.09031720279839789, 'max_depth': 11, 'alpha': 0.8068000000000001, 'lambda': 29.817134190681976, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:50,593]\u001b[0m Trial 348 finished with value: 0.8295144951127478 and parameters: {'n_estimators': 485, 'eta': 0.09498933097155914, 'max_depth': 11, 'alpha': 0.2394, 'lambda': 28.868996503095353, 'max_bin': 397}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:58:57,909]\u001b[0m Trial 349 finished with value: 0.8244205142380616 and parameters: {'n_estimators': 843, 'eta': 0.09687798638361833, 'max_depth': 11, 'alpha': 0.5318, 'lambda': 34.636876147134096, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 350.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_6 = lambda trial: objective_xgb_CV(trial, X_trainSet6, Y_trainSet6, Y_trainSet6_class)\n",
    "study_xgb.optimize(func_xgb_6, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea8e79dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:54:39.215082Z",
     "iopub.status.busy": "2023-01-15T14:54:39.214957Z",
     "iopub.status.idle": "2023-01-15T14:54:39.649960Z",
     "shell.execute_reply": "2023-01-15T14:54:39.649567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4        Set5        Set6  \n",
      "0   344.000000  339.000000  322.000000  \n",
      "1   161.000000  172.000000  179.000000  \n",
      "2    64.000000   53.000000   53.000000  \n",
      "3    26.000000   31.000000   41.000000  \n",
      "4     0.848739    0.858824    0.842017  \n",
      "5     0.843137    0.864796    0.858667  \n",
      "6     0.929730    0.916216    0.887052  \n",
      "7     0.715600    0.764400    0.771600  \n",
      "8     0.884319    0.889764    0.872629  \n",
      "9     0.845458    0.857233    0.841204  \n",
      "10    0.832936    0.846751    0.832332  \n",
      "11    0.822643    0.840330    0.829302  \n",
      "12    0.674051    0.696196    0.665418  \n",
      "13    0.861000    0.847300    0.813600  \n",
      "14    0.822643    0.840330    0.829302  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_6 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet6, Y_testSet6)]\n",
    "optimized_xgb_6.fit(X_trainSet6,Y_trainSet6, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_6 = optimized_xgb_6.predict(X_testSet6)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet6, y_pred_xgb_6)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet6, y_pred_xgb_6)\n",
    "Precision = precision_score(Y_testSet6, y_pred_xgb_6)\n",
    "Sensitivity = recall_score(Y_testSet6, y_pred_xgb_6)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet6, y_pred_xgb_6)      \n",
    "f1_scores_W = f1_score(Y_testSet6, y_pred_xgb_6, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet6, y_pred_xgb_6, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet6, y_pred_xgb_6)\n",
    "MCC = matthews_corrcoef(Y_testSet6, y_pred_xgb_6)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet6, y_pred_xgb_6)\n",
    "\n",
    "\n",
    "Set6 = pd.DataFrame({ 'Set6':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set6'] =Set6\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be1838b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:54:39.651407Z",
     "iopub.status.busy": "2023-01-15T14:54:39.651281Z",
     "iopub.status.idle": "2023-01-15T14:59:20.145429Z",
     "shell.execute_reply": "2023-01-15T14:59:20.145090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 16:59:05,516]\u001b[0m Trial 350 finished with value: 0.8294687712284959 and parameters: {'n_estimators': 822, 'eta': 0.09861297498151934, 'max_depth': 10, 'alpha': 0.36610000000000004, 'lambda': 37.16891293909341, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:11,951]\u001b[0m Trial 351 finished with value: 0.8326388269910755 and parameters: {'n_estimators': 886, 'eta': 0.0942951812222532, 'max_depth': 11, 'alpha': 0.3, 'lambda': 31.34355473702704, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:18,912]\u001b[0m Trial 352 finished with value: 0.8297844116980299 and parameters: {'n_estimators': 856, 'eta': 0.09197260605255997, 'max_depth': 11, 'alpha': 0.22540000000000002, 'lambda': 35.44236229007555, 'max_bin': 346}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:28,358]\u001b[0m Trial 353 finished with value: 0.8284689865810329 and parameters: {'n_estimators': 899, 'eta': 0.05375250365671595, 'max_depth': 11, 'alpha': 0.2802, 'lambda': 33.88870735899188, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:42,896]\u001b[0m Trial 354 finished with value: 0.8289083311678664 and parameters: {'n_estimators': 870, 'eta': 0.03477532383189558, 'max_depth': 11, 'alpha': 0.4772, 'lambda': 32.679101530925365, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:50,432]\u001b[0m Trial 355 finished with value: 0.8231198727549716 and parameters: {'n_estimators': 778, 'eta': 0.09971962494942735, 'max_depth': 10, 'alpha': 0.34040000000000004, 'lambda': 38.018385109827726, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 16:59:57,198]\u001b[0m Trial 356 finished with value: 0.8334862465888639 and parameters: {'n_estimators': 828, 'eta': 0.0843529930624578, 'max_depth': 11, 'alpha': 0.3819, 'lambda': 30.535267986725383, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:03,282]\u001b[0m Trial 357 finished with value: 0.8304131417459173 and parameters: {'n_estimators': 805, 'eta': 0.09679884958162668, 'max_depth': 12, 'alpha': 0.31420000000000003, 'lambda': 32.0320914944327, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:09,753]\u001b[0m Trial 358 finished with value: 0.8270867971080831 and parameters: {'n_estimators': 855, 'eta': 0.09517374412623927, 'max_depth': 11, 'alpha': 0.26180000000000003, 'lambda': 36.7999761662395, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:16,054]\u001b[0m Trial 359 finished with value: 0.8248833678759058 and parameters: {'n_estimators': 879, 'eta': 0.09806239364638865, 'max_depth': 11, 'alpha': 0.5656, 'lambda': 35.91673176460775, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:21,652]\u001b[0m Trial 360 finished with value: 0.8254060465145706 and parameters: {'n_estimators': 242, 'eta': 0.09985295543863507, 'max_depth': 11, 'alpha': 0.6421, 'lambda': 38.66806166781168, 'max_bin': 350}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:28,327]\u001b[0m Trial 361 finished with value: 0.8250522634679742 and parameters: {'n_estimators': 838, 'eta': 0.09307788145472291, 'max_depth': 11, 'alpha': 0.4238, 'lambda': 35.00623407396231, 'max_bin': 359}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:35,928]\u001b[0m Trial 362 finished with value: 0.8282062087510853 and parameters: {'n_estimators': 899, 'eta': 0.06861073440836572, 'max_depth': 10, 'alpha': 0.39840000000000003, 'lambda': 31.103514600227964, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:37,843]\u001b[0m Trial 363 finished with value: 0.8176613690148484 and parameters: {'n_estimators': 64, 'eta': 0.09599878958072959, 'max_depth': 11, 'alpha': 0.20120000000000002, 'lambda': 29.84125841091999, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:44,281]\u001b[0m Trial 364 finished with value: 0.8298002347221237 and parameters: {'n_estimators': 865, 'eta': 0.09696490120276784, 'max_depth': 11, 'alpha': 0.2515, 'lambda': 37.21936697379354, 'max_bin': 392}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:51,137]\u001b[0m Trial 365 finished with value: 0.8275398444950162 and parameters: {'n_estimators': 822, 'eta': 0.08887969927486783, 'max_depth': 9, 'alpha': 0.3602, 'lambda': 31.681066784153852, 'max_bin': 385}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:00:57,596]\u001b[0m Trial 366 finished with value: 0.8227239453654643 and parameters: {'n_estimators': 848, 'eta': 0.09489510806072865, 'max_depth': 11, 'alpha': 0.5169, 'lambda': 28.405364097804537, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:03,875]\u001b[0m Trial 367 finished with value: 0.8287984283863044 and parameters: {'n_estimators': 795, 'eta': 0.09123512245232383, 'max_depth': 11, 'alpha': 0.4627, 'lambda': 36.432524910538476, 'max_bin': 336}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:10,292]\u001b[0m Trial 368 finished with value: 0.8266737422656396 and parameters: {'n_estimators': 875, 'eta': 0.09801898592785283, 'max_depth': 12, 'alpha': 0.7433000000000001, 'lambda': 33.19081738681033, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:16,672]\u001b[0m Trial 369 finished with value: 0.8259013504506836 and parameters: {'n_estimators': 758, 'eta': 0.0999534740380184, 'max_depth': 11, 'alpha': 0.3355, 'lambda': 30.37717733736774, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:22,967]\u001b[0m Trial 370 finished with value: 0.8252252308763645 and parameters: {'n_estimators': 837, 'eta': 0.09368667861456179, 'max_depth': 11, 'alpha': 0.2918, 'lambda': 29.27406879562841, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:29,035]\u001b[0m Trial 371 finished with value: 0.8282904965859872 and parameters: {'n_estimators': 900, 'eta': 0.09639787060220623, 'max_depth': 10, 'alpha': 0.6145, 'lambda': 34.29701625620068, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:35,075]\u001b[0m Trial 372 finished with value: 0.8272766141042229 and parameters: {'n_estimators': 808, 'eta': 0.09992747452903424, 'max_depth': 11, 'alpha': 0.6678000000000001, 'lambda': 37.79584480844356, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:41,885]\u001b[0m Trial 373 finished with value: 0.8271645424589815 and parameters: {'n_estimators': 861, 'eta': 0.09238967891744082, 'max_depth': 10, 'alpha': 0.3171, 'lambda': 35.51888981234116, 'max_bin': 346}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:48,042]\u001b[0m Trial 374 finished with value: 0.8237669754197879 and parameters: {'n_estimators': 882, 'eta': 0.09729719071591257, 'max_depth': 11, 'alpha': 0.7073, 'lambda': 32.429595124514805, 'max_bin': 372}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:01:54,289]\u001b[0m Trial 375 finished with value: 0.8273808330327468 and parameters: {'n_estimators': 850, 'eta': 0.09477296016465983, 'max_depth': 11, 'alpha': 0.3804, 'lambda': 30.840106337221904, 'max_bin': 402}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:00,845]\u001b[0m Trial 376 finished with value: 0.8277395883995622 and parameters: {'n_estimators': 818, 'eta': 0.09796657666385164, 'max_depth': 11, 'alpha': 0.2717, 'lambda': 36.188545369365634, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:07,912]\u001b[0m Trial 377 finished with value: 0.8259516553290517 and parameters: {'n_estimators': 868, 'eta': 0.09591573589311515, 'max_depth': 11, 'alpha': 0.5876, 'lambda': 31.393843205831406, 'max_bin': 438}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:14,986]\u001b[0m Trial 378 finished with value: 0.8246758019282703 and parameters: {'n_estimators': 833, 'eta': 0.09365800145854104, 'max_depth': 11, 'alpha': 0.497, 'lambda': 39.00143603511402, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:02:21,309]\u001b[0m Trial 379 finished with value: 0.8270100608225628 and parameters: {'n_estimators': 780, 'eta': 0.09993466155017139, 'max_depth': 10, 'alpha': 0.2285, 'lambda': 34.88717164299278, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:27,160]\u001b[0m Trial 380 finished with value: 0.8287433188393303 and parameters: {'n_estimators': 883, 'eta': 0.09796773702046249, 'max_depth': 12, 'alpha': 0.35050000000000003, 'lambda': 25.821976839518335, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:34,398]\u001b[0m Trial 381 finished with value: 0.8341537025278237 and parameters: {'n_estimators': 857, 'eta': 0.0902755371972982, 'max_depth': 11, 'alpha': 0.4307, 'lambda': 33.797714986192744, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:41,130]\u001b[0m Trial 382 finished with value: 0.8266981235160371 and parameters: {'n_estimators': 815, 'eta': 0.09583451511444402, 'max_depth': 11, 'alpha': 0.29510000000000003, 'lambda': 36.78588998928022, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:47,524]\u001b[0m Trial 383 finished with value: 0.830434830774176 and parameters: {'n_estimators': 843, 'eta': 0.09335346872172653, 'max_depth': 11, 'alpha': 0.3287, 'lambda': 37.623583832841604, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:53,776]\u001b[0m Trial 384 finished with value: 0.829913200531189 and parameters: {'n_estimators': 900, 'eta': 0.0866965276069177, 'max_depth': 11, 'alpha': 0.44920000000000004, 'lambda': 29.99771315014063, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:02:59,547]\u001b[0m Trial 385 finished with value: 0.8246386242884778 and parameters: {'n_estimators': 872, 'eta': 0.09796589759727152, 'max_depth': 11, 'alpha': 0.3738, 'lambda': 31.8741400370273, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:05,835]\u001b[0m Trial 386 finished with value: 0.8297643531559601 and parameters: {'n_estimators': 832, 'eta': 0.09519836364158543, 'max_depth': 11, 'alpha': 0.2775, 'lambda': 35.4677713319593, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:12,627]\u001b[0m Trial 387 finished with value: 0.8240437619775717 and parameters: {'n_estimators': 884, 'eta': 0.09670916390337392, 'max_depth': 10, 'alpha': 0.2479, 'lambda': 30.873496557366412, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:19,397]\u001b[0m Trial 388 finished with value: 0.8230549065143761 and parameters: {'n_estimators': 789, 'eta': 0.09171111897955621, 'max_depth': 11, 'alpha': 0.7614000000000001, 'lambda': 32.79459676230528, 'max_bin': 394}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:26,292]\u001b[0m Trial 389 finished with value: 0.8278859978863323 and parameters: {'n_estimators': 856, 'eta': 0.09824570324913802, 'max_depth': 11, 'alpha': 0.6927, 'lambda': 36.11084411327865, 'max_bin': 421}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:32,981]\u001b[0m Trial 390 finished with value: 0.8299794834951152 and parameters: {'n_estimators': 356, 'eta': 0.09440147090222727, 'max_depth': 11, 'alpha': 0.4056, 'lambda': 29.290278856680633, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:40,095]\u001b[0m Trial 391 finished with value: 0.8280637254350687 and parameters: {'n_estimators': 814, 'eta': 0.09659797231722156, 'max_depth': 12, 'alpha': 0.34340000000000004, 'lambda': 34.562623056376644, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:46,875]\u001b[0m Trial 392 finished with value: 0.8263619704068483 and parameters: {'n_estimators': 866, 'eta': 0.0999981093263196, 'max_depth': 10, 'alpha': 0.7257, 'lambda': 37.04473048797027, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:03:53,938]\u001b[0m Trial 393 finished with value: 0.826693794959597 and parameters: {'n_estimators': 844, 'eta': 0.09488270412728679, 'max_depth': 8, 'alpha': 0.312, 'lambda': 30.36992573334, 'max_bin': 386}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:00,413]\u001b[0m Trial 394 finished with value: 0.8249569591917364 and parameters: {'n_estimators': 885, 'eta': 0.0982165113215629, 'max_depth': 11, 'alpha': 0.259, 'lambda': 31.8761746019854, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:08,120]\u001b[0m Trial 395 finished with value: 0.8235072711237956 and parameters: {'n_estimators': 829, 'eta': 0.09160791600878987, 'max_depth': 7, 'alpha': 0.21930000000000002, 'lambda': 38.48572275136804, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:15,364]\u001b[0m Trial 396 finished with value: 0.8248916161543294 and parameters: {'n_estimators': 795, 'eta': 0.09645550983413702, 'max_depth': 11, 'alpha': 0.47740000000000005, 'lambda': 33.55405954934768, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:21,704]\u001b[0m Trial 397 finished with value: 0.8256462206781136 and parameters: {'n_estimators': 856, 'eta': 0.0999873334849162, 'max_depth': 11, 'alpha': 0.3574, 'lambda': 35.537911460513165, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:27,469]\u001b[0m Trial 398 finished with value: 0.8283739045533371 and parameters: {'n_estimators': 872, 'eta': 0.09273739392171268, 'max_depth': 11, 'alpha': 0.30310000000000004, 'lambda': 30.980147076029628, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:35,228]\u001b[0m Trial 399 finished with value: 0.8327065435030505 and parameters: {'n_estimators': 900, 'eta': 0.08966357866888953, 'max_depth': 11, 'alpha': 0.9992000000000001, 'lambda': 36.38559722809089, 'max_bin': 367}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 400.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_7 = lambda trial: objective_xgb_CV(trial, X_trainSet7, Y_trainSet7, Y_trainSet7_class)\n",
    "study_xgb.optimize(func_xgb_7, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35af308c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:59:20.146922Z",
     "iopub.status.busy": "2023-01-15T14:59:20.146779Z",
     "iopub.status.idle": "2023-01-15T14:59:20.594449Z",
     "shell.execute_reply": "2023-01-15T14:59:20.594113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4        Set5        Set6        Set7  \n",
      "0   344.000000  339.000000  322.000000  337.000000  \n",
      "1   161.000000  172.000000  179.000000  178.000000  \n",
      "2    64.000000   53.000000   53.000000   43.000000  \n",
      "3    26.000000   31.000000   41.000000   37.000000  \n",
      "4     0.848739    0.858824    0.842017    0.865546  \n",
      "5     0.843137    0.864796    0.858667    0.886842  \n",
      "6     0.929730    0.916216    0.887052    0.901070  \n",
      "7     0.715600    0.764400    0.771600    0.805400  \n",
      "8     0.884319    0.889764    0.872629    0.893899  \n",
      "9     0.845458    0.857233    0.841204    0.865156  \n",
      "10    0.832936    0.846751    0.832332    0.855206  \n",
      "11    0.822643    0.840330    0.829302    0.853250  \n",
      "12    0.674051    0.696196    0.665418    0.710612  \n",
      "13    0.861000    0.847300    0.813600    0.827900  \n",
      "14    0.822643    0.840330    0.829302    0.853250  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_7 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet7, Y_testSet7)]\n",
    "optimized_xgb_7.fit(X_trainSet7,Y_trainSet7, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_7 = optimized_xgb_7.predict(X_testSet7)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet7, y_pred_xgb_7)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet7, y_pred_xgb_7)\n",
    "Precision = precision_score(Y_testSet7, y_pred_xgb_7)\n",
    "Sensitivity = recall_score(Y_testSet7, y_pred_xgb_7)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet7, y_pred_xgb_7)      \n",
    "f1_scores_W = f1_score(Y_testSet7, y_pred_xgb_7, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet7, y_pred_xgb_7, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet7, y_pred_xgb_7)\n",
    "MCC = matthews_corrcoef(Y_testSet7, y_pred_xgb_7)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet7, y_pred_xgb_7)\n",
    "\n",
    "\n",
    "Set7 = pd.DataFrame({ 'Set7':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set7'] =Set7\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4cebba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:59:20.596069Z",
     "iopub.status.busy": "2023-01-15T14:59:20.595951Z",
     "iopub.status.idle": "2023-01-15T15:03:28.090057Z",
     "shell.execute_reply": "2023-01-15T15:03:28.089579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:04:43,011]\u001b[0m Trial 400 finished with value: 0.8305780359246041 and parameters: {'n_estimators': 844, 'eta': 0.09767324388168877, 'max_depth': 11, 'alpha': 0.387, 'lambda': 27.411903573967443, 'max_bin': 500}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:50,594]\u001b[0m Trial 401 finished with value: 0.8257649152474951 and parameters: {'n_estimators': 807, 'eta': 0.09457494325957619, 'max_depth': 11, 'alpha': 0.2856, 'lambda': 32.50764081071091, 'max_bin': 378}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:04:58,198]\u001b[0m Trial 402 finished with value: 0.8244618728096246 and parameters: {'n_estimators': 826, 'eta': 0.09634825180356425, 'max_depth': 12, 'alpha': 0.24230000000000002, 'lambda': 37.58637685250378, 'max_bin': 355}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:05,308]\u001b[0m Trial 403 finished with value: 0.8270112719618712 and parameters: {'n_estimators': 884, 'eta': 0.09799524799344907, 'max_depth': 10, 'alpha': 0.6507000000000001, 'lambda': 31.53341587840196, 'max_bin': 334}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:14,920]\u001b[0m Trial 404 finished with value: 0.8250410936419408 and parameters: {'n_estimators': 865, 'eta': 0.06038104499762009, 'max_depth': 11, 'alpha': 0.5027, 'lambda': 29.959333890210143, 'max_bin': 327}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:23,964]\u001b[0m Trial 405 finished with value: 0.8242187809625191 and parameters: {'n_estimators': 846, 'eta': 0.06501303742114564, 'max_depth': 11, 'alpha': 0.43960000000000005, 'lambda': 28.392621405573372, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:31,147]\u001b[0m Trial 406 finished with value: 0.8229790901471512 and parameters: {'n_estimators': 774, 'eta': 0.09998460733036603, 'max_depth': 10, 'alpha': 0.3335, 'lambda': 36.760609239964005, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:36,998]\u001b[0m Trial 407 finished with value: 0.8310326952467288 and parameters: {'n_estimators': 825, 'eta': 0.09335034646530803, 'max_depth': 11, 'alpha': 0.4186, 'lambda': 11.771149965613965, 'max_bin': 397}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:44,272]\u001b[0m Trial 408 finished with value: 0.8242536322761064 and parameters: {'n_estimators': 883, 'eta': 0.09596056609142611, 'max_depth': 9, 'alpha': 0.2662, 'lambda': 34.99473470132802, 'max_bin': 389}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:51,885]\u001b[0m Trial 409 finished with value: 0.8281315583443376 and parameters: {'n_estimators': 738, 'eta': 0.09816471434267064, 'max_depth': 11, 'alpha': 0.4681, 'lambda': 32.97576534783674, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:05:58,939]\u001b[0m Trial 410 finished with value: 0.8286744565668647 and parameters: {'n_estimators': 805, 'eta': 0.09452992168510795, 'max_depth': 11, 'alpha': 0.3114, 'lambda': 33.859218908409964, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:06,399]\u001b[0m Trial 411 finished with value: 0.8286130781528105 and parameters: {'n_estimators': 862, 'eta': 0.09188543343988577, 'max_depth': 11, 'alpha': 0.1925, 'lambda': 38.01518652366383, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:13,633]\u001b[0m Trial 412 finished with value: 0.8287563115245895 and parameters: {'n_estimators': 843, 'eta': 0.09637173090126834, 'max_depth': 11, 'alpha': 0.35850000000000004, 'lambda': 39.595002827302736, 'max_bin': 373}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:18,628]\u001b[0m Trial 413 finished with value: 0.8242147519220436 and parameters: {'n_estimators': 873, 'eta': 0.0980422713392296, 'max_depth': 11, 'alpha': 0.3977, 'lambda': 8.852514516074505, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:25,673]\u001b[0m Trial 414 finished with value: 0.8238969134830313 and parameters: {'n_estimators': 889, 'eta': 0.09444843367557682, 'max_depth': 10, 'alpha': 0.37220000000000003, 'lambda': 35.833468676814505, 'max_bin': 342}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:32,780]\u001b[0m Trial 415 finished with value: 0.8260732741785732 and parameters: {'n_estimators': 856, 'eta': 0.09845292663062366, 'max_depth': 12, 'alpha': 0.6246, 'lambda': 30.732619752565597, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:40,297]\u001b[0m Trial 416 finished with value: 0.8307939503999172 and parameters: {'n_estimators': 829, 'eta': 0.08812246079077099, 'max_depth': 11, 'alpha': 0.2842, 'lambda': 29.526990379636988, 'max_bin': 409}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:47,416]\u001b[0m Trial 417 finished with value: 0.827206851150731 and parameters: {'n_estimators': 900, 'eta': 0.09600192395084162, 'max_depth': 11, 'alpha': 0.7928000000000001, 'lambda': 32.18288752068628, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:06:54,681]\u001b[0m Trial 418 finished with value: 0.8246357659473682 and parameters: {'n_estimators': 802, 'eta': 0.09316095598646566, 'max_depth': 11, 'alpha': 0.22640000000000002, 'lambda': 36.96719033798454, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:01,629]\u001b[0m Trial 419 finished with value: 0.8256772392701915 and parameters: {'n_estimators': 873, 'eta': 0.09842579122463545, 'max_depth': 11, 'alpha': 0.3292, 'lambda': 31.396383919622032, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:04,814]\u001b[0m Trial 420 finished with value: 0.819790214597776 and parameters: {'n_estimators': 113, 'eta': 0.09642610027752836, 'max_depth': 11, 'alpha': 0.5239, 'lambda': 36.11716623174217, 'max_bin': 347}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:11,880]\u001b[0m Trial 421 finished with value: 0.8260655955903552 and parameters: {'n_estimators': 844, 'eta': 0.09029190106762908, 'max_depth': 11, 'alpha': 0.25220000000000004, 'lambda': 34.49979055556784, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:23,162]\u001b[0m Trial 422 finished with value: 0.7930765237301969 and parameters: {'n_estimators': 409, 'eta': 0.0062943884918226015, 'max_depth': 10, 'alpha': 0.7169, 'lambda': 30.0697155403838, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:28,622]\u001b[0m Trial 423 finished with value: 0.826015703075775 and parameters: {'n_estimators': 214, 'eta': 0.09448385027746443, 'max_depth': 11, 'alpha': 0.4566, 'lambda': 29.109570771684346, 'max_bin': 338}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:36,238]\u001b[0m Trial 424 finished with value: 0.8277830050920822 and parameters: {'n_estimators': 816, 'eta': 0.09878728583128714, 'max_depth': 12, 'alpha': 0.3015, 'lambda': 35.422012789579455, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:43,279]\u001b[0m Trial 425 finished with value: 0.8234561918395489 and parameters: {'n_estimators': 789, 'eta': 0.09257869468162326, 'max_depth': 11, 'alpha': 0.34490000000000004, 'lambda': 37.44798816353463, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:50,528]\u001b[0m Trial 426 finished with value: 0.8254335865998543 and parameters: {'n_estimators': 861, 'eta': 0.09664356089161451, 'max_depth': 11, 'alpha': 0.6876, 'lambda': 31.06817539014297, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:07:57,324]\u001b[0m Trial 427 finished with value: 0.8273869763052957 and parameters: {'n_estimators': 884, 'eta': 0.09976112484110167, 'max_depth': 11, 'alpha': 0.48760000000000003, 'lambda': 32.120580628282184, 'max_bin': 401}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:03,840]\u001b[0m Trial 428 finished with value: 0.8261262041799139 and parameters: {'n_estimators': 849, 'eta': 0.09510722264528833, 'max_depth': 10, 'alpha': 0.55, 'lambda': 33.256680812007005, 'max_bin': 374}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:08:10,700]\u001b[0m Trial 429 finished with value: 0.8218059745730193 and parameters: {'n_estimators': 830, 'eta': 0.09991783746358532, 'max_depth': 9, 'alpha': 0.2656, 'lambda': 36.42871777860438, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:17,735]\u001b[0m Trial 430 finished with value: 0.8272109996900554 and parameters: {'n_estimators': 869, 'eta': 0.09705610864500057, 'max_depth': 11, 'alpha': 0.3191, 'lambda': 38.67459909560096, 'max_bin': 384}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:24,711]\u001b[0m Trial 431 finished with value: 0.8234022966049064 and parameters: {'n_estimators': 761, 'eta': 0.0913172915520364, 'max_depth': 10, 'alpha': 0.3733, 'lambda': 30.40799118026352, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:31,627]\u001b[0m Trial 432 finished with value: 0.8223055079182817 and parameters: {'n_estimators': 462, 'eta': 0.09449328795683132, 'max_depth': 11, 'alpha': 0.42800000000000005, 'lambda': 35.31408479651013, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:38,510]\u001b[0m Trial 433 finished with value: 0.8302674225156602 and parameters: {'n_estimators': 833, 'eta': 0.09762717524713195, 'max_depth': 11, 'alpha': 0.3972, 'lambda': 34.17586423177925, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:44,918]\u001b[0m Trial 434 finished with value: 0.8274917532439569 and parameters: {'n_estimators': 814, 'eta': 0.09299939610880582, 'max_depth': 11, 'alpha': 0.6023000000000001, 'lambda': 31.550257692454764, 'max_bin': 392}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:51,261]\u001b[0m Trial 435 finished with value: 0.8314633600224856 and parameters: {'n_estimators': 883, 'eta': 0.09997502590293485, 'max_depth': 11, 'alpha': 0.21330000000000002, 'lambda': 24.792325638522534, 'max_bin': 345}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:08:58,149]\u001b[0m Trial 436 finished with value: 0.830271060053428 and parameters: {'n_estimators': 856, 'eta': 0.09610762659311825, 'max_depth': 11, 'alpha': 0.2771, 'lambda': 37.08765956051956, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:05,417]\u001b[0m Trial 437 finished with value: 0.8293307086852646 and parameters: {'n_estimators': 796, 'eta': 0.09751931852002331, 'max_depth': 12, 'alpha': 0.3537, 'lambda': 32.68909924046234, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:13,185]\u001b[0m Trial 438 finished with value: 0.8262068401936415 and parameters: {'n_estimators': 900, 'eta': 0.0896047004435376, 'max_depth': 11, 'alpha': 0.3266, 'lambda': 36.135193361164184, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:25,227]\u001b[0m Trial 439 finished with value: 0.8253253921809968 and parameters: {'n_estimators': 872, 'eta': 0.04557860146196876, 'max_depth': 11, 'alpha': 0.7652, 'lambda': 37.72792131252456, 'max_bin': 350}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:31,802]\u001b[0m Trial 440 finished with value: 0.8244353734013548 and parameters: {'n_estimators': 842, 'eta': 0.09511405949102612, 'max_depth': 11, 'alpha': 0.2325, 'lambda': 30.668711969293703, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:38,171]\u001b[0m Trial 441 finished with value: 0.8308841199986452 and parameters: {'n_estimators': 814, 'eta': 0.09994397192664842, 'max_depth': 10, 'alpha': 0.41100000000000003, 'lambda': 34.96238538013885, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:45,118]\u001b[0m Trial 442 finished with value: 0.8204089027421295 and parameters: {'n_estimators': 859, 'eta': 0.09269797517117472, 'max_depth': 11, 'alpha': 0.4505, 'lambda': 29.6707337839486, 'max_bin': 362}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:09:51,079]\u001b[0m Trial 443 finished with value: 0.8291755471959373 and parameters: {'n_estimators': 884, 'eta': 0.09770543129853085, 'max_depth': 11, 'alpha': 0.29810000000000003, 'lambda': 20.42819325860372, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:05,715]\u001b[0m Trial 444 finished with value: 0.8125120717233786 and parameters: {'n_estimators': 534, 'eta': 0.010992124590863371, 'max_depth': 11, 'alpha': 0.4812, 'lambda': 28.661809938362257, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:12,717]\u001b[0m Trial 445 finished with value: 0.8284399963257256 and parameters: {'n_estimators': 842, 'eta': 0.09562990808130505, 'max_depth': 11, 'alpha': 0.24650000000000002, 'lambda': 31.69478588207987, 'max_bin': 340}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:20,336]\u001b[0m Trial 446 finished with value: 0.8250433589040936 and parameters: {'n_estimators': 827, 'eta': 0.09811501519461133, 'max_depth': 11, 'alpha': 0.6662, 'lambda': 36.73261063768797, 'max_bin': 448}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:27,947]\u001b[0m Trial 447 finished with value: 0.8287411636588835 and parameters: {'n_estimators': 868, 'eta': 0.07081094008752835, 'max_depth': 10, 'alpha': 0.3808, 'lambda': 18.95263108710781, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:35,383]\u001b[0m Trial 448 finished with value: 0.8302684476641154 and parameters: {'n_estimators': 782, 'eta': 0.09386409205444968, 'max_depth': 10, 'alpha': 0.28150000000000003, 'lambda': 38.33989691828478, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:43,190]\u001b[0m Trial 449 finished with value: 0.827207819469247 and parameters: {'n_estimators': 886, 'eta': 0.09618487307687688, 'max_depth': 12, 'alpha': 0.7489, 'lambda': 35.88540585795183, 'max_bin': 360}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 450.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_8 = lambda trial: objective_xgb_CV(trial, X_trainSet8, Y_trainSet8, Y_trainSet8_class)\n",
    "study_xgb.optimize(func_xgb_8, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b9ad3192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:03:28.091756Z",
     "iopub.status.busy": "2023-01-15T15:03:28.091623Z",
     "iopub.status.idle": "2023-01-15T15:03:28.522402Z",
     "shell.execute_reply": "2023-01-15T15:03:28.521964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8  \n",
      "0   344.000000  339.000000  322.000000  337.000000  335.000000  \n",
      "1   161.000000  172.000000  179.000000  178.000000  165.000000  \n",
      "2    64.000000   53.000000   53.000000   43.000000   62.000000  \n",
      "3    26.000000   31.000000   41.000000   37.000000   33.000000  \n",
      "4     0.848739    0.858824    0.842017    0.865546    0.840336  \n",
      "5     0.843137    0.864796    0.858667    0.886842    0.843829  \n",
      "6     0.929730    0.916216    0.887052    0.901070    0.910326  \n",
      "7     0.715600    0.764400    0.771600    0.805400    0.726900  \n",
      "8     0.884319    0.889764    0.872629    0.893899    0.875817  \n",
      "9     0.845458    0.857233    0.841204    0.865156    0.837915  \n",
      "10    0.832936    0.846751    0.832332    0.855206    0.826144  \n",
      "11    0.822643    0.840330    0.829302    0.853250    0.818599  \n",
      "12    0.674051    0.696196    0.665418    0.710612    0.656876  \n",
      "13    0.861000    0.847300    0.813600    0.827900    0.833300  \n",
      "14    0.822643    0.840330    0.829302    0.853250    0.818599  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_8 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet8, Y_testSet8)]\n",
    "optimized_xgb_8.fit(X_trainSet8,Y_trainSet8, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_8 = optimized_xgb_8.predict(X_testSet8)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet8, y_pred_xgb_8)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet8, y_pred_xgb_8)\n",
    "Precision = precision_score(Y_testSet8, y_pred_xgb_8)\n",
    "Sensitivity = recall_score(Y_testSet8, y_pred_xgb_8)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet8, y_pred_xgb_8)      \n",
    "f1_scores_W = f1_score(Y_testSet8, y_pred_xgb_8, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet8, y_pred_xgb_8, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet8, y_pred_xgb_8)\n",
    "MCC = matthews_corrcoef(Y_testSet8, y_pred_xgb_8)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet8, y_pred_xgb_8)\n",
    "\n",
    "\n",
    "Set8 = pd.DataFrame({ 'Set8':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set8'] =Set8\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d985847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:03:28.524017Z",
     "iopub.status.busy": "2023-01-15T15:03:28.523900Z",
     "iopub.status.idle": "2023-01-15T15:08:18.015274Z",
     "shell.execute_reply": "2023-01-15T15:08:18.014935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:10:49,585]\u001b[0m Trial 450 finished with value: 0.823822804579495 and parameters: {'n_estimators': 849, 'eta': 0.0910374311952486, 'max_depth': 11, 'alpha': 0.5752, 'lambda': 31.063066793161603, 'max_bin': 346}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:55,880]\u001b[0m Trial 451 finished with value: 0.824667603283212 and parameters: {'n_estimators': 806, 'eta': 0.09998178276748991, 'max_depth': 11, 'alpha': 0.3435, 'lambda': 33.312053491325436, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:10:59,950]\u001b[0m Trial 452 finished with value: 0.8316823214928247 and parameters: {'n_estimators': 827, 'eta': 0.0977409330657724, 'max_depth': 11, 'alpha': 0.3015, 'lambda': 5.24342650887098, 'max_bin': 389}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:07,315]\u001b[0m Trial 453 finished with value: 0.8237900018918813 and parameters: {'n_estimators': 869, 'eta': 0.09393631947986446, 'max_depth': 11, 'alpha': 0.5068, 'lambda': 34.22178496486156, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:13,602]\u001b[0m Trial 454 finished with value: 0.8258455927795734 and parameters: {'n_estimators': 857, 'eta': 0.09639142134662435, 'max_depth': 11, 'alpha': 0.2636, 'lambda': 32.424003066364016, 'max_bin': 398}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:20,326]\u001b[0m Trial 455 finished with value: 0.8268281733076819 and parameters: {'n_estimators': 900, 'eta': 0.09840043963914581, 'max_depth': 11, 'alpha': 0.35810000000000003, 'lambda': 30.611587766335752, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:26,519]\u001b[0m Trial 456 finished with value: 0.8261585828927525 and parameters: {'n_estimators': 839, 'eta': 0.09480819740183334, 'max_depth': 11, 'alpha': 0.3163, 'lambda': 27.900446190013884, 'max_bin': 371}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:33,371]\u001b[0m Trial 457 finished with value: 0.8201848188490442 and parameters: {'n_estimators': 877, 'eta': 0.0920840495342707, 'max_depth': 11, 'alpha': 0.6433, 'lambda': 35.3503386943424, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:41,138]\u001b[0m Trial 458 finished with value: 0.821858430252815 and parameters: {'n_estimators': 817, 'eta': 0.08607223716045481, 'max_depth': 9, 'alpha': 0.46340000000000003, 'lambda': 37.45618352025407, 'max_bin': 363}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:47,726]\u001b[0m Trial 459 finished with value: 0.8245517321898614 and parameters: {'n_estimators': 796, 'eta': 0.09689481019081743, 'max_depth': 11, 'alpha': 0.3895, 'lambda': 30.07612676014415, 'max_bin': 381}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:11:53,978]\u001b[0m Trial 460 finished with value: 0.826865098094912 and parameters: {'n_estimators': 886, 'eta': 0.08842182073943564, 'max_depth': 11, 'alpha': 0.368, 'lambda': 26.704627221213546, 'max_bin': 368}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:00,530]\u001b[0m Trial 461 finished with value: 0.8261487376057797 and parameters: {'n_estimators': 852, 'eta': 0.09820274707093593, 'max_depth': 12, 'alpha': 0.4143, 'lambda': 36.478684599489576, 'max_bin': 332}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:07,295]\u001b[0m Trial 462 finished with value: 0.8243073663264152 and parameters: {'n_estimators': 869, 'eta': 0.09483703858311819, 'max_depth': 10, 'alpha': 0.2467, 'lambda': 31.899827568679278, 'max_bin': 348}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:14,618]\u001b[0m Trial 463 finished with value: 0.824843186611227 and parameters: {'n_estimators': 830, 'eta': 0.09336879671395568, 'max_depth': 11, 'alpha': 0.7327, 'lambda': 39.13629561491521, 'max_bin': 374}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:21,290]\u001b[0m Trial 464 finished with value: 0.8267681101146422 and parameters: {'n_estimators': 856, 'eta': 0.0983867798004335, 'max_depth': 11, 'alpha': 0.3356, 'lambda': 34.73643401642998, 'max_bin': 358}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:29,668]\u001b[0m Trial 465 finished with value: 0.8278862633715798 and parameters: {'n_estimators': 900, 'eta': 0.07653738954122619, 'max_depth': 11, 'alpha': 0.2813, 'lambda': 31.354228647871413, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:35,022]\u001b[0m Trial 466 finished with value: 0.8262783331071102 and parameters: {'n_estimators': 271, 'eta': 0.0961065701230403, 'max_depth': 10, 'alpha': 0.20980000000000001, 'lambda': 29.14667235094291, 'max_bin': 354}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:42,346]\u001b[0m Trial 467 finished with value: 0.823557345447737 and parameters: {'n_estimators': 782, 'eta': 0.09077525204373, 'max_depth': 11, 'alpha': 0.30820000000000003, 'lambda': 35.77306413036975, 'max_bin': 343}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:49,380]\u001b[0m Trial 468 finished with value: 0.8247093441816938 and parameters: {'n_estimators': 812, 'eta': 0.09996175442580968, 'max_depth': 10, 'alpha': 0.6994, 'lambda': 36.99273587234809, 'max_bin': 385}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:12:55,598]\u001b[0m Trial 469 finished with value: 0.8229350632307144 and parameters: {'n_estimators': 838, 'eta': 0.0962554281767685, 'max_depth': 11, 'alpha': 0.3342, 'lambda': 30.187828285710008, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:01,316]\u001b[0m Trial 470 finished with value: 0.8219888910207753 and parameters: {'n_estimators': 875, 'eta': 0.09335325839991898, 'max_depth': 11, 'alpha': 0.44220000000000004, 'lambda': 33.6724053346767, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:21,536]\u001b[0m Trial 471 finished with value: 0.8230176423368146 and parameters: {'n_estimators': 852, 'eta': 0.022221990238419895, 'max_depth': 11, 'alpha': 0.2602, 'lambda': 32.6331363819136, 'max_bin': 376}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:29,007]\u001b[0m Trial 472 finished with value: 0.824028116072199 and parameters: {'n_estimators': 885, 'eta': 0.09998897688360336, 'max_depth': 11, 'alpha': 0.2849, 'lambda': 37.723613349238846, 'max_bin': 394}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:35,767]\u001b[0m Trial 473 finished with value: 0.8267799135265154 and parameters: {'n_estimators': 820, 'eta': 0.09759824885270088, 'max_depth': 11, 'alpha': 0.1787, 'lambda': 31.232339800966624, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:42,491]\u001b[0m Trial 474 finished with value: 0.8229351932054996 and parameters: {'n_estimators': 865, 'eta': 0.0950763585832107, 'max_depth': 10, 'alpha': 0.22690000000000002, 'lambda': 35.82329389929783, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:49,413]\u001b[0m Trial 475 finished with value: 0.8274181666713535 and parameters: {'n_estimators': 833, 'eta': 0.09822080698060713, 'max_depth': 11, 'alpha': 0.3493, 'lambda': 38.35475575257548, 'max_bin': 403}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:13:56,366]\u001b[0m Trial 476 finished with value: 0.8234361181237126 and parameters: {'n_estimators': 795, 'eta': 0.0925548718008043, 'max_depth': 12, 'alpha': 0.4849, 'lambda': 36.54461353635049, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:03,372]\u001b[0m Trial 477 finished with value: 0.8251659437494064 and parameters: {'n_estimators': 881, 'eta': 0.09642254126191109, 'max_depth': 11, 'alpha': 0.3785, 'lambda': 34.711130081470785, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:09,367]\u001b[0m Trial 478 finished with value: 0.8238897089789944 and parameters: {'n_estimators': 770, 'eta': 0.09482637246067802, 'max_depth': 11, 'alpha': 0.3211, 'lambda': 29.758691206694913, 'max_bin': 338}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:14:15,316]\u001b[0m Trial 479 finished with value: 0.8276089526839823 and parameters: {'n_estimators': 848, 'eta': 0.09813742212638642, 'max_depth': 11, 'alpha': 0.5217, 'lambda': 31.95213923594425, 'max_bin': 348}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:21,569]\u001b[0m Trial 480 finished with value: 0.826695730953625 and parameters: {'n_estimators': 867, 'eta': 0.09089466018245988, 'max_depth': 10, 'alpha': 0.4218, 'lambda': 30.580444528050762, 'max_bin': 372}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:28,327]\u001b[0m Trial 481 finished with value: 0.8244575441427413 and parameters: {'n_estimators': 578, 'eta': 0.09996313078971057, 'max_depth': 11, 'alpha': 0.2381, 'lambda': 33.12578480346974, 'max_bin': 364}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:35,050]\u001b[0m Trial 482 finished with value: 0.826028023266745 and parameters: {'n_estimators': 807, 'eta': 0.09673734628494084, 'max_depth': 11, 'alpha': 0.2962, 'lambda': 37.117229665837115, 'max_bin': 380}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:42,258]\u001b[0m Trial 483 finished with value: 0.8250714338912248 and parameters: {'n_estimators': 839, 'eta': 0.09417327489028732, 'max_depth': 11, 'alpha': 0.6121, 'lambda': 35.35247217819526, 'max_bin': 389}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:48,615]\u001b[0m Trial 484 finished with value: 0.8257994659619874 and parameters: {'n_estimators': 886, 'eta': 0.09599206827954841, 'max_depth': 11, 'alpha': 0.40240000000000004, 'lambda': 32.41773110260684, 'max_bin': 357}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:14:55,034]\u001b[0m Trial 485 finished with value: 0.8252615553550158 and parameters: {'n_estimators': 858, 'eta': 0.09852181362816555, 'max_depth': 11, 'alpha': 0.3642, 'lambda': 31.23211009379821, 'max_bin': 369}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:02,402]\u001b[0m Trial 486 finished with value: 0.8248176228264443 and parameters: {'n_estimators': 900, 'eta': 0.09269507975112849, 'max_depth': 12, 'alpha': 0.7153, 'lambda': 33.89340955673605, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:08,732]\u001b[0m Trial 487 finished with value: 0.8224609540586787 and parameters: {'n_estimators': 824, 'eta': 0.08968113876031651, 'max_depth': 11, 'alpha': 0.6809000000000001, 'lambda': 29.144340261042302, 'max_bin': 477}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:26,095]\u001b[0m Trial 488 finished with value: 0.8217768097884848 and parameters: {'n_estimators': 869, 'eta': 0.029116520712270073, 'max_depth': 10, 'alpha': 0.2624, 'lambda': 36.343411715333616, 'max_bin': 352}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:33,963]\u001b[0m Trial 489 finished with value: 0.8197959946661335 and parameters: {'n_estimators': 841, 'eta': 0.09732882021474458, 'max_depth': 5, 'alpha': 0.3241, 'lambda': 38.11713009991048, 'max_bin': 343}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:39,978]\u001b[0m Trial 490 finished with value: 0.8278313402881438 and parameters: {'n_estimators': 817, 'eta': 0.09995097128674148, 'max_depth': 11, 'alpha': 0.38830000000000003, 'lambda': 30.534836316594312, 'max_bin': 375}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:45,775]\u001b[0m Trial 491 finished with value: 0.8245380639824955 and parameters: {'n_estimators': 883, 'eta': 0.09513105666763608, 'max_depth': 11, 'alpha': 0.46890000000000004, 'lambda': 31.730378357976335, 'max_bin': 365}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:52,388]\u001b[0m Trial 492 finished with value: 0.8260841096095056 and parameters: {'n_estimators': 755, 'eta': 0.09668169206364155, 'max_depth': 11, 'alpha': 0.5004000000000001, 'lambda': 35.831884210558535, 'max_bin': 349}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:15:59,430]\u001b[0m Trial 493 finished with value: 0.8227428276344899 and parameters: {'n_estimators': 853, 'eta': 0.09345838917943332, 'max_depth': 11, 'alpha': 0.2781, 'lambda': 39.68562422329232, 'max_bin': 356}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:06,266]\u001b[0m Trial 494 finished with value: 0.8271505081406652 and parameters: {'n_estimators': 802, 'eta': 0.09820191205981708, 'max_depth': 11, 'alpha': 0.4471, 'lambda': 36.639718589649796, 'max_bin': 361}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:12,791]\u001b[0m Trial 495 finished with value: 0.8218930747441029 and parameters: {'n_estimators': 900, 'eta': 0.09506565494929561, 'max_depth': 9, 'alpha': 0.29660000000000003, 'lambda': 34.322321656355186, 'max_bin': 366}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:19,438]\u001b[0m Trial 496 finished with value: 0.8275408079103741 and parameters: {'n_estimators': 867, 'eta': 0.09230084989952801, 'max_depth': 10, 'alpha': 0.6321, 'lambda': 29.739377479951532, 'max_bin': 384}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:25,705]\u001b[0m Trial 497 finished with value: 0.8234494139085363 and parameters: {'n_estimators': 832, 'eta': 0.09828596436528277, 'max_depth': 11, 'alpha': 0.3524, 'lambda': 35.10485917228927, 'max_bin': 370}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:32,411]\u001b[0m Trial 498 finished with value: 0.8255582032401512 and parameters: {'n_estimators': 662, 'eta': 0.09996014386022774, 'max_depth': 8, 'alpha': 0.2511, 'lambda': 37.60613926741361, 'max_bin': 377}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:16:36,272]\u001b[0m Trial 499 finished with value: 0.8309501584343145 and parameters: {'n_estimators': 876, 'eta': 0.09639734317175017, 'max_depth': 12, 'alpha': 0.21150000000000002, 'lambda': 4.031483401192748, 'max_bin': 353}. Best is trial 134 with value: 0.8466591551930043.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.8467\n",
      "\tBest params:\n",
      "\t\tn_estimators: 800\n",
      "\t\teta: 0.09523263614439825\n",
      "\t\tmax_depth: 11\n",
      "\t\talpha: 0.47040000000000004\n",
      "\t\tlambda: 31.295709075795422\n",
      "\t\tmax_bin: 345\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_xgb_9 = lambda trial: objective_xgb_CV(trial, X_trainSet9, Y_trainSet9, Y_trainSet9_class)\n",
    "study_xgb.optimize(func_xgb_9, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_xgb.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_xgb.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e9f6fc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:18.016913Z",
     "iopub.status.busy": "2023-01-15T15:08:18.016759Z",
     "iopub.status.idle": "2023-01-15T15:08:18.518428Z",
     "shell.execute_reply": "2023-01-15T15:08:18.518053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
      "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
      "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
      "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
      "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
      "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
      "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
      "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
      "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
      "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
      "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
      "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
      "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
      "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
      "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8        Set9  \n",
      "0   344.000000  339.000000  322.000000  337.000000  335.000000  347.000000  \n",
      "1   161.000000  172.000000  179.000000  178.000000  165.000000  162.000000  \n",
      "2    64.000000   53.000000   53.000000   43.000000   62.000000   47.000000  \n",
      "3    26.000000   31.000000   41.000000   37.000000   33.000000   39.000000  \n",
      "4     0.848739    0.858824    0.842017    0.865546    0.840336    0.855462  \n",
      "5     0.843137    0.864796    0.858667    0.886842    0.843829    0.880711  \n",
      "6     0.929730    0.916216    0.887052    0.901070    0.910326    0.898964  \n",
      "7     0.715600    0.764400    0.771600    0.805400    0.726900    0.775100  \n",
      "8     0.884319    0.889764    0.872629    0.893899    0.875817    0.889744  \n",
      "9     0.845458    0.857233    0.841204    0.865156    0.837915    0.854793  \n",
      "10    0.832936    0.846751    0.832332    0.855206    0.826144    0.839994  \n",
      "11    0.822643    0.840330    0.829302    0.853250    0.818599    0.837042  \n",
      "12    0.674051    0.696196    0.665418    0.710612    0.656876    0.680353  \n",
      "13    0.861000    0.847300    0.813600    0.827900    0.833300    0.806000  \n",
      "14    0.822643    0.840330    0.829302    0.853250    0.818599    0.837042  \n"
     ]
    }
   ],
   "source": [
    "optimized_xgb_9 = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "    \n",
    "eval_set = [(X_testSet9, Y_testSet9)]\n",
    "optimized_xgb_9.fit(X_trainSet9,Y_trainSet9, \n",
    "                          eval_set=eval_set,\n",
    "                          eval_metric=[\"logloss\"],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose= False,\n",
    "                  )\n",
    "\n",
    "#predict        \n",
    "y_pred_xgb_9 = optimized_xgb_9.predict(X_testSet9)\n",
    "\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet9, y_pred_xgb_9)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet9, y_pred_xgb_9)\n",
    "Precision = precision_score(Y_testSet9, y_pred_xgb_9)\n",
    "Sensitivity = recall_score(Y_testSet9, y_pred_xgb_9)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet9, y_pred_xgb_9)      \n",
    "f1_scores_W = f1_score(Y_testSet9, y_pred_xgb_9, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet9, y_pred_xgb_9, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet9, y_pred_xgb_9)\n",
    "MCC = matthews_corrcoef(Y_testSet9, y_pred_xgb_9)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet9, y_pred_xgb_9)\n",
    "\n",
    "\n",
    "Set9 = pd.DataFrame({ 'Set9':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "            \n",
    "                       })    \n",
    "\n",
    "mat_met_xgb_test['Set9'] =Set9\n",
    "print(mat_met_xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c1317b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:18.520122Z",
     "iopub.status.busy": "2023-01-15T15:08:18.519962Z",
     "iopub.status.idle": "2023-01-15T15:08:18.656284Z",
     "shell.execute_reply": "2023-01-15T15:08:18.655914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study_xgb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b90d1484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:18.657960Z",
     "iopub.status.busy": "2023-01-15T15:08:18.657796Z",
     "iopub.status.idle": "2023-01-15T15:08:38.048579Z",
     "shell.execute_reply": "2023-01-15T15:08:38.048286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param_importances(study_xgb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b46bd79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:38.049990Z",
     "iopub.status.busy": "2023-01-15T15:08:38.049858Z",
     "iopub.status.idle": "2023-01-15T15:08:43.794806Z",
     "shell.execute_reply": "2023-01-15T15:08:43.794482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value (average)</th>\n",
       "      <th>Value (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>8.646772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>6.289321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>3.627059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>4.325634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.851914</td>\n",
       "      <td>0.023701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.866378</td>\n",
       "      <td>0.020484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.898484</td>\n",
       "      <td>0.024362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.028963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.882063</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.850982</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.837244</td>\n",
       "      <td>0.023232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.683402</td>\n",
       "      <td>0.048636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.826100</td>\n",
       "      <td>0.036732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.837244</td>\n",
       "      <td>0.023232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value (average)  Value (std)\n",
       "0                    TP       165.100000     8.646772\n",
       "1                    TN        88.000000     6.289321\n",
       "2                    FP        25.400000     3.627059\n",
       "3                    FN        18.600000     4.325634\n",
       "4              Accuracy         0.851914     0.023701\n",
       "5             Precision         0.866378     0.020484\n",
       "6           Sensitivity         0.898484     0.024362\n",
       "7           Specificity         0.776000     0.028963\n",
       "8              F1 score         0.882063     0.020658\n",
       "9   F1 score (weighted)         0.850982     0.023700\n",
       "10     F1 score (macro)         0.841053     0.024128\n",
       "11    Balanced Accuracy         0.837244     0.023232\n",
       "12                  MCC         0.683402     0.048636\n",
       "13                  NPV         0.826100     0.036732\n",
       "14              ROC_AUC         0.837244     0.023232"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objective_xgb_CV(study_xgb.best_trial, X, Y, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc89d739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:43.796401Z",
     "iopub.status.busy": "2023-01-15T15:08:43.796275Z",
     "iopub.status.idle": "2023-01-15T15:08:43.809281Z",
     "shell.execute_reply": "2023-01-15T15:08:43.809000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Set0</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Set3</th>\n",
       "      <th>Set4</th>\n",
       "      <th>Set5</th>\n",
       "      <th>Set6</th>\n",
       "      <th>Set7</th>\n",
       "      <th>Set8</th>\n",
       "      <th>Set9</th>\n",
       "      <th>ave</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>336.300000</td>\n",
       "      <td>9.141481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>169.500000</td>\n",
       "      <td>7.043516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>54.700000</td>\n",
       "      <td>8.179242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>8.195527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.853782</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.850084</td>\n",
       "      <td>0.010047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.872396</td>\n",
       "      <td>0.832512</td>\n",
       "      <td>0.867209</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.864796</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.886842</td>\n",
       "      <td>0.843829</td>\n",
       "      <td>0.880711</td>\n",
       "      <td>0.860442</td>\n",
       "      <td>0.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.936288</td>\n",
       "      <td>0.862534</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.887052</td>\n",
       "      <td>0.901070</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.898964</td>\n",
       "      <td>0.907028</td>\n",
       "      <td>0.021834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.764400</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.805400</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.756380</td>\n",
       "      <td>0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.888318</td>\n",
       "      <td>0.884319</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.872629</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.875817</td>\n",
       "      <td>0.889744</td>\n",
       "      <td>0.882813</td>\n",
       "      <td>0.009128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.856238</td>\n",
       "      <td>0.843410</td>\n",
       "      <td>0.832079</td>\n",
       "      <td>0.851177</td>\n",
       "      <td>0.845458</td>\n",
       "      <td>0.857233</td>\n",
       "      <td>0.841204</td>\n",
       "      <td>0.865156</td>\n",
       "      <td>0.837915</td>\n",
       "      <td>0.854793</td>\n",
       "      <td>0.848466</td>\n",
       "      <td>0.010168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.846007</td>\n",
       "      <td>0.833113</td>\n",
       "      <td>0.821321</td>\n",
       "      <td>0.838320</td>\n",
       "      <td>0.832936</td>\n",
       "      <td>0.846751</td>\n",
       "      <td>0.832332</td>\n",
       "      <td>0.855206</td>\n",
       "      <td>0.826144</td>\n",
       "      <td>0.839994</td>\n",
       "      <td>0.837212</td>\n",
       "      <td>0.010193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.842107</td>\n",
       "      <td>0.822845</td>\n",
       "      <td>0.821892</td>\n",
       "      <td>0.829083</td>\n",
       "      <td>0.822643</td>\n",
       "      <td>0.840330</td>\n",
       "      <td>0.829302</td>\n",
       "      <td>0.853250</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>0.837042</td>\n",
       "      <td>0.831709</td>\n",
       "      <td>0.011139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.642663</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.710612</td>\n",
       "      <td>0.656876</td>\n",
       "      <td>0.680353</td>\n",
       "      <td>0.677871</td>\n",
       "      <td>0.019747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.829400</td>\n",
       "      <td>0.878300</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.852600</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.847300</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.827900</td>\n",
       "      <td>0.833300</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.029835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.842107</td>\n",
       "      <td>0.822845</td>\n",
       "      <td>0.821892</td>\n",
       "      <td>0.829083</td>\n",
       "      <td>0.822643</td>\n",
       "      <td>0.840330</td>\n",
       "      <td>0.829302</td>\n",
       "      <td>0.853250</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>0.837042</td>\n",
       "      <td>0.831709</td>\n",
       "      <td>0.011139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric        Set0        Set1        Set2        Set3  \\\n",
       "0                    TP  335.000000  338.000000  320.000000  346.000000   \n",
       "1                    TN  175.000000  166.000000  175.000000  162.000000   \n",
       "2                    FP   49.000000   68.000000   49.000000   59.000000   \n",
       "3                    FN   36.000000   23.000000   51.000000   28.000000   \n",
       "4              Accuracy    0.857143    0.847059    0.831933    0.853782   \n",
       "5             Precision    0.872396    0.832512    0.867209    0.854321   \n",
       "6           Sensitivity    0.902965    0.936288    0.862534    0.925134   \n",
       "7           Specificity    0.781200    0.709400    0.781200    0.733000   \n",
       "8              F1 score    0.887417    0.881356    0.864865    0.888318   \n",
       "9   F1 score (weighted)    0.856238    0.843410    0.832079    0.851177   \n",
       "10     F1 score (macro)    0.846007    0.833113    0.821321    0.838320   \n",
       "11    Balanced Accuracy    0.842107    0.822845    0.821892    0.829083   \n",
       "12                  MCC    0.692942    0.677472    0.642663    0.682123   \n",
       "13                  NPV    0.829400    0.878300    0.774300    0.852600   \n",
       "14              ROC_AUC    0.842107    0.822845    0.821892    0.829083   \n",
       "\n",
       "          Set4        Set5        Set6        Set7        Set8        Set9  \\\n",
       "0   344.000000  339.000000  322.000000  337.000000  335.000000  347.000000   \n",
       "1   161.000000  172.000000  179.000000  178.000000  165.000000  162.000000   \n",
       "2    64.000000   53.000000   53.000000   43.000000   62.000000   47.000000   \n",
       "3    26.000000   31.000000   41.000000   37.000000   33.000000   39.000000   \n",
       "4     0.848739    0.858824    0.842017    0.865546    0.840336    0.855462   \n",
       "5     0.843137    0.864796    0.858667    0.886842    0.843829    0.880711   \n",
       "6     0.929730    0.916216    0.887052    0.901070    0.910326    0.898964   \n",
       "7     0.715600    0.764400    0.771600    0.805400    0.726900    0.775100   \n",
       "8     0.884319    0.889764    0.872629    0.893899    0.875817    0.889744   \n",
       "9     0.845458    0.857233    0.841204    0.865156    0.837915    0.854793   \n",
       "10    0.832936    0.846751    0.832332    0.855206    0.826144    0.839994   \n",
       "11    0.822643    0.840330    0.829302    0.853250    0.818599    0.837042   \n",
       "12    0.674051    0.696196    0.665418    0.710612    0.656876    0.680353   \n",
       "13    0.861000    0.847300    0.813600    0.827900    0.833300    0.806000   \n",
       "14    0.822643    0.840330    0.829302    0.853250    0.818599    0.837042   \n",
       "\n",
       "           ave       std  \n",
       "0   336.300000  9.141481  \n",
       "1   169.500000  7.043516  \n",
       "2    54.700000  8.179242  \n",
       "3    34.500000  8.195527  \n",
       "4     0.850084  0.010047  \n",
       "5     0.860442  0.017358  \n",
       "6     0.907028  0.021834  \n",
       "7     0.756380  0.032604  \n",
       "8     0.882813  0.009128  \n",
       "9     0.848466  0.010168  \n",
       "10    0.837212  0.010193  \n",
       "11    0.831709  0.011139  \n",
       "12    0.677871  0.019747  \n",
       "13    0.832370  0.029835  \n",
       "14    0.831709  0.011139  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_met_xgb_test['ave'] = mat_met_xgb_test.iloc[:,1:11].mean(axis='columns', numeric_only=True)\n",
    "mat_met_xgb_test['std'] = mat_met_xgb_test.iloc[:,1:11].std(axis='columns', numeric_only=True)\n",
    "mat_met_xgb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01de6232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:08:43.810736Z",
     "iopub.status.busy": "2023-01-15T15:08:43.810612Z",
     "iopub.status.idle": "2023-01-15T15:09:10.972102Z",
     "shell.execute_reply": "2023-01-15T15:09:10.971729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test_idx0</th>\n",
       "      <th>y_test0</th>\n",
       "      <th>y_pred_xgb0</th>\n",
       "      <th>y_pred_xgb1</th>\n",
       "      <th>y_pred_xgb2</th>\n",
       "      <th>y_pred_xgb3</th>\n",
       "      <th>y_pred_xgb4</th>\n",
       "      <th>y_pred_xgb_ave</th>\n",
       "      <th>y_pred_xgb_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test_idx0  y_test0  y_pred_xgb0  y_pred_xgb1  y_pred_xgb2  \\\n",
       "0               0      1.0          1.0          1.0          1.0   \n",
       "1               1      1.0          1.0          1.0          1.0   \n",
       "2               2      0.0          0.0          0.0          0.0   \n",
       "3               3      0.0          1.0          1.0          1.0   \n",
       "4               4      0.0          1.0          1.0          1.0   \n",
       "...           ...      ...          ...          ...          ...   \n",
       "2966         2966      1.0          1.0          1.0          1.0   \n",
       "2967         2967      1.0          1.0          1.0          1.0   \n",
       "2968         2968      0.0          1.0          1.0          1.0   \n",
       "2969         2969      1.0          1.0          0.0          0.0   \n",
       "2970         2970      1.0          0.0          0.0          0.0   \n",
       "\n",
       "      y_pred_xgb3  y_pred_xgb4  y_pred_xgb_ave  y_pred_xgb_std  \n",
       "0             1.0          1.0             1.0             0.0  \n",
       "1             1.0          1.0             1.0             0.0  \n",
       "2             0.0          0.0             0.0             0.0  \n",
       "3             1.0          1.0             1.0             0.0  \n",
       "4             1.0          1.0             1.0             0.0  \n",
       "...           ...          ...             ...             ...  \n",
       "2966          1.0          1.0             1.0             0.0  \n",
       "2967          1.0          1.0             1.0             0.0  \n",
       "2968          1.0          1.0             1.0             0.0  \n",
       "2969          0.0          0.0             0.2             0.4  \n",
       "2970          0.0          0.0             0.0             0.0  \n",
       "\n",
       "[2971 rows x 9 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to fit into these X values \n",
    "\n",
    "TP = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "\n",
    "\n",
    "Accuracy_outer = []\n",
    "Precision_outer = [] #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity_outer = [] # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity_outer = [] #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores_outer = []\n",
    "f1_scores_W_outer = []\n",
    "f1_scores_M_outer = []\n",
    "BA_scores_outer = []\n",
    "MCC_outer = []\n",
    "NPV_outer = []\n",
    "ROC_AUC_outer = []\n",
    "\n",
    "NUM_TRIALS = 5\n",
    "random_state= [687266, 98656, 56, 280189, 76543] # \n",
    "data_xgb=pd.DataFrame()\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    cv_change = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state[i])\n",
    "    data_inner = pd.DataFrame({'y_test_idx': pd.Series(dtype='int'),\n",
    "                   'y_test': pd.Series(dtype='float'),\n",
    "                   'y_pred': pd.Series(dtype='float')})\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv_change.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        optimizedCV_xgb = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                    random_state=1121218, \n",
    "                                    booster =\"gbtree\", \n",
    "                                    tree_method='hist', \n",
    "                                    n_estimators = study_xgb.best_params['n_estimators'], \n",
    "                                    eta = study_xgb.best_params['eta'],\n",
    "                                    max_depth = study_xgb.best_params['max_depth'], \n",
    "                                    max_bin = study_xgb.best_params['max_bin'], \n",
    "                                    reg_lambda = study_xgb.best_params['lambda'], \n",
    "                                    alpha =study_xgb.best_params['alpha'],  \n",
    "                                    n_jobs=16,\n",
    "                                    subsample=0.8, \n",
    "                                   )\n",
    "\n",
    "\n",
    "        #learn\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        optimizedCV_xgb.fit(X_train,y_train, \n",
    "            eval_set=eval_set,\n",
    "            eval_metric=[\"logloss\"],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose= False,\n",
    "                  )\n",
    "                          \n",
    "                  \n",
    "        #print(test_idx)\n",
    "        y_pred_optimized_xgb = optimizedCV_xgb.predict(X_test) \n",
    "        data_inner = data_inner.append(pd.DataFrame({'y_test_idx': test_idx, 'y_test': y_test, 'y_pred_xgb': y_pred_optimized_xgb } ), )\n",
    "        data_inner.reset_index(inplace=True, drop=True) \n",
    "        data_inner.sort_values(by='y_test_idx', inplace=True) \n",
    "        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimized_xgb)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        \n",
    "        Accuracy_outer.append(accuracy_score(y_test, y_pred_optimized_xgb))\n",
    "        Precision_outer.append(precision_score(y_test, y_pred_optimized_xgb))\n",
    "        Sensitivity_outer.append(recall_score(y_test, y_pred_optimized_xgb))\n",
    "        Specificity_outer.append(round( TN[idx] / (TN[idx]+FP[idx]),4 ))\n",
    "        f1_scores_outer.append(f1_score(y_test, y_pred_optimized_xgb))\n",
    "        f1_scores_W_outer.append(f1_score(y_test, y_pred_optimized_xgb, average=\"weighted\"))\n",
    "        f1_scores_M_outer.append(f1_score(y_test, y_pred_optimized_xgb, average=\"macro\"))\n",
    "        BA_scores_outer.append(balanced_accuracy_score(y_test, y_pred_optimized_xgb))\n",
    "        MCC_outer.append(matthews_corrcoef(y_test, y_pred_optimized_xgb))\n",
    "        NPV_outer.append(round( TN[idx] / (TN[idx]+FN[idx]),4 ))\n",
    "        ROC_AUC_outer.append(roc_auc_score(y_test, y_pred_optimized_xgb))\n",
    "        \n",
    "    data_xgb['y_test_idx' + str(i)] = data_inner['y_test_idx']\n",
    "    data_xgb['y_test' + str(i)] = data_inner['y_test']\n",
    "    data_xgb['y_pred_xgb' + str(i)] = data_inner['y_pred_xgb']\n",
    "   # data_xgb['correct' + str(i)] = correct_value\n",
    "   # data_xgb['pred' + str(i)] = y_pred_optimized_xgb\n",
    "\n",
    "mat_met_optimized_xgb = pd.DataFrame({'Metric':['Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(Accuracy_outer),np.mean(Precision_outer),\n",
    "                                           np.mean(Sensitivity_outer),np.mean(Specificity_outer),np.mean(f1_scores_outer),\n",
    "                                           np.mean(f1_scores_W_outer), np.mean(f1_scores_M_outer), np.mean(BA_scores_outer), \n",
    "                                           np.mean(MCC_outer),np.mean(NPV_outer),np.mean(ROC_AUC_outer)],\n",
    "                        'Value (std)': [np.std(Accuracy_outer, ddof=1),np.std(Precision_outer, ddof=1),\n",
    "                                        np.std(Sensitivity_outer,ddof=1),np.std(Specificity_outer,ddof=1),np.std(f1_scores_outer, ddof=1),\n",
    "                                        np.std(f1_scores_W_outer, ddof=1),np.std(f1_scores_M_outer, ddof=1), np.std(BA_scores_outer, ddof=1), \n",
    "                                        np.std(MCC_outer, ddof=1),np.std(NPV_outer, ddof=1),np.std(ROC_AUC_outer, ddof=1)]\n",
    "                       }) \n",
    "\n",
    "\n",
    "xgb_run0 = data_xgb[['y_test_idx0', 'y_test0', 'y_pred_xgb0']]\n",
    "xgb_run0.sort_values(by='y_test_idx0', inplace=True)\n",
    "xgb_run0.reset_index(inplace=True, drop=True)\n",
    "xgb_run1 = data_xgb[['y_test_idx1', 'y_test1', 'y_pred_xgb1']]\n",
    "xgb_run1.sort_values(by='y_test_idx1', inplace=True)\n",
    "xgb_run1.reset_index(inplace=True, drop=True)\n",
    "xgb_run2 = data_xgb[['y_test_idx2', 'y_test2', 'y_pred_xgb2']]\n",
    "xgb_run2.sort_values(by='y_test_idx2', inplace=True)\n",
    "xgb_run2.reset_index(inplace=True, drop=True)\n",
    "xgb_run3 = data_xgb[['y_test_idx3', 'y_test3', 'y_pred_xgb3']]\n",
    "xgb_run3.sort_values(by='y_test_idx3', inplace=True)\n",
    "xgb_run3.reset_index(inplace=True, drop=True)\n",
    "xgb_run4 = data_xgb[['y_test_idx4', 'y_test4', 'y_pred_xgb4']]\n",
    "xgb_run4.sort_values(by='y_test_idx4', inplace=True)\n",
    "xgb_run4.reset_index(inplace=True, drop=True)\n",
    "xgb_5preds = pd.concat([xgb_run0, xgb_run1, xgb_run2, xgb_run3, xgb_run4], axis=1)\n",
    "xgb_5preds = xgb_5preds[['y_test_idx0', 'y_test0', 'y_pred_xgb0', 'y_pred_xgb1', 'y_pred_xgb2', 'y_pred_xgb3', 'y_pred_xgb4']]\n",
    "xgb_5preds['y_pred_xgb_ave'] = xgb_5preds.iloc[:,2:11].mean(axis='columns', numeric_only=True)\n",
    "xgb_5preds['y_pred_xgb_std'] = xgb_5preds.iloc[:,2:].std(axis='columns', numeric_only=True)\n",
    "# maybe also calculate the std for each value\n",
    "xgb_5preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2883ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:10.973682Z",
     "iopub.status.busy": "2023-01-15T15:09:10.973507Z",
     "iopub.status.idle": "2023-01-15T15:09:10.988135Z",
     "shell.execute_reply": "2023-01-15T15:09:10.987837Z"
    }
   },
   "outputs": [],
   "source": [
    "mat_met_optimized_xgb.to_csv('mat_met_xgb_opt.csv')\n",
    "xgb_5preds.to_csv('xgb_5test_CV_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eac08484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:10.989791Z",
     "iopub.status.busy": "2023-01-15T15:09:10.989632Z",
     "iopub.status.idle": "2023-01-15T15:09:33.496986Z",
     "shell.execute_reply": "2023-01-15T15:09:33.496624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:17:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:18:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:18:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:18:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost baseline model f1_score 0.8386 with a standard deviation of 0.0201\n",
      "XGBoost optimized model f1_score 0.8371 with a standard deviation of 0.0221\n"
     ]
    }
   ],
   "source": [
    "#cross valide using this optimized XGBoost \n",
    "fit_params = {'early_stopping_rounds': 50, \n",
    "            'eval_set': [(X_tr, Y_tr), (X_te, Y_te)],\n",
    "              'verbose' : False,\n",
    "             }\n",
    "\n",
    "xgb_baseline_CVscore = cross_val_score(xgb_clf, X, Y, cv=10, scoring=\"f1_macro\", )\n",
    "#cv_xgb_opt_testSet = cross_val_score(optimized_xgb, X, Y, cv=10, scoring=\"f1_macro\", fit_params = fit_params)\n",
    "cv_xgb_opt = cross_val_score(optimizedCV_xgb, X, Y, cv=10, scoring=\"f1_macro\", fit_params = fit_params)\n",
    "print(\"XGBoost baseline model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(xgb_baseline_CVscore), np.std(xgb_baseline_CVscore, ddof=1)))\n",
    "#print(\"XGBoost optimized model (tested with Y_te) f1_score %0.4f with a standard deviation of %0.4f\" % (cv_xgb_opt_testSet.mean(), cv_xgb_opt_testSet.std()))\n",
    "print(\"XGBoost optimized model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(cv_xgb_opt), np.std(cv_xgb_opt, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7db6158b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:33.498753Z",
     "iopub.status.busy": "2023-01-15T15:09:33.498599Z",
     "iopub.status.idle": "2023-01-15T15:09:33.524827Z",
     "shell.execute_reply": "2023-01-15T15:09:33.524494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optimizedCV_xgb_clf.joblib']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_clf, \"./xgb_clf.joblib\")\n",
    "#joblib.dump(optimized_xgb, \"./optimized_xgb.joblib\")\n",
    "joblib.dump(optimizedCV_xgb, \"./optimizedCV_xgb_clf.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4b54e",
   "metadata": {},
   "source": [
    "## KNeighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f757a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:33.526719Z",
     "iopub.status.busy": "2023-01-15T15:09:33.526569Z",
     "iopub.status.idle": "2023-01-15T15:09:44.430644Z",
     "shell.execute_reply": "2023-01-15T15:09:44.430251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       165.400000     8.140434\n",
      "1                    TN        80.500000     8.922506\n",
      "2                    FP        32.900000     4.458450\n",
      "3                    FN        18.300000     2.263233\n",
      "4              Accuracy         0.827678     0.017518\n",
      "5             Precision         0.834342     0.018525\n",
      "6           Sensitivity         0.900050     0.014459\n",
      "7           Specificity         0.708560     0.044901\n",
      "8              F1 score         0.865845     0.013552\n",
      "9   F1 score (weighted)         0.824855     0.018398\n",
      "10     F1 score (macro)         0.811578     0.020611\n",
      "11    Balanced Accuracy         0.804300     0.021952\n",
      "12                  MCC         0.628236     0.039357\n",
      "13                  NPV         0.814270     0.020775\n",
      "14              ROC_AUC         0.804300     0.021952\n",
      "CPU times: user 8.97 s, sys: 0 ns, total: 8.97 s\n",
      "Wall time: 8.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "TP =np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "Accuracy = np.empty(10)\n",
    "Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores = np.empty(10)\n",
    "f1_scores_W = np.empty(10)\n",
    "f1_scores_M = np.empty(10)\n",
    "BA_scores = np.empty(10)\n",
    "MCC = np.empty(10)\n",
    "NPV = np.empty(10)\n",
    "ROC_AUC= np.empty(10)\n",
    "\n",
    "\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    \n",
    "    knn_clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = knn_clf.predict(X_test) \n",
    "    \n",
    "    #calculate the evaluation results\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TP[idx] = conf_matrix[1][1]\n",
    "    TN[idx] = conf_matrix[0][0]\n",
    "    FP[idx] = conf_matrix[0][1] \n",
    "    FN[idx] = conf_matrix[1][0]\n",
    "    Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "    Precision[idx] = precision_score(y_test, y_pred)\n",
    "    Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "    Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "    f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "    f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "    MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "    NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "    ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })  \n",
    "    \n",
    "print(mat_met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c405f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:44.432347Z",
     "iopub.status.busy": "2023-01-15T15:09:44.432196Z",
     "iopub.status.idle": "2023-01-15T15:09:44.436418Z",
     "shell.execute_reply": "2023-01-15T15:09:44.436087Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_knn_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \"n_neighbors\" : trial.suggest_int(\"n_neighbors\", 5, 30),\n",
    "        \"weights\" :trial.suggest_categorical(\"weights\", ['uniform', 'distance']),\n",
    "        \"metric\" : trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski']),\n",
    "        \"leaf_size\": trial.suggest_int(\"leaf_size\", 20, 100)\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "   \n",
    "    cv_scores=np.empty(10)\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        knn_model = KNeighborsClassifier(**param_grid, n_jobs=16)\n",
    "        knn_model.fit(X_train,y_train)\n",
    "    \n",
    "        y_pred = knn_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "        cv_scores[idx] = f1_score(y_test, y_pred, average='macro')\n",
    "       \n",
    "        \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a83374a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:44.438015Z",
     "iopub.status.busy": "2023-01-15T15:09:44.437858Z",
     "iopub.status.idle": "2023-01-15T15:09:44.448230Z",
     "shell.execute_reply": "2023-01-15T15:09:44.447914Z"
    }
   },
   "outputs": [],
   "source": [
    "def detailed_objective_knn_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \"n_neighbors\" : trial.suggest_int(\"n_neighbors\", 1, 30),\n",
    "        \"weights\" :trial.suggest_categorical(\"weights\", ['uniform', 'distance']),\n",
    "        \"metric\" : trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski']),\n",
    "        \"leaf_size\": trial.suggest_int(\"leaf_size\", 20, 100)\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu']),      \n",
    "    }\n",
    "    \n",
    "  \n",
    "    TP =np.empty(10)\n",
    "    TN = np.empty(10)\n",
    "    FP = np.empty(10)\n",
    "    FN = np.empty(10)\n",
    "    Accuracy = np.empty(10)\n",
    "    Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "    Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "    Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "    f1_scores = np.empty(10)\n",
    "    f1_scores_W = np.empty(10)\n",
    "    f1_scores_M = np.empty(10)\n",
    "    BA_scores = np.empty(10)\n",
    "    MCC = np.empty(10)\n",
    "    NPV = np.empty(10)\n",
    "    ROC_AUC= np.empty(10)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1121218)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        knn_model = KNeighborsClassifier(**param_grid, n_jobs=16)\n",
    "        knn_model.fit(X_train,y_train)\n",
    "    \n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        \n",
    "        #calculate the evaluation results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })  \n",
    "    \n",
    "    return(mat_met)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16e1ca20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:09:44.449746Z",
     "iopub.status.busy": "2023-01-15T15:09:44.449566Z",
     "iopub.status.idle": "2023-01-15T15:11:26.429346Z",
     "shell.execute_reply": "2023-01-15T15:11:26.428991Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:18:18,444]\u001b[0m A new study created in memory with name: KNNClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:19,816]\u001b[0m Trial 0 finished with value: 0.7974945900679993 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 73}. Best is trial 0 with value: 0.7974945900679993.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:21,183]\u001b[0m Trial 1 finished with value: 0.805034416781886 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 97}. Best is trial 1 with value: 0.805034416781886.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:22,572]\u001b[0m Trial 2 finished with value: 0.8005900267291267 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 99}. Best is trial 1 with value: 0.805034416781886.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:24,650]\u001b[0m Trial 3 finished with value: 0.7945560427118943 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 29}. Best is trial 1 with value: 0.805034416781886.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:26,733]\u001b[0m Trial 4 finished with value: 0.7922427768678817 and parameters: {'n_neighbors': 22, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 24}. Best is trial 1 with value: 0.805034416781886.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:28,288]\u001b[0m Trial 5 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:29,672]\u001b[0m Trial 6 finished with value: 0.8083719297497544 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 74}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:31,368]\u001b[0m Trial 7 finished with value: 0.7843132657310984 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'metric': 'euclidean', 'leaf_size': 50}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:33,480]\u001b[0m Trial 8 finished with value: 0.7940755667986485 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 21}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:35,149]\u001b[0m Trial 9 finished with value: 0.8036230514063153 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 34}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:36,809]\u001b[0m Trial 10 finished with value: 0.8054935970847108 and parameters: {'n_neighbors': 27, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 51}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:38,141]\u001b[0m Trial 11 finished with value: 0.7975661143997955 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 74}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:39,418]\u001b[0m Trial 12 finished with value: 0.8026215436667771 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:40,709]\u001b[0m Trial 13 finished with value: 0.7980694962595692 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 85}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:42,337]\u001b[0m Trial 14 finished with value: 0.8078671377337242 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:43,917]\u001b[0m Trial 15 finished with value: 0.8054498826648603 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 41}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:45,495]\u001b[0m Trial 16 finished with value: 0.8059943543926883 and parameters: {'n_neighbors': 25, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:46,817]\u001b[0m Trial 17 finished with value: 0.8120946744780726 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 87}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:48,146]\u001b[0m Trial 18 finished with value: 0.8162853123901715 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 87}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:49,466]\u001b[0m Trial 19 finished with value: 0.8100658601387334 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 86}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:51,100]\u001b[0m Trial 20 finished with value: 0.8122157032445874 and parameters: {'n_neighbors': 24, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 43}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:52,672]\u001b[0m Trial 21 finished with value: 0.8122157032445874 and parameters: {'n_neighbors': 24, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 46}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:54,301]\u001b[0m Trial 22 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:55,919]\u001b[0m Trial 23 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:57,530]\u001b[0m Trial 24 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:18:59,152]\u001b[0m Trial 25 finished with value: 0.8133196661845637 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:00,833]\u001b[0m Trial 26 finished with value: 0.8101979468123626 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 53}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:02,478]\u001b[0m Trial 27 finished with value: 0.8101979468123626 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:04,046]\u001b[0m Trial 28 finished with value: 0.8151133960759724 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 37}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:05,408]\u001b[0m Trial 29 finished with value: 0.7974945900679993 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 69}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:07,080]\u001b[0m Trial 30 finished with value: 0.8078671377337242 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:08,723]\u001b[0m Trial 31 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:10,083]\u001b[0m Trial 32 finished with value: 0.8146215106205625 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:11,759]\u001b[0m Trial 33 finished with value: 0.8123920551945348 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:13,414]\u001b[0m Trial 34 finished with value: 0.8138866486891695 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:19:15,069]\u001b[0m Trial 35 finished with value: 0.7919497252938619 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 47}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:16,406]\u001b[0m Trial 36 finished with value: 0.8082462907159634 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 78}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:17,805]\u001b[0m Trial 37 finished with value: 0.7872666459161636 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:19,455]\u001b[0m Trial 38 finished with value: 0.8094966100438808 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:21,161]\u001b[0m Trial 39 finished with value: 0.7938873763167307 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 49}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:22,825]\u001b[0m Trial 40 finished with value: 0.8148579956147148 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:24,486]\u001b[0m Trial 41 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:26,144]\u001b[0m Trial 42 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:27,450]\u001b[0m Trial 43 finished with value: 0.8088598128603722 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:29,067]\u001b[0m Trial 44 finished with value: 0.8138866486891695 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:30,410]\u001b[0m Trial 45 finished with value: 0.8100658601387334 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:32,060]\u001b[0m Trial 46 finished with value: 0.8171233411162863 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 52}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:33,394]\u001b[0m Trial 47 finished with value: 0.805034416781886 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 77}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:35,078]\u001b[0m Trial 48 finished with value: 0.7904435936004798 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'metric': 'euclidean', 'leaf_size': 52}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:36,715]\u001b[0m Trial 49 finished with value: 0.8151133960759724 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 42}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 50.0\n",
      "\tBest value (f1_score): 0.8171\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 16\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 57\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "study_knn = optuna.create_study(direction='maximize', study_name=\"KNNClassifier\")\n",
    "func_knn_0 = lambda trial: objective_knn_CV(trial, X_trainSet0, Y_trainSet0, Y_trainSet0_class)\n",
    "study_knn.optimize(func_knn_0, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ac43f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:11:26.431063Z",
     "iopub.status.busy": "2023-01-15T15:11:26.430920Z",
     "iopub.status.idle": "2023-01-15T15:11:26.803281Z",
     "shell.execute_reply": "2023-01-15T15:11:26.802873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0\n",
      "0                    TP  321.000000\n",
      "1                    TN  174.000000\n",
      "2                    FP   50.000000\n",
      "3                    FN   50.000000\n",
      "4              Accuracy    0.831933\n",
      "5             Precision    0.865229\n",
      "6           Sensitivity    0.865229\n",
      "7           Specificity    0.776800\n",
      "8              F1 score    0.865229\n",
      "9   F1 score (weighted)    0.831933\n",
      "10     F1 score (macro)    0.821007\n",
      "11    Balanced Accuracy    0.821007\n",
      "12                  MCC    0.642015\n",
      "13                  NPV    0.776800\n",
      "14              ROC_AUC    0.821007\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_0 = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_0.fit(X_trainSet0,Y_trainSet0, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_0 = optimized_knn_0.predict(X_testSet0)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet0, y_pred_knn_0)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet0, y_pred_knn_0)\n",
    "Precision = precision_score(Y_testSet0, y_pred_knn_0)\n",
    "Sensitivity = recall_score(Y_testSet0, y_pred_knn_0)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet0, y_pred_knn_0)      \n",
    "f1_scores_W = f1_score(Y_testSet0, y_pred_knn_0, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet0, y_pred_knn_0, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet0, y_pred_knn_0)\n",
    "MCC = matthews_corrcoef(Y_testSet0, y_pred_knn_0)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet0, y_pred_knn_0)\n",
    "    \n",
    "\n",
    "mat_met_knn_test = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Set0':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })    \n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "13d758f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:11:26.805146Z",
     "iopub.status.busy": "2023-01-15T15:11:26.804892Z",
     "iopub.status.idle": "2023-01-15T15:12:58.753626Z",
     "shell.execute_reply": "2023-01-15T15:12:58.753252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:19:38,950]\u001b[0m Trial 50 finished with value: 0.8129330522661855 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 27}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:40,561]\u001b[0m Trial 51 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:42,190]\u001b[0m Trial 52 finished with value: 0.8059709099249159 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 49}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:43,813]\u001b[0m Trial 53 finished with value: 0.8060953920008934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:45,476]\u001b[0m Trial 54 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:47,134]\u001b[0m Trial 55 finished with value: 0.7983660751451345 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 66}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:48,765]\u001b[0m Trial 56 finished with value: 0.8112581152540729 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:50,407]\u001b[0m Trial 57 finished with value: 0.8008414826751684 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:52,017]\u001b[0m Trial 58 finished with value: 0.8036479963268812 and parameters: {'n_neighbors': 29, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 46}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:53,650]\u001b[0m Trial 59 finished with value: 0.8019939186550719 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 37}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:55,288]\u001b[0m Trial 60 finished with value: 0.811568541389071 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 52}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:56,941]\u001b[0m Trial 61 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:58,311]\u001b[0m Trial 62 finished with value: 0.8073897386678249 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:19:59,997]\u001b[0m Trial 63 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:01,383]\u001b[0m Trial 64 finished with value: 0.8062347327833583 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:03,079]\u001b[0m Trial 65 finished with value: 0.8008414826751684 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:04,627]\u001b[0m Trial 66 finished with value: 0.8112581152540729 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:06,340]\u001b[0m Trial 67 finished with value: 0.776276326346647 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'minkowski', 'leaf_size': 59}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:08,032]\u001b[0m Trial 68 finished with value: 0.815074843243986 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 50}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:09,444]\u001b[0m Trial 69 finished with value: 0.810451372244481 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 95}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:11,136]\u001b[0m Trial 70 finished with value: 0.8059709099249159 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 45}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:12,806]\u001b[0m Trial 71 finished with value: 0.815074843243986 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:14,473]\u001b[0m Trial 72 finished with value: 0.8060953920008934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:15,829]\u001b[0m Trial 73 finished with value: 0.810451372244481 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:17,437]\u001b[0m Trial 74 finished with value: 0.8059709099249159 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:19,110]\u001b[0m Trial 75 finished with value: 0.8143032567040729 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:20,471]\u001b[0m Trial 76 finished with value: 0.7901605476152633 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:22,134]\u001b[0m Trial 77 finished with value: 0.7923117978473312 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 57}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:23,785]\u001b[0m Trial 78 finished with value: 0.802445638340522 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 63}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:25,448]\u001b[0m Trial 79 finished with value: 0.8075811742877109 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 51}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:27,095]\u001b[0m Trial 80 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 48}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:28,438]\u001b[0m Trial 81 finished with value: 0.8029432706979345 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 82}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:29,756]\u001b[0m Trial 82 finished with value: 0.8073897386678249 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 98}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:31,086]\u001b[0m Trial 83 finished with value: 0.8159448146399277 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 81}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:32,739]\u001b[0m Trial 84 finished with value: 0.809705509532791 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:20:34,070]\u001b[0m Trial 85 finished with value: 0.8062347327833583 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 92}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:35,733]\u001b[0m Trial 86 finished with value: 0.8055793448363275 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:37,121]\u001b[0m Trial 87 finished with value: 0.780693304580163 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:38,457]\u001b[0m Trial 88 finished with value: 0.810451372244481 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:40,516]\u001b[0m Trial 89 finished with value: 0.7925506766176074 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 20}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:42,177]\u001b[0m Trial 90 finished with value: 0.815074843243986 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 53}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:43,446]\u001b[0m Trial 91 finished with value: 0.8159448146399277 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 91}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:44,770]\u001b[0m Trial 92 finished with value: 0.8073897386678249 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 85}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:46,092]\u001b[0m Trial 93 finished with value: 0.8062347327833583 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 82}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:47,741]\u001b[0m Trial 94 finished with value: 0.8080947426939386 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:49,097]\u001b[0m Trial 95 finished with value: 0.8035923850022744 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 90}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:50,453]\u001b[0m Trial 96 finished with value: 0.810451372244481 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 82}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:51,861]\u001b[0m Trial 97 finished with value: 0.8062347327833583 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 100}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:53,219]\u001b[0m Trial 98 finished with value: 0.8159448146399277 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 95}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:54,596]\u001b[0m Trial 99 finished with value: 0.8029432706979345 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 93}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 100.0\n",
      "\tBest value (f1_score): 0.8171\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 16\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 57\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_1 = lambda trial: objective_knn_CV(trial, X_trainSet1, Y_trainSet1, Y_trainSet1_class)\n",
    "study_knn.optimize(func_knn_1, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1d7f3971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:12:58.755697Z",
     "iopub.status.busy": "2023-01-15T15:12:58.755377Z",
     "iopub.status.idle": "2023-01-15T15:12:59.138625Z",
     "shell.execute_reply": "2023-01-15T15:12:59.138223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1\n",
      "0                    TP  321.000000  337.000000\n",
      "1                    TN  174.000000  161.000000\n",
      "2                    FP   50.000000   73.000000\n",
      "3                    FN   50.000000   24.000000\n",
      "4              Accuracy    0.831933    0.836975\n",
      "5             Precision    0.865229    0.821951\n",
      "6           Sensitivity    0.865229    0.933518\n",
      "7           Specificity    0.776800    0.688000\n",
      "8              F1 score    0.865229    0.874189\n",
      "9   F1 score (weighted)    0.831933    0.832623\n",
      "10     F1 score (macro)    0.821007    0.821343\n",
      "11    Balanced Accuracy    0.821007    0.810776\n",
      "12                  MCC    0.642015    0.655936\n",
      "13                  NPV    0.776800    0.870300\n",
      "14              ROC_AUC    0.821007    0.810776\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_1 =  KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_1.fit(X_trainSet1,Y_trainSet1, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_1 = optimized_knn_1.predict(X_testSet1)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet1, y_pred_knn_1)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet1, y_pred_knn_1)\n",
    "Precision = precision_score(Y_testSet1, y_pred_knn_1)\n",
    "Sensitivity = recall_score(Y_testSet1, y_pred_knn_1)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet1, y_pred_knn_1)      \n",
    "f1_scores_W = f1_score(Y_testSet1, y_pred_knn_1, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet1, y_pred_knn_1, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet1, y_pred_knn_1)\n",
    "MCC = matthews_corrcoef(Y_testSet1, y_pred_knn_1)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet1, y_pred_knn_1)\n",
    "    \n",
    "\n",
    "set1 = pd.DataFrame({'Set1':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set1'] = set1\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "92d3e174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:12:59.140671Z",
     "iopub.status.busy": "2023-01-15T15:12:59.140332Z",
     "iopub.status.idle": "2023-01-15T15:14:27.323419Z",
     "shell.execute_reply": "2023-01-15T15:14:27.323065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:20:56,323]\u001b[0m Trial 100 finished with value: 0.7921481097919947 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:57,563]\u001b[0m Trial 101 finished with value: 0.8166006433295848 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 79}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:20:58,816]\u001b[0m Trial 102 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 88}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:00,076]\u001b[0m Trial 103 finished with value: 0.8109633582551112 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 87}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:01,339]\u001b[0m Trial 104 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 88}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:02,653]\u001b[0m Trial 105 finished with value: 0.8160706189122277 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 89}. Best is trial 5 with value: 0.8171233411162863.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:04,148]\u001b[0m Trial 106 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:05,667]\u001b[0m Trial 107 finished with value: 0.8140053528468398 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:07,165]\u001b[0m Trial 108 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:08,567]\u001b[0m Trial 109 finished with value: 0.8147725993394241 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:09,849]\u001b[0m Trial 110 finished with value: 0.8113267476440711 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 71}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:11,344]\u001b[0m Trial 111 finished with value: 0.8116086264298868 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:12,862]\u001b[0m Trial 112 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:14,324]\u001b[0m Trial 113 finished with value: 0.8162208025613085 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:15,810]\u001b[0m Trial 114 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:17,266]\u001b[0m Trial 115 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:18,754]\u001b[0m Trial 116 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:20,270]\u001b[0m Trial 117 finished with value: 0.8132341961892184 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:21,714]\u001b[0m Trial 118 finished with value: 0.8111301471792493 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 66}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:23,192]\u001b[0m Trial 119 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:24,673]\u001b[0m Trial 120 finished with value: 0.8153731158832003 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:26,197]\u001b[0m Trial 121 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:27,691]\u001b[0m Trial 122 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:29,145]\u001b[0m Trial 123 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:30,455]\u001b[0m Trial 124 finished with value: 0.8109633582551112 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:31,961]\u001b[0m Trial 125 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:33,416]\u001b[0m Trial 126 finished with value: 0.8153731158832003 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:34,849]\u001b[0m Trial 127 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:36,311]\u001b[0m Trial 128 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 106 with value: 0.8204888458939147.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:37,570]\u001b[0m Trial 129 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:38,843]\u001b[0m Trial 130 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:40,144]\u001b[0m Trial 131 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:41,758]\u001b[0m Trial 132 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:43,102]\u001b[0m Trial 133 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:44,486]\u001b[0m Trial 134 finished with value: 0.8160706189122277 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:21:45,858]\u001b[0m Trial 135 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:47,136]\u001b[0m Trial 136 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:48,492]\u001b[0m Trial 137 finished with value: 0.7945163590385306 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:49,817]\u001b[0m Trial 138 finished with value: 0.8160706189122277 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:51,186]\u001b[0m Trial 139 finished with value: 0.8089370286675411 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:52,563]\u001b[0m Trial 140 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:54,240]\u001b[0m Trial 141 finished with value: 0.8204888458939147 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:55,604]\u001b[0m Trial 142 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:56,978]\u001b[0m Trial 143 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:58,288]\u001b[0m Trial 144 finished with value: 0.8136863293505023 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:21:59,652]\u001b[0m Trial 145 finished with value: 0.8162156389882071 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:00,994]\u001b[0m Trial 146 finished with value: 0.8212919235819719 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:02,385]\u001b[0m Trial 147 finished with value: 0.8136863293505023 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:03,736]\u001b[0m Trial 148 finished with value: 0.8143531408531415 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:05,122]\u001b[0m Trial 149 finished with value: 0.8136863293505023 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 150.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_2 = lambda trial: objective_knn_CV(trial, X_trainSet2, Y_trainSet2, Y_trainSet2_class)\n",
    "study_knn.optimize(func_knn_2, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "455b4e3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:14:27.325034Z",
     "iopub.status.busy": "2023-01-15T15:14:27.324908Z",
     "iopub.status.idle": "2023-01-15T15:14:27.698306Z",
     "shell.execute_reply": "2023-01-15T15:14:27.697935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2\n",
      "0                    TP  321.000000  337.000000  324.000000\n",
      "1                    TN  174.000000  161.000000  167.000000\n",
      "2                    FP   50.000000   73.000000   57.000000\n",
      "3                    FN   50.000000   24.000000   47.000000\n",
      "4              Accuracy    0.831933    0.836975    0.825210\n",
      "5             Precision    0.865229    0.821951    0.850394\n",
      "6           Sensitivity    0.865229    0.933518    0.873315\n",
      "7           Specificity    0.776800    0.688000    0.745500\n",
      "8              F1 score    0.865229    0.874189    0.861702\n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377\n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130\n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426\n",
      "12                  MCC    0.642015    0.655936    0.624781\n",
      "13                  NPV    0.776800    0.870300    0.780400\n",
      "14              ROC_AUC    0.821007    0.810776    0.809426\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_2 = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_2.fit(X_trainSet2,Y_trainSet2, )\n",
    "#predict\n",
    "y_pred_knn_2 = optimized_knn_2.predict(X_testSet2)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet2, y_pred_knn_2)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet2, y_pred_knn_2)\n",
    "Precision = precision_score(Y_testSet2, y_pred_knn_2)\n",
    "Sensitivity = recall_score(Y_testSet2, y_pred_knn_2)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet2, y_pred_knn_2)      \n",
    "f1_scores_W = f1_score(Y_testSet2, y_pred_knn_2, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet2, y_pred_knn_2, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet2, y_pred_knn_2)\n",
    "MCC = matthews_corrcoef(Y_testSet2, y_pred_knn_2)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet2, y_pred_knn_2)\n",
    "    \n",
    "\n",
    "Set2 = pd.DataFrame({'Set2':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set2'] = Set2\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5425d357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:14:27.700019Z",
     "iopub.status.busy": "2023-01-15T15:14:27.699873Z",
     "iopub.status.idle": "2023-01-15T15:15:58.079305Z",
     "shell.execute_reply": "2023-01-15T15:15:58.078797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:22:06,690]\u001b[0m Trial 150 finished with value: 0.8043047559617935 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:08,167]\u001b[0m Trial 151 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:09,394]\u001b[0m Trial 152 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:10,667]\u001b[0m Trial 153 finished with value: 0.8103042933652679 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:12,131]\u001b[0m Trial 154 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:13,583]\u001b[0m Trial 155 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:14,880]\u001b[0m Trial 156 finished with value: 0.8084308609509261 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 79}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:16,166]\u001b[0m Trial 157 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:17,490]\u001b[0m Trial 158 finished with value: 0.8057042398944695 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:19,028]\u001b[0m Trial 159 finished with value: 0.7932746606778378 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:20,240]\u001b[0m Trial 160 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:21,452]\u001b[0m Trial 161 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:22,959]\u001b[0m Trial 162 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:24,461]\u001b[0m Trial 163 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:25,939]\u001b[0m Trial 164 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:27,271]\u001b[0m Trial 165 finished with value: 0.8057042398944695 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:28,740]\u001b[0m Trial 166 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:30,032]\u001b[0m Trial 167 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:31,481]\u001b[0m Trial 168 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:32,710]\u001b[0m Trial 169 finished with value: 0.8057042398944695 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:34,005]\u001b[0m Trial 170 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:35,478]\u001b[0m Trial 171 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:36,921]\u001b[0m Trial 172 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:38,378]\u001b[0m Trial 173 finished with value: 0.8077800630535575 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:39,849]\u001b[0m Trial 174 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:41,293]\u001b[0m Trial 175 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:42,559]\u001b[0m Trial 176 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:43,985]\u001b[0m Trial 177 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:45,474]\u001b[0m Trial 178 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:46,971]\u001b[0m Trial 179 finished with value: 0.8056182134658256 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:48,257]\u001b[0m Trial 180 finished with value: 0.8004798719813394 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:49,728]\u001b[0m Trial 181 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:51,210]\u001b[0m Trial 182 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:52,481]\u001b[0m Trial 183 finished with value: 0.8057042398944695 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:22:53,940]\u001b[0m Trial 184 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:55,145]\u001b[0m Trial 185 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:56,615]\u001b[0m Trial 186 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:58,122]\u001b[0m Trial 187 finished with value: 0.8097292606103348 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:22:59,640]\u001b[0m Trial 188 finished with value: 0.7912196304796998 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:00,945]\u001b[0m Trial 189 finished with value: 0.8103042933652679 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:02,244]\u001b[0m Trial 190 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:03,538]\u001b[0m Trial 191 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:05,029]\u001b[0m Trial 192 finished with value: 0.8074086271873682 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:06,435]\u001b[0m Trial 193 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:07,924]\u001b[0m Trial 194 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:09,163]\u001b[0m Trial 195 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:10,630]\u001b[0m Trial 196 finished with value: 0.8068203088213934 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:12,087]\u001b[0m Trial 197 finished with value: 0.8082608126472846 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:13,435]\u001b[0m Trial 198 finished with value: 0.8080017699962475 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:14,957]\u001b[0m Trial 199 finished with value: 0.8085762831284559 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 200.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_3 = lambda trial: objective_knn_CV(trial, X_trainSet3, Y_trainSet3, Y_trainSet3_class)\n",
    "study_knn.optimize(func_knn_3, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0558b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:15:58.081262Z",
     "iopub.status.busy": "2023-01-15T15:15:58.081103Z",
     "iopub.status.idle": "2023-01-15T15:15:58.446850Z",
     "shell.execute_reply": "2023-01-15T15:15:58.446356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000\n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000\n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000\n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000\n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017\n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143\n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396\n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600\n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285\n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520\n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793\n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501\n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358\n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800\n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_3 = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_3.fit(X_trainSet3,Y_trainSet3, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_3 = optimized_knn_3.predict(X_testSet3)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet3, y_pred_knn_3)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet3, y_pred_knn_3)\n",
    "Precision = precision_score(Y_testSet3, y_pred_knn_3)\n",
    "Sensitivity = recall_score(Y_testSet3, y_pred_knn_3)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet3, y_pred_knn_3)      \n",
    "f1_scores_W = f1_score(Y_testSet3, y_pred_knn_3, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet3, y_pred_knn_3, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet3, y_pred_knn_3)\n",
    "MCC = matthews_corrcoef(Y_testSet3, y_pred_knn_3)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet3, y_pred_knn_3)\n",
    "    \n",
    "\n",
    "Set3 = pd.DataFrame({'Set3':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set3'] = Set3\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "353f5dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:15:58.448693Z",
     "iopub.status.busy": "2023-01-15T15:15:58.448527Z",
     "iopub.status.idle": "2023-01-15T15:17:29.909685Z",
     "shell.execute_reply": "2023-01-15T15:17:29.909315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:23:16,845]\u001b[0m Trial 200 finished with value: 0.8135433485447774 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:18,461]\u001b[0m Trial 201 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:20,095]\u001b[0m Trial 202 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:21,427]\u001b[0m Trial 203 finished with value: 0.816642359997358 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:23,086]\u001b[0m Trial 204 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:24,450]\u001b[0m Trial 205 finished with value: 0.8162663104534641 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:25,814]\u001b[0m Trial 206 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:27,489]\u001b[0m Trial 207 finished with value: 0.8158522426509149 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:29,060]\u001b[0m Trial 208 finished with value: 0.8135433485447774 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:30,723]\u001b[0m Trial 209 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:32,112]\u001b[0m Trial 210 finished with value: 0.8114171318048691 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:33,764]\u001b[0m Trial 211 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:35,117]\u001b[0m Trial 212 finished with value: 0.816642359997358 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:36,465]\u001b[0m Trial 213 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:38,116]\u001b[0m Trial 214 finished with value: 0.8135433485447774 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:39,658]\u001b[0m Trial 215 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:41,025]\u001b[0m Trial 216 finished with value: 0.8129589598103184 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:42,711]\u001b[0m Trial 217 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:44,403]\u001b[0m Trial 218 finished with value: 0.8178096354359129 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:46,087]\u001b[0m Trial 219 finished with value: 0.8153712808809613 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:47,785]\u001b[0m Trial 220 finished with value: 0.795255541443284 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:49,067]\u001b[0m Trial 221 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:50,701]\u001b[0m Trial 222 finished with value: 0.8158522426509149 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:52,378]\u001b[0m Trial 223 finished with value: 0.8135433485447774 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:53,914]\u001b[0m Trial 224 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:55,380]\u001b[0m Trial 225 finished with value: 0.8158522426509149 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:56,658]\u001b[0m Trial 226 finished with value: 0.8193022098753154 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:57,860]\u001b[0m Trial 227 finished with value: 0.8162663104534641 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:23:59,605]\u001b[0m Trial 228 finished with value: 0.8166969160061974 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 23}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:00,889]\u001b[0m Trial 229 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:02,151]\u001b[0m Trial 230 finished with value: 0.816642359997358 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:03,407]\u001b[0m Trial 231 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:04,692]\u001b[0m Trial 232 finished with value: 0.8193022098753154 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:05,983]\u001b[0m Trial 233 finished with value: 0.8162663104534641 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:07,189]\u001b[0m Trial 234 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:24:08,394]\u001b[0m Trial 235 finished with value: 0.8193022098753154 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:09,679]\u001b[0m Trial 236 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:11,000]\u001b[0m Trial 237 finished with value: 0.816642359997358 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 79}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:12,268]\u001b[0m Trial 238 finished with value: 0.8162663104534641 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:13,553]\u001b[0m Trial 239 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:14,829]\u001b[0m Trial 240 finished with value: 0.8162663104534641 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:16,078]\u001b[0m Trial 241 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:17,575]\u001b[0m Trial 242 finished with value: 0.8178096354359129 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:18,833]\u001b[0m Trial 243 finished with value: 0.8175867993033625 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:20,144]\u001b[0m Trial 244 finished with value: 0.8193022098753154 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:21,464]\u001b[0m Trial 245 finished with value: 0.8193022098753154 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:22,948]\u001b[0m Trial 246 finished with value: 0.8135433485447774 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:24,213]\u001b[0m Trial 247 finished with value: 0.816642359997358 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:25,662]\u001b[0m Trial 248 finished with value: 0.8158522426509149 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:27,156]\u001b[0m Trial 249 finished with value: 0.8165986144259303 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 250.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_4 = lambda trial: objective_knn_CV(trial, X_trainSet4, Y_trainSet4, Y_trainSet4_class)\n",
    "study_knn.optimize(func_knn_4, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09d47487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:17:29.911604Z",
     "iopub.status.busy": "2023-01-15T15:17:29.911324Z",
     "iopub.status.idle": "2023-01-15T15:17:30.234900Z",
     "shell.execute_reply": "2023-01-15T15:17:30.234517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4  \n",
      "0   339.000000  \n",
      "1   164.000000  \n",
      "2    61.000000  \n",
      "3    31.000000  \n",
      "4     0.845378  \n",
      "5     0.847500  \n",
      "6     0.916216  \n",
      "7     0.728900  \n",
      "8     0.880519  \n",
      "9     0.842868  \n",
      "10    0.830736  \n",
      "11    0.822553  \n",
      "12    0.666462  \n",
      "13    0.841000  \n",
      "14    0.822553  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_4 =  KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_4.fit(X_trainSet4,Y_trainSet4, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_4 = optimized_knn_4.predict(X_testSet4)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet4, y_pred_knn_4)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet4, y_pred_knn_4)\n",
    "Precision = precision_score(Y_testSet4, y_pred_knn_4)\n",
    "Sensitivity = recall_score(Y_testSet4, y_pred_knn_4)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet4, y_pred_knn_4)      \n",
    "f1_scores_W = f1_score(Y_testSet4, y_pred_knn_4, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet4, y_pred_knn_4, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet4, y_pred_knn_4)\n",
    "MCC = matthews_corrcoef(Y_testSet4, y_pred_knn_4)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet4, y_pred_knn_4)\n",
    "    \n",
    "\n",
    "Set4 = pd.DataFrame({'Set4':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set4'] = Set4\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6089e60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:17:30.236566Z",
     "iopub.status.busy": "2023-01-15T15:17:30.236433Z",
     "iopub.status.idle": "2023-01-15T15:19:01.220930Z",
     "shell.execute_reply": "2023-01-15T15:19:01.220521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:24:28,736]\u001b[0m Trial 250 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:30,269]\u001b[0m Trial 251 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:31,845]\u001b[0m Trial 252 finished with value: 0.8028189712486684 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:33,147]\u001b[0m Trial 253 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:34,462]\u001b[0m Trial 254 finished with value: 0.7955249691221893 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:35,793]\u001b[0m Trial 255 finished with value: 0.8005411718054208 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 78}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:37,125]\u001b[0m Trial 256 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:38,790]\u001b[0m Trial 257 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:40,480]\u001b[0m Trial 258 finished with value: 0.8045630691131915 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:41,846]\u001b[0m Trial 259 finished with value: 0.7999996182842586 and parameters: {'n_neighbors': 23, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:43,446]\u001b[0m Trial 260 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:45,066]\u001b[0m Trial 261 finished with value: 0.8083305012319775 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:46,387]\u001b[0m Trial 262 finished with value: 0.8033174051528278 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:47,726]\u001b[0m Trial 263 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:49,090]\u001b[0m Trial 264 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:50,447]\u001b[0m Trial 265 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:52,088]\u001b[0m Trial 266 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:53,667]\u001b[0m Trial 267 finished with value: 0.8003039794740374 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:55,309]\u001b[0m Trial 268 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:56,694]\u001b[0m Trial 269 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:58,368]\u001b[0m Trial 270 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:24:59,779]\u001b[0m Trial 271 finished with value: 0.790989481096681 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:01,116]\u001b[0m Trial 272 finished with value: 0.8004761697713342 and parameters: {'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:02,544]\u001b[0m Trial 273 finished with value: 0.797917522808283 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:04,211]\u001b[0m Trial 274 finished with value: 0.7928640726390727 and parameters: {'n_neighbors': 29, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:05,560]\u001b[0m Trial 275 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:06,910]\u001b[0m Trial 276 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:08,582]\u001b[0m Trial 277 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:10,235]\u001b[0m Trial 278 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:11,557]\u001b[0m Trial 279 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:13,223]\u001b[0m Trial 280 finished with value: 0.8083305012319775 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:14,877]\u001b[0m Trial 281 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 53}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:16,552]\u001b[0m Trial 282 finished with value: 0.8045630691131915 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:18,216]\u001b[0m Trial 283 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:20,290]\u001b[0m Trial 284 finished with value: 0.8003798167977898 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 30}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:25:21,934]\u001b[0m Trial 285 finished with value: 0.8083305012319775 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:23,236]\u001b[0m Trial 286 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:24,920]\u001b[0m Trial 287 finished with value: 0.8030834544589004 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:26,308]\u001b[0m Trial 288 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:27,971]\u001b[0m Trial 289 finished with value: 0.8049594506204212 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:29,331]\u001b[0m Trial 290 finished with value: 0.8033174051528278 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:31,009]\u001b[0m Trial 291 finished with value: 0.7925681970962194 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:32,664]\u001b[0m Trial 292 finished with value: 0.8083305012319775 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:33,998]\u001b[0m Trial 293 finished with value: 0.8035427650301156 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:35,367]\u001b[0m Trial 294 finished with value: 0.8033174051528278 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:36,745]\u001b[0m Trial 295 finished with value: 0.805727893864782 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:38,404]\u001b[0m Trial 296 finished with value: 0.8028189712486684 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:40,059]\u001b[0m Trial 297 finished with value: 0.8003039794740374 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:41,713]\u001b[0m Trial 298 finished with value: 0.8028189712486684 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:43,371]\u001b[0m Trial 299 finished with value: 0.8045630691131915 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 300.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_5 = lambda trial: objective_knn_CV(trial, X_trainSet5, Y_trainSet5, Y_trainSet5_class)\n",
    "study_knn.optimize(func_knn_5, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29b6d99b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:19:01.222711Z",
     "iopub.status.busy": "2023-01-15T15:19:01.222579Z",
     "iopub.status.idle": "2023-01-15T15:19:01.624381Z",
     "shell.execute_reply": "2023-01-15T15:19:01.623976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4        Set5  \n",
      "0   339.000000  330.000000  \n",
      "1   164.000000  161.000000  \n",
      "2    61.000000   64.000000  \n",
      "3    31.000000   40.000000  \n",
      "4     0.845378    0.825210  \n",
      "5     0.847500    0.837563  \n",
      "6     0.916216    0.891892  \n",
      "7     0.728900    0.715600  \n",
      "8     0.880519    0.863874  \n",
      "9     0.842868    0.823032  \n",
      "10    0.830736    0.809871  \n",
      "11    0.822553    0.803724  \n",
      "12    0.666462    0.622809  \n",
      "13    0.841000    0.801000  \n",
      "14    0.822553    0.803724  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_5 = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_5.fit(X_trainSet5,Y_trainSet5, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_5 = optimized_knn_5.predict(X_testSet5)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet5, y_pred_knn_5)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet5, y_pred_knn_5)\n",
    "Precision = precision_score(Y_testSet5, y_pred_knn_5)\n",
    "Sensitivity = recall_score(Y_testSet5, y_pred_knn_5)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet5, y_pred_knn_5)      \n",
    "f1_scores_W = f1_score(Y_testSet5, y_pred_knn_5, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet5, y_pred_knn_5, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet5, y_pred_knn_5)\n",
    "MCC = matthews_corrcoef(Y_testSet5, y_pred_knn_5)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet5, y_pred_knn_5)\n",
    "    \n",
    "\n",
    "Set5 = pd.DataFrame({'Set5':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set5'] = Set5\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "baa41e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:19:01.626157Z",
     "iopub.status.busy": "2023-01-15T15:19:01.625992Z",
     "iopub.status.idle": "2023-01-15T15:20:32.500245Z",
     "shell.execute_reply": "2023-01-15T15:20:32.499753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:25:45,007]\u001b[0m Trial 300 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:46,654]\u001b[0m Trial 301 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:48,035]\u001b[0m Trial 302 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:49,430]\u001b[0m Trial 303 finished with value: 0.8113374597003855 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:50,787]\u001b[0m Trial 304 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:52,165]\u001b[0m Trial 305 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:53,792]\u001b[0m Trial 306 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:55,114]\u001b[0m Trial 307 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:56,506]\u001b[0m Trial 308 finished with value: 0.8049222022318127 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:58,081]\u001b[0m Trial 309 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:25:59,780]\u001b[0m Trial 310 finished with value: 0.8003394987528643 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:01,444]\u001b[0m Trial 311 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:03,114]\u001b[0m Trial 312 finished with value: 0.8076784512331528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:04,482]\u001b[0m Trial 313 finished with value: 0.8113374597003855 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:05,831]\u001b[0m Trial 314 finished with value: 0.8076549996562395 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:07,190]\u001b[0m Trial 315 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:08,468]\u001b[0m Trial 316 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 79}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:10,099]\u001b[0m Trial 317 finished with value: 0.8103129259669022 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:11,743]\u001b[0m Trial 318 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:13,107]\u001b[0m Trial 319 finished with value: 0.798831394247671 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 78}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:14,787]\u001b[0m Trial 320 finished with value: 0.8054969775516951 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:16,471]\u001b[0m Trial 321 finished with value: 0.8076784512331528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:18,155]\u001b[0m Trial 322 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 40}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:19,817]\u001b[0m Trial 323 finished with value: 0.807798102849478 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:21,430]\u001b[0m Trial 324 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:22,794]\u001b[0m Trial 325 finished with value: 0.8085262506888578 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:24,477]\u001b[0m Trial 326 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:25,836]\u001b[0m Trial 327 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:27,212]\u001b[0m Trial 328 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:28,626]\u001b[0m Trial 329 finished with value: 0.800056704312477 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:30,024]\u001b[0m Trial 330 finished with value: 0.8054150232004357 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:31,383]\u001b[0m Trial 331 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:32,994]\u001b[0m Trial 332 finished with value: 0.8076784512331528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:34,634]\u001b[0m Trial 333 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:36,294]\u001b[0m Trial 334 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:26:37,965]\u001b[0m Trial 335 finished with value: 0.8076784512331528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:39,342]\u001b[0m Trial 336 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 74}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:40,727]\u001b[0m Trial 337 finished with value: 0.8049222022318127 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 76}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:42,381]\u001b[0m Trial 338 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:43,676]\u001b[0m Trial 339 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:45,007]\u001b[0m Trial 340 finished with value: 0.8006491519407406 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:46,333]\u001b[0m Trial 341 finished with value: 0.7997433983889468 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:47,970]\u001b[0m Trial 342 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:49,600]\u001b[0m Trial 343 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:50,935]\u001b[0m Trial 344 finished with value: 0.8063990760175981 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:52,614]\u001b[0m Trial 345 finished with value: 0.807900413236833 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:54,019]\u001b[0m Trial 346 finished with value: 0.8092790570387693 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:55,562]\u001b[0m Trial 347 finished with value: 0.8076784512331528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:56,941]\u001b[0m Trial 348 finished with value: 0.7807280039046118 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:26:58,471]\u001b[0m Trial 349 finished with value: 0.8108628346461204 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 350.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_6 = lambda trial: objective_knn_CV(trial, X_trainSet6, Y_trainSet6, Y_trainSet6_class)\n",
    "study_knn.optimize(func_knn_6, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1946b7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:20:32.502284Z",
     "iopub.status.busy": "2023-01-15T15:20:32.502023Z",
     "iopub.status.idle": "2023-01-15T15:20:32.856638Z",
     "shell.execute_reply": "2023-01-15T15:20:32.856140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4        Set5        Set6  \n",
      "0   339.000000  330.000000  333.000000  \n",
      "1   164.000000  161.000000  174.000000  \n",
      "2    61.000000   64.000000   58.000000  \n",
      "3    31.000000   40.000000   30.000000  \n",
      "4     0.845378    0.825210    0.852101  \n",
      "5     0.847500    0.837563    0.851662  \n",
      "6     0.916216    0.891892    0.917355  \n",
      "7     0.728900    0.715600    0.750000  \n",
      "8     0.880519    0.863874    0.883289  \n",
      "9     0.842868    0.823032    0.850098  \n",
      "10    0.830736    0.809871    0.840727  \n",
      "11    0.822553    0.803724    0.833678  \n",
      "12    0.666462    0.622809    0.685727  \n",
      "13    0.841000    0.801000    0.852900  \n",
      "14    0.822553    0.803724    0.833678  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_6 =  KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_6.fit(X_trainSet6,Y_trainSet6, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_6 = optimized_knn_6.predict(X_testSet6)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet6, y_pred_knn_6)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet6, y_pred_knn_6)\n",
    "Precision = precision_score(Y_testSet6, y_pred_knn_6)\n",
    "Sensitivity = recall_score(Y_testSet6, y_pred_knn_6)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet6, y_pred_knn_6)      \n",
    "f1_scores_W = f1_score(Y_testSet6, y_pred_knn_6, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet6, y_pred_knn_6, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet6, y_pred_knn_6)\n",
    "MCC = matthews_corrcoef(Y_testSet6, y_pred_knn_6)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet6, y_pred_knn_6)\n",
    "    \n",
    "\n",
    "Set6 = pd.DataFrame({'Set6':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set6'] = Set6\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "869b61ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:20:32.858595Z",
     "iopub.status.busy": "2023-01-15T15:20:32.858406Z",
     "iopub.status.idle": "2023-01-15T15:22:04.253174Z",
     "shell.execute_reply": "2023-01-15T15:22:04.252814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:27:00,255]\u001b[0m Trial 350 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:01,520]\u001b[0m Trial 351 finished with value: 0.8123117359982419 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:03,026]\u001b[0m Trial 352 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:04,370]\u001b[0m Trial 353 finished with value: 0.8161055219035485 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:05,628]\u001b[0m Trial 354 finished with value: 0.812427914707148 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:07,056]\u001b[0m Trial 355 finished with value: 0.8135219903170586 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:08,328]\u001b[0m Trial 356 finished with value: 0.8123117359982419 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:09,843]\u001b[0m Trial 357 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:11,156]\u001b[0m Trial 358 finished with value: 0.812427914707148 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 80}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:12,627]\u001b[0m Trial 359 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:14,107]\u001b[0m Trial 360 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:15,604]\u001b[0m Trial 361 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:17,086]\u001b[0m Trial 362 finished with value: 0.8081929535070952 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:18,339]\u001b[0m Trial 363 finished with value: 0.8204114763528221 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:19,595]\u001b[0m Trial 364 finished with value: 0.8089627192822058 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:20,850]\u001b[0m Trial 365 finished with value: 0.8123117359982419 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:22,308]\u001b[0m Trial 366 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:23,767]\u001b[0m Trial 367 finished with value: 0.8201889167991588 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:25,321]\u001b[0m Trial 368 finished with value: 0.7952733849344622 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:26,816]\u001b[0m Trial 369 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:28,337]\u001b[0m Trial 370 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:29,877]\u001b[0m Trial 371 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:31,329]\u001b[0m Trial 372 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:32,833]\u001b[0m Trial 373 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:34,277]\u001b[0m Trial 374 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:35,777]\u001b[0m Trial 375 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:37,305]\u001b[0m Trial 376 finished with value: 0.8201889167991588 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:38,781]\u001b[0m Trial 377 finished with value: 0.8135219903170586 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:40,248]\u001b[0m Trial 378 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:41,724]\u001b[0m Trial 379 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:43,178]\u001b[0m Trial 380 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:44,675]\u001b[0m Trial 381 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:46,139]\u001b[0m Trial 382 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:47,605]\u001b[0m Trial 383 finished with value: 0.8201889167991588 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:49,046]\u001b[0m Trial 384 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:27:50,502]\u001b[0m Trial 385 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:51,985]\u001b[0m Trial 386 finished with value: 0.8067872164444859 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:53,464]\u001b[0m Trial 387 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:54,978]\u001b[0m Trial 388 finished with value: 0.7969990751116269 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:56,429]\u001b[0m Trial 389 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:57,940]\u001b[0m Trial 390 finished with value: 0.8129604132126979 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:27:59,437]\u001b[0m Trial 391 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:00,911]\u001b[0m Trial 392 finished with value: 0.8134889405718972 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:02,413]\u001b[0m Trial 393 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 52}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:03,913]\u001b[0m Trial 394 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:05,371]\u001b[0m Trial 395 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:06,641]\u001b[0m Trial 396 finished with value: 0.8133321461971368 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:08,072]\u001b[0m Trial 397 finished with value: 0.8107484133028502 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:09,566]\u001b[0m Trial 398 finished with value: 0.8161067947700813 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:11,061]\u001b[0m Trial 399 finished with value: 0.8109174981768161 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 400.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_7 = lambda trial: objective_knn_CV(trial, X_trainSet7, Y_trainSet7, Y_trainSet7_class)\n",
    "study_knn.optimize(func_knn_7, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40066dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:22:04.254974Z",
     "iopub.status.busy": "2023-01-15T15:22:04.254814Z",
     "iopub.status.idle": "2023-01-15T15:22:04.636470Z",
     "shell.execute_reply": "2023-01-15T15:22:04.636095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4        Set5        Set6        Set7  \n",
      "0   339.000000  330.000000  333.000000  338.000000  \n",
      "1   164.000000  161.000000  174.000000  162.000000  \n",
      "2    61.000000   64.000000   58.000000   59.000000  \n",
      "3    31.000000   40.000000   30.000000   36.000000  \n",
      "4     0.845378    0.825210    0.852101    0.840336  \n",
      "5     0.847500    0.837563    0.851662    0.851385  \n",
      "6     0.916216    0.891892    0.917355    0.903743  \n",
      "7     0.728900    0.715600    0.750000    0.733000  \n",
      "8     0.880519    0.863874    0.883289    0.876783  \n",
      "9     0.842868    0.823032    0.850098    0.838335  \n",
      "10    0.830736    0.809871    0.840727    0.825027  \n",
      "11    0.822553    0.803724    0.833678    0.818387  \n",
      "12    0.666462    0.622809    0.685727    0.652965  \n",
      "13    0.841000    0.801000    0.852900    0.818200  \n",
      "14    0.822553    0.803724    0.833678    0.818387  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_7 =  KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_7.fit(X_trainSet7,Y_trainSet7, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_7 = optimized_knn_7.predict(X_testSet7)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet7, y_pred_knn_7)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet7, y_pred_knn_7)\n",
    "Precision = precision_score(Y_testSet7, y_pred_knn_7)\n",
    "Sensitivity = recall_score(Y_testSet7, y_pred_knn_7)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet7, y_pred_knn_7)      \n",
    "f1_scores_W = f1_score(Y_testSet7, y_pred_knn_7, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet7, y_pred_knn_7, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet7, y_pred_knn_7)\n",
    "MCC = matthews_corrcoef(Y_testSet7, y_pred_knn_7)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet7, y_pred_knn_7)\n",
    "    \n",
    "\n",
    "Set7 = pd.DataFrame({'Set7':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set7'] = Set7\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18e519f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:22:04.638166Z",
     "iopub.status.busy": "2023-01-15T15:22:04.638040Z",
     "iopub.status.idle": "2023-01-15T15:23:36.973253Z",
     "shell.execute_reply": "2023-01-15T15:23:36.972785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:28:12,669]\u001b[0m Trial 400 finished with value: 0.8101595096060914 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:14,048]\u001b[0m Trial 401 finished with value: 0.8063114248016742 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:15,733]\u001b[0m Trial 402 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:17,415]\u001b[0m Trial 403 finished with value: 0.8081064259189088 and parameters: {'n_neighbors': 25, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:19,052]\u001b[0m Trial 404 finished with value: 0.8157906467193333 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:20,614]\u001b[0m Trial 405 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:22,280]\u001b[0m Trial 406 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:23,988]\u001b[0m Trial 407 finished with value: 0.7976596669436988 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:25,647]\u001b[0m Trial 408 finished with value: 0.8015809511226673 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:26,890]\u001b[0m Trial 409 finished with value: 0.8056955466431528 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:28,253]\u001b[0m Trial 410 finished with value: 0.8126492558825653 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:29,924]\u001b[0m Trial 411 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:31,538]\u001b[0m Trial 412 finished with value: 0.8106987910345864 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:33,147]\u001b[0m Trial 413 finished with value: 0.8076906477043762 and parameters: {'n_neighbors': 28, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:34,773]\u001b[0m Trial 414 finished with value: 0.8095454201878731 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:36,402]\u001b[0m Trial 415 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:38,033]\u001b[0m Trial 416 finished with value: 0.8063858065362846 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:39,374]\u001b[0m Trial 417 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:41,001]\u001b[0m Trial 418 finished with value: 0.8157906467193333 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:42,351]\u001b[0m Trial 419 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:43,967]\u001b[0m Trial 420 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:45,619]\u001b[0m Trial 421 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:46,945]\u001b[0m Trial 422 finished with value: 0.8149159124218122 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:48,629]\u001b[0m Trial 423 finished with value: 0.8157906467193333 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:50,314]\u001b[0m Trial 424 finished with value: 0.8063858065362846 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:51,743]\u001b[0m Trial 425 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:53,458]\u001b[0m Trial 426 finished with value: 0.7940127038558533 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:54,859]\u001b[0m Trial 427 finished with value: 0.8101595096060914 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:56,457]\u001b[0m Trial 428 finished with value: 0.8078765503210319 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:28:58,138]\u001b[0m Trial 429 finished with value: 0.8015809511226673 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:00,229]\u001b[0m Trial 430 finished with value: 0.8163719603001368 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 32}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:01,590]\u001b[0m Trial 431 finished with value: 0.8090654131617147 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:02,952]\u001b[0m Trial 432 finished with value: 0.8093698191470533 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:04,621]\u001b[0m Trial 433 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:06,308]\u001b[0m Trial 434 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:29:07,853]\u001b[0m Trial 435 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 53}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:09,392]\u001b[0m Trial 436 finished with value: 0.8157906467193333 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 56}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:10,773]\u001b[0m Trial 437 finished with value: 0.8091400245181648 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:12,445]\u001b[0m Trial 438 finished with value: 0.8063858065362846 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:14,113]\u001b[0m Trial 439 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:15,785]\u001b[0m Trial 440 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:17,149]\u001b[0m Trial 441 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 84}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:18,815]\u001b[0m Trial 442 finished with value: 0.8157906467193333 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:20,186]\u001b[0m Trial 443 finished with value: 0.8101595096060914 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:21,479]\u001b[0m Trial 444 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 72}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:23,213]\u001b[0m Trial 445 finished with value: 0.7967618575711952 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:24,564]\u001b[0m Trial 446 finished with value: 0.8108551657800376 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:26,234]\u001b[0m Trial 447 finished with value: 0.8122691048737236 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:27,595]\u001b[0m Trial 448 finished with value: 0.8149159124218122 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:29,269]\u001b[0m Trial 449 finished with value: 0.8081773162185927 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 450.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_8 = lambda trial: objective_knn_CV(trial, X_trainSet8, Y_trainSet8, Y_trainSet8_class)\n",
    "study_knn.optimize(func_knn_8, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc63e372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:23:36.974902Z",
     "iopub.status.busy": "2023-01-15T15:23:36.974772Z",
     "iopub.status.idle": "2023-01-15T15:23:37.299525Z",
     "shell.execute_reply": "2023-01-15T15:23:37.299048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8  \n",
      "0   339.000000  330.000000  333.000000  338.000000  331.000000  \n",
      "1   164.000000  161.000000  174.000000  162.000000  150.000000  \n",
      "2    61.000000   64.000000   58.000000   59.000000   77.000000  \n",
      "3    31.000000   40.000000   30.000000   36.000000   37.000000  \n",
      "4     0.845378    0.825210    0.852101    0.840336    0.808403  \n",
      "5     0.847500    0.837563    0.851662    0.851385    0.811275  \n",
      "6     0.916216    0.891892    0.917355    0.903743    0.899457  \n",
      "7     0.728900    0.715600    0.750000    0.733000    0.660800  \n",
      "8     0.880519    0.863874    0.883289    0.876783    0.853093  \n",
      "9     0.842868    0.823032    0.850098    0.838335    0.804086  \n",
      "10    0.830736    0.809871    0.840727    0.825027    0.788865  \n",
      "11    0.822553    0.803724    0.833678    0.818387    0.780125  \n",
      "12    0.666462    0.622809    0.685727    0.652965    0.586229  \n",
      "13    0.841000    0.801000    0.852900    0.818200    0.802100  \n",
      "14    0.822553    0.803724    0.833678    0.818387    0.780125  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_8 =  KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_8.fit(X_trainSet8,Y_trainSet8, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_8 = optimized_knn_8.predict(X_testSet8)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet8, y_pred_knn_8)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet8, y_pred_knn_8)\n",
    "Precision = precision_score(Y_testSet8, y_pred_knn_8)\n",
    "Sensitivity = recall_score(Y_testSet8, y_pred_knn_8)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet8, y_pred_knn_8)      \n",
    "f1_scores_W = f1_score(Y_testSet8, y_pred_knn_8, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet8, y_pred_knn_8, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet8, y_pred_knn_8)\n",
    "MCC = matthews_corrcoef(Y_testSet8, y_pred_knn_8)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet8, y_pred_knn_8)\n",
    "    \n",
    "\n",
    "Set8 = pd.DataFrame({'Set8':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set8'] = Set8\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "70af445e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:23:37.301378Z",
     "iopub.status.busy": "2023-01-15T15:23:37.301251Z",
     "iopub.status.idle": "2023-01-15T15:25:06.253445Z",
     "shell.execute_reply": "2023-01-15T15:25:06.252993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:29:31,014]\u001b[0m Trial 450 finished with value: 0.8173649322635332 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:32,505]\u001b[0m Trial 451 finished with value: 0.8166409109897703 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:33,726]\u001b[0m Trial 452 finished with value: 0.8143202824453109 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:35,031]\u001b[0m Trial 453 finished with value: 0.812471544803223 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:36,515]\u001b[0m Trial 454 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:37,794]\u001b[0m Trial 455 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:39,289]\u001b[0m Trial 456 finished with value: 0.8134103399554415 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:40,742]\u001b[0m Trial 457 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:42,235]\u001b[0m Trial 458 finished with value: 0.81210619014842 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:43,695]\u001b[0m Trial 459 finished with value: 0.8144734807926708 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:44,957]\u001b[0m Trial 460 finished with value: 0.8141733168017039 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:46,356]\u001b[0m Trial 461 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:47,644]\u001b[0m Trial 462 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:49,146]\u001b[0m Trial 463 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:50,911]\u001b[0m Trial 464 finished with value: 0.7969888749610985 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 27}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:52,375]\u001b[0m Trial 465 finished with value: 0.8139097236978762 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:53,642]\u001b[0m Trial 466 finished with value: 0.8141733168017039 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:55,112]\u001b[0m Trial 467 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:56,613]\u001b[0m Trial 468 finished with value: 0.81210619014842 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 58}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:58,086]\u001b[0m Trial 469 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:29:59,525]\u001b[0m Trial 470 finished with value: 0.8134103399554415 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:00,993]\u001b[0m Trial 471 finished with value: 0.81210619014842 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:02,502]\u001b[0m Trial 472 finished with value: 0.8134103399554415 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 54}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:03,803]\u001b[0m Trial 473 finished with value: 0.812471544803223 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 69}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:05,078]\u001b[0m Trial 474 finished with value: 0.8189881812791798 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:06,393]\u001b[0m Trial 475 finished with value: 0.812471544803223 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 75}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:07,896]\u001b[0m Trial 476 finished with value: 0.8144734807926708 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:09,384]\u001b[0m Trial 477 finished with value: 0.81210619014842 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:10,630]\u001b[0m Trial 478 finished with value: 0.8141733168017039 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:11,855]\u001b[0m Trial 479 finished with value: 0.8184794223563895 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:13,335]\u001b[0m Trial 480 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 65}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:14,587]\u001b[0m Trial 481 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 71}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:16,073]\u001b[0m Trial 482 finished with value: 0.812529243032911 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:17,606]\u001b[0m Trial 483 finished with value: 0.8060023330761796 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'leaf_size': 59}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:18,878]\u001b[0m Trial 484 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:30:20,392]\u001b[0m Trial 485 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 50}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:21,890]\u001b[0m Trial 486 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 57}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:23,341]\u001b[0m Trial 487 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:24,627]\u001b[0m Trial 488 finished with value: 0.8141733168017039 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 68}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:25,934]\u001b[0m Trial 489 finished with value: 0.814437570919158 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 73}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:27,237]\u001b[0m Trial 490 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 77}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:28,849]\u001b[0m Trial 491 finished with value: 0.81210619014842 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 61}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:30,320]\u001b[0m Trial 492 finished with value: 0.8134103399554415 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 55}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:31,798]\u001b[0m Trial 493 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 62}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:33,313]\u001b[0m Trial 494 finished with value: 0.8166409109897703 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 66}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:34,785]\u001b[0m Trial 495 finished with value: 0.8131474241697152 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'leaf_size': 64}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:35,980]\u001b[0m Trial 496 finished with value: 0.8153318493976599 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 67}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:37,454]\u001b[0m Trial 497 finished with value: 0.8145537358410406 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'leaf_size': 60}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:38,903]\u001b[0m Trial 498 finished with value: 0.8190838771121683 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 63}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:30:40,162]\u001b[0m Trial 499 finished with value: 0.8131393681665126 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'leaf_size': 70}. Best is trial 129 with value: 0.8212919235819719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.8213\n",
      "\tBest params:\n",
      "\t\tn_neighbors: 13\n",
      "\t\tweights: distance\n",
      "\t\tmetric: manhattan\n",
      "\t\tleaf_size: 67\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "\n",
    "func_knn_9 = lambda trial: objective_knn_CV(trial, X_trainSet9, Y_trainSet9, Y_trainSet9_class)\n",
    "study_knn.optimize(func_knn_9, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_knn.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_knn.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_knn.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae930c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:06.255621Z",
     "iopub.status.busy": "2023-01-15T15:25:06.255170Z",
     "iopub.status.idle": "2023-01-15T15:25:06.606242Z",
     "shell.execute_reply": "2023-01-15T15:25:06.605801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
      "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
      "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
      "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
      "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
      "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
      "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
      "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
      "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
      "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
      "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
      "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
      "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
      "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
      "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8        Set9  \n",
      "0   339.000000  330.000000  333.000000  338.000000  331.000000  348.000000  \n",
      "1   164.000000  161.000000  174.000000  162.000000  150.000000  156.000000  \n",
      "2    61.000000   64.000000   58.000000   59.000000   77.000000   53.000000  \n",
      "3    31.000000   40.000000   30.000000   36.000000   37.000000   38.000000  \n",
      "4     0.845378    0.825210    0.852101    0.840336    0.808403    0.847059  \n",
      "5     0.847500    0.837563    0.851662    0.851385    0.811275    0.867830  \n",
      "6     0.916216    0.891892    0.917355    0.903743    0.899457    0.901554  \n",
      "7     0.728900    0.715600    0.750000    0.733000    0.660800    0.746400  \n",
      "8     0.880519    0.863874    0.883289    0.876783    0.853093    0.884371  \n",
      "9     0.842868    0.823032    0.850098    0.838335    0.804086    0.845670  \n",
      "10    0.830736    0.809871    0.840727    0.825027    0.788865    0.829282  \n",
      "11    0.822553    0.803724    0.833678    0.818387    0.780125    0.823983  \n",
      "12    0.666462    0.622809    0.685727    0.652965    0.586229    0.659851  \n",
      "13    0.841000    0.801000    0.852900    0.818200    0.802100    0.804100  \n",
      "14    0.822553    0.803724    0.833678    0.818387    0.780125    0.823983  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_knn_9 = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "    \n",
    "#learn\n",
    "\n",
    "\n",
    "optimized_knn_9.fit(X_trainSet9,Y_trainSet9, )\n",
    "\n",
    "# predict\n",
    "y_pred_knn_9 = optimized_knn_9.predict(X_testSet9)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet9, y_pred_knn_9)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet9, y_pred_knn_9)\n",
    "Precision = precision_score(Y_testSet9, y_pred_knn_9)\n",
    "Sensitivity = recall_score(Y_testSet9, y_pred_knn_9)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet9, y_pred_knn_9)      \n",
    "f1_scores_W = f1_score(Y_testSet9, y_pred_knn_9, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet9, y_pred_knn_9, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet9, y_pred_knn_9)\n",
    "MCC = matthews_corrcoef(Y_testSet9, y_pred_knn_9)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet9, y_pred_knn_9)\n",
    "    \n",
    "\n",
    "Set9 = pd.DataFrame({'Set9':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                      })   \n",
    "\n",
    "mat_met_knn_test['Set9'] = Set9\n",
    "print(mat_met_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b3879852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:06.608160Z",
     "iopub.status.busy": "2023-01-15T15:25:06.607932Z",
     "iopub.status.idle": "2023-01-15T15:25:06.775252Z",
     "shell.execute_reply": "2023-01-15T15:25:06.774847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study_knn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d16d4a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:06.777150Z",
     "iopub.status.busy": "2023-01-15T15:25:06.776976Z",
     "iopub.status.idle": "2023-01-15T15:25:11.289922Z",
     "shell.execute_reply": "2023-01-15T15:25:11.289577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_param_importances(study_knn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "52ff7ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:11.291360Z",
     "iopub.status.busy": "2023-01-15T15:25:11.291233Z",
     "iopub.status.idle": "2023-01-15T15:25:13.961668Z",
     "shell.execute_reply": "2023-01-15T15:25:13.961287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value (average)</th>\n",
       "      <th>Value (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>7.731609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>83.400000</td>\n",
       "      <td>7.260242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.788867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>3.497618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.829355</td>\n",
       "      <td>0.012725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.844553</td>\n",
       "      <td>0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.887157</td>\n",
       "      <td>0.020254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.027849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.865185</td>\n",
       "      <td>0.011899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.827758</td>\n",
       "      <td>0.012702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.815669</td>\n",
       "      <td>0.013670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.633678</td>\n",
       "      <td>0.027943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.801260</td>\n",
       "      <td>0.027518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value (average)  Value (std)\n",
       "0                    TP       163.000000     7.731609\n",
       "1                    TN        83.400000     7.260242\n",
       "2                    FP        30.000000     2.788867\n",
       "3                    FN        20.700000     3.497618\n",
       "4              Accuracy         0.829355     0.012725\n",
       "5             Precision         0.844553     0.012933\n",
       "6           Sensitivity         0.887157     0.020254\n",
       "7           Specificity         0.734660     0.027849\n",
       "8              F1 score         0.865185     0.011899\n",
       "9   F1 score (weighted)         0.827758     0.012702\n",
       "10     F1 score (macro)         0.815669     0.013670\n",
       "11    Balanced Accuracy         0.810913     0.013805\n",
       "12                  MCC         0.633678     0.027943\n",
       "13                  NPV         0.801260     0.027518\n",
       "14              ROC_AUC         0.810913     0.013805"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objective_knn_CV(study_knn.best_trial, X, Y, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9465254c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:13.963377Z",
     "iopub.status.busy": "2023-01-15T15:25:13.963242Z",
     "iopub.status.idle": "2023-01-15T15:25:13.976953Z",
     "shell.execute_reply": "2023-01-15T15:25:13.976597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Set0</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Set3</th>\n",
       "      <th>Set4</th>\n",
       "      <th>Set5</th>\n",
       "      <th>Set6</th>\n",
       "      <th>Set7</th>\n",
       "      <th>Set8</th>\n",
       "      <th>Set9</th>\n",
       "      <th>ave</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>333.700000</td>\n",
       "      <td>7.775317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>163.400000</td>\n",
       "      <td>7.366591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>60.800000</td>\n",
       "      <td>8.482662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>7.709302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.836975</td>\n",
       "      <td>0.825210</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>0.845378</td>\n",
       "      <td>0.825210</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.808403</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.835462</td>\n",
       "      <td>0.013053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.821951</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.837563</td>\n",
       "      <td>0.851662</td>\n",
       "      <td>0.851385</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.867830</td>\n",
       "      <td>0.846193</td>\n",
       "      <td>0.017976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.933518</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.898396</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.903743</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>0.900068</td>\n",
       "      <td>0.020259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.746600</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.746400</td>\n",
       "      <td>0.729160</td>\n",
       "      <td>0.033563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.874189</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.877285</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.863874</td>\n",
       "      <td>0.883289</td>\n",
       "      <td>0.876783</td>\n",
       "      <td>0.853093</td>\n",
       "      <td>0.884371</td>\n",
       "      <td>0.872034</td>\n",
       "      <td>0.010457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.832623</td>\n",
       "      <td>0.824377</td>\n",
       "      <td>0.840520</td>\n",
       "      <td>0.842868</td>\n",
       "      <td>0.823032</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.838335</td>\n",
       "      <td>0.804086</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.833354</td>\n",
       "      <td>0.013520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.821007</td>\n",
       "      <td>0.821343</td>\n",
       "      <td>0.812130</td>\n",
       "      <td>0.827793</td>\n",
       "      <td>0.830736</td>\n",
       "      <td>0.809871</td>\n",
       "      <td>0.840727</td>\n",
       "      <td>0.825027</td>\n",
       "      <td>0.788865</td>\n",
       "      <td>0.829282</td>\n",
       "      <td>0.820678</td>\n",
       "      <td>0.014334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.821007</td>\n",
       "      <td>0.810776</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.822501</td>\n",
       "      <td>0.822553</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>0.833678</td>\n",
       "      <td>0.818387</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.823983</td>\n",
       "      <td>0.814616</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.642015</td>\n",
       "      <td>0.655936</td>\n",
       "      <td>0.624781</td>\n",
       "      <td>0.657358</td>\n",
       "      <td>0.666462</td>\n",
       "      <td>0.622809</td>\n",
       "      <td>0.685727</td>\n",
       "      <td>0.652965</td>\n",
       "      <td>0.586229</td>\n",
       "      <td>0.659851</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>0.027964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.780400</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.852900</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.815960</td>\n",
       "      <td>0.030394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.821007</td>\n",
       "      <td>0.810776</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.822501</td>\n",
       "      <td>0.822553</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>0.833678</td>\n",
       "      <td>0.818387</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.823983</td>\n",
       "      <td>0.814616</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric        Set0        Set1        Set2        Set3  \\\n",
       "0                    TP  321.000000  337.000000  324.000000  336.000000   \n",
       "1                    TN  174.000000  161.000000  167.000000  165.000000   \n",
       "2                    FP   50.000000   73.000000   57.000000   56.000000   \n",
       "3                    FN   50.000000   24.000000   47.000000   38.000000   \n",
       "4              Accuracy    0.831933    0.836975    0.825210    0.842017   \n",
       "5             Precision    0.865229    0.821951    0.850394    0.857143   \n",
       "6           Sensitivity    0.865229    0.933518    0.873315    0.898396   \n",
       "7           Specificity    0.776800    0.688000    0.745500    0.746600   \n",
       "8              F1 score    0.865229    0.874189    0.861702    0.877285   \n",
       "9   F1 score (weighted)    0.831933    0.832623    0.824377    0.840520   \n",
       "10     F1 score (macro)    0.821007    0.821343    0.812130    0.827793   \n",
       "11    Balanced Accuracy    0.821007    0.810776    0.809426    0.822501   \n",
       "12                  MCC    0.642015    0.655936    0.624781    0.657358   \n",
       "13                  NPV    0.776800    0.870300    0.780400    0.812800   \n",
       "14              ROC_AUC    0.821007    0.810776    0.809426    0.822501   \n",
       "\n",
       "          Set4        Set5        Set6        Set7        Set8        Set9  \\\n",
       "0   339.000000  330.000000  333.000000  338.000000  331.000000  348.000000   \n",
       "1   164.000000  161.000000  174.000000  162.000000  150.000000  156.000000   \n",
       "2    61.000000   64.000000   58.000000   59.000000   77.000000   53.000000   \n",
       "3    31.000000   40.000000   30.000000   36.000000   37.000000   38.000000   \n",
       "4     0.845378    0.825210    0.852101    0.840336    0.808403    0.847059   \n",
       "5     0.847500    0.837563    0.851662    0.851385    0.811275    0.867830   \n",
       "6     0.916216    0.891892    0.917355    0.903743    0.899457    0.901554   \n",
       "7     0.728900    0.715600    0.750000    0.733000    0.660800    0.746400   \n",
       "8     0.880519    0.863874    0.883289    0.876783    0.853093    0.884371   \n",
       "9     0.842868    0.823032    0.850098    0.838335    0.804086    0.845670   \n",
       "10    0.830736    0.809871    0.840727    0.825027    0.788865    0.829282   \n",
       "11    0.822553    0.803724    0.833678    0.818387    0.780125    0.823983   \n",
       "12    0.666462    0.622809    0.685727    0.652965    0.586229    0.659851   \n",
       "13    0.841000    0.801000    0.852900    0.818200    0.802100    0.804100   \n",
       "14    0.822553    0.803724    0.833678    0.818387    0.780125    0.823983   \n",
       "\n",
       "           ave       std  \n",
       "0   333.700000  7.775317  \n",
       "1   163.400000  7.366591  \n",
       "2    60.800000  8.482662  \n",
       "3    37.100000  7.709302  \n",
       "4     0.835462  0.013053  \n",
       "5     0.846193  0.017976  \n",
       "6     0.900068  0.020259  \n",
       "7     0.729160  0.033563  \n",
       "8     0.872034  0.010457  \n",
       "9     0.833354  0.013520  \n",
       "10    0.820678  0.014334  \n",
       "11    0.814616  0.014837  \n",
       "12    0.645413  0.027964  \n",
       "13    0.815960  0.030394  \n",
       "14    0.814616  0.014837  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_met_knn_test['ave'] = mat_met_knn_test.iloc[:,1:11].mean(axis='columns', numeric_only=True)\n",
    "mat_met_knn_test['std'] = mat_met_knn_test.iloc[:,1:11].std(axis='columns', numeric_only=True)\n",
    "mat_met_knn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e11bef7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:13.978700Z",
     "iopub.status.busy": "2023-01-15T15:25:13.978550Z",
     "iopub.status.idle": "2023-01-15T15:25:27.691289Z",
     "shell.execute_reply": "2023-01-15T15:25:27.690871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test_idx0</th>\n",
       "      <th>y_test0</th>\n",
       "      <th>y_pred_knn0</th>\n",
       "      <th>y_pred_knn1</th>\n",
       "      <th>y_pred_knn2</th>\n",
       "      <th>y_pred_knn3</th>\n",
       "      <th>y_pred_knn4</th>\n",
       "      <th>y_pred_knn_ave</th>\n",
       "      <th>y_pred_knn_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test_idx0  y_test0  y_pred_knn0  y_pred_knn1  y_pred_knn2  \\\n",
       "0               0      1.0          1.0          1.0          1.0   \n",
       "1               1      1.0          1.0          1.0          1.0   \n",
       "2               2      0.0          0.0          0.0          0.0   \n",
       "3               3      0.0          1.0          1.0          1.0   \n",
       "4               4      0.0          1.0          1.0          1.0   \n",
       "...           ...      ...          ...          ...          ...   \n",
       "2966         2966      1.0          1.0          1.0          1.0   \n",
       "2967         2967      1.0          1.0          1.0          1.0   \n",
       "2968         2968      0.0          1.0          1.0          1.0   \n",
       "2969         2969      1.0          1.0          0.0          1.0   \n",
       "2970         2970      1.0          0.0          0.0          0.0   \n",
       "\n",
       "      y_pred_knn3  y_pred_knn4  y_pred_knn_ave  y_pred_knn_std  \n",
       "0             1.0          1.0             1.0        0.000000  \n",
       "1             1.0          1.0             1.0        0.000000  \n",
       "2             0.0          0.0             0.0        0.000000  \n",
       "3             1.0          1.0             1.0        0.000000  \n",
       "4             1.0          1.0             1.0        0.000000  \n",
       "...           ...          ...             ...             ...  \n",
       "2966          1.0          1.0             1.0        0.000000  \n",
       "2967          1.0          1.0             1.0        0.000000  \n",
       "2968          1.0          1.0             1.0        0.000000  \n",
       "2969          1.0          0.0             0.6        0.489898  \n",
       "2970          0.0          0.0             0.0        0.000000  \n",
       "\n",
       "[2971 rows x 9 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to fit into these X values \n",
    "\n",
    "TP = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "\n",
    "\n",
    "Accuracy_outer = []\n",
    "Precision_outer = [] #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity_outer = [] # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity_outer = [] #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores_outer = []\n",
    "f1_scores_W_outer = []\n",
    "f1_scores_M_outer = []\n",
    "BA_scores_outer = []\n",
    "MCC_outer = []\n",
    "NPV_outer = []\n",
    "ROC_AUC_outer = []\n",
    "\n",
    "NUM_TRIALS = 5\n",
    "random_state= [687266, 98656, 56, 280189, 76543] # \n",
    "data_knn=pd.DataFrame()\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    cv_change = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state[i])\n",
    "    data_inner = pd.DataFrame({'y_test_idx': pd.Series(dtype='int'),\n",
    "                   'y_test': pd.Series(dtype='float'),\n",
    "                   'y_pred': pd.Series(dtype='float')})\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv_change.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        optimizedCV_knn = KNeighborsClassifier(n_neighbors = study_knn.best_params['n_neighbors'],\n",
    "                                                  weights= study_knn.best_params['weights'],\n",
    "                                                  metric= study_knn.best_params['metric'],\n",
    "                                                  leaf_size= study_knn.best_params['leaf_size'],\n",
    "                                                  n_jobs=16,\n",
    "                                                 )\n",
    "\n",
    "\n",
    "        #learn\n",
    "        \n",
    "        optimizedCV_knn.fit(X_train,y_train)\n",
    "                          \n",
    "                  \n",
    "        #print(test_idx)\n",
    "        y_pred_optimized_knn = optimizedCV_knn.predict(X_test) \n",
    "        data_inner = data_inner.append(pd.DataFrame({'y_test_idx': test_idx, 'y_test': y_test, 'y_pred_knn': y_pred_optimized_knn } ), )\n",
    "        data_inner.reset_index(inplace=True, drop=True) \n",
    "        data_inner.sort_values(by='y_test_idx', inplace=True) \n",
    "        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimized_knn)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        \n",
    "        Accuracy_outer.append(accuracy_score(y_test, y_pred_optimized_knn))\n",
    "        Precision_outer.append(precision_score(y_test, y_pred_optimized_knn))\n",
    "        Sensitivity_outer.append(recall_score(y_test, y_pred_optimized_knn))\n",
    "        Specificity_outer.append(round( TN[idx] / (TN[idx]+FP[idx]),4 ))\n",
    "        f1_scores_outer.append(f1_score(y_test, y_pred_optimized_knn))\n",
    "        f1_scores_W_outer.append(f1_score(y_test, y_pred_optimized_knn, average=\"weighted\"))\n",
    "        f1_scores_M_outer.append(f1_score(y_test, y_pred_optimized_knn, average=\"macro\"))\n",
    "        BA_scores_outer.append(balanced_accuracy_score(y_test, y_pred_optimized_knn))\n",
    "        MCC_outer.append(matthews_corrcoef(y_test, y_pred_optimized_knn))\n",
    "        NPV_outer.append(round( TN[idx] / (TN[idx]+FN[idx]),4 ))\n",
    "        ROC_AUC_outer.append(roc_auc_score(y_test, y_pred_optimized_knn))\n",
    "        \n",
    "    data_knn['y_test_idx' + str(i)] = data_inner['y_test_idx']\n",
    "    data_knn['y_test' + str(i)] = data_inner['y_test']\n",
    "    data_knn['y_pred_knn' + str(i)] = data_inner['y_pred_knn']\n",
    "   # data_knn['correct' + str(i)] = correct_value\n",
    "   # data_knn['pred' + str(i)] = y_pred_optimized_knn\n",
    "\n",
    "mat_met_optimized_knn = pd.DataFrame({'Metric':['Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(Accuracy_outer),np.mean(Precision_outer),\n",
    "                                           np.mean(Sensitivity_outer),np.mean(Specificity_outer),np.mean(f1_scores_outer),\n",
    "                                           np.mean(f1_scores_W_outer), np.mean(f1_scores_M_outer), np.mean(BA_scores_outer), \n",
    "                                           np.mean(MCC_outer),np.mean(NPV_outer),np.mean(ROC_AUC_outer)],\n",
    "                        'Value (std)': [ np.std(Accuracy_outer, ddof=1),np.std(Precision_outer, ddof=1),\n",
    "                                        np.std(Sensitivity_outer,ddof=1),np.std(Specificity_outer,ddof=1),np.std(f1_scores_outer, ddof=1),\n",
    "                                        np.std(f1_scores_W_outer, ddof=1),np.std(f1_scores_M_outer, ddof=1), np.std(BA_scores_outer, ddof=1), \n",
    "                                        np.std(MCC_outer, ddof=1),np.std(NPV_outer, ddof=1),np.std(ROC_AUC_outer, ddof=1)]\n",
    "                       }) \n",
    "\n",
    "\n",
    "knn_run0 = data_knn[['y_test_idx0', 'y_test0', 'y_pred_knn0']]\n",
    "knn_run0.sort_values(by='y_test_idx0', inplace=True)\n",
    "knn_run0.reset_index(inplace=True, drop=True)\n",
    "knn_run1 = data_knn[['y_test_idx1', 'y_test1', 'y_pred_knn1']]\n",
    "knn_run1.sort_values(by='y_test_idx1', inplace=True)\n",
    "knn_run1.reset_index(inplace=True, drop=True)\n",
    "knn_run2 = data_knn[['y_test_idx2', 'y_test2', 'y_pred_knn2']]\n",
    "knn_run2.sort_values(by='y_test_idx2', inplace=True)\n",
    "knn_run2.reset_index(inplace=True, drop=True)\n",
    "knn_run3 = data_knn[['y_test_idx3', 'y_test3', 'y_pred_knn3']]\n",
    "knn_run3.sort_values(by='y_test_idx3', inplace=True)\n",
    "knn_run3.reset_index(inplace=True, drop=True)\n",
    "knn_run4 = data_knn[['y_test_idx4', 'y_test4', 'y_pred_knn4']]\n",
    "knn_run4.sort_values(by='y_test_idx4', inplace=True)\n",
    "knn_run4.reset_index(inplace=True, drop=True)\n",
    "knn_5preds = pd.concat([knn_run0, knn_run1, knn_run2, knn_run3, knn_run4], axis=1)\n",
    "knn_5preds = knn_5preds[['y_test_idx0', 'y_test0', 'y_pred_knn0', 'y_pred_knn1', 'y_pred_knn2', 'y_pred_knn3', 'y_pred_knn4']]\n",
    "knn_5preds['y_pred_knn_ave'] = knn_5preds.iloc[:,2:11].mean(axis='columns', numeric_only=True)\n",
    "knn_5preds['y_pred_knn_std'] = knn_5preds.iloc[:,2:].std(axis='columns', numeric_only=True)\n",
    "# maybe also calculate the std for each value\n",
    "knn_5preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c149767d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:27.693050Z",
     "iopub.status.busy": "2023-01-15T15:25:27.692903Z",
     "iopub.status.idle": "2023-01-15T15:25:27.708235Z",
     "shell.execute_reply": "2023-01-15T15:25:27.707910Z"
    }
   },
   "outputs": [],
   "source": [
    "mat_met_optimized_knn.to_csv('mat_met_knn_opt.csv')\n",
    "knn_5preds.to_csv('knn_5test_CV_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1fb53bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:27.709793Z",
     "iopub.status.busy": "2023-01-15T15:25:27.709657Z",
     "iopub.status.idle": "2023-01-15T15:25:43.434949Z",
     "shell.execute_reply": "2023-01-15T15:25:43.434399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN baseline model f1_score 0.8107 with a standard deviation of 0.0306\n",
      "KNN optimized model f1_score 0.8224 with a standard deviation of 0.0273\n"
     ]
    }
   ],
   "source": [
    "#cross valide using this optimized KNN \n",
    "knn_baseline_CVscore = cross_val_score(knn_clf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "#cv_knn_opt_testSet = cross_val_score(optimized_knn, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "cv_knn_opt = cross_val_score(optimizedCV_knn, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "print(\"KNN baseline model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(knn_baseline_CVscore), np.std(knn_baseline_CVscore, ddof=1)))\n",
    "#print(\"KNN optimized model (tested on Y_te) f1_score %0.4f with a standard deviation of %0.4f\" % (cv_knn_opt_testSet.mean(), cv_knn_opt_testSet.std()))\n",
    "print(\"KNN optimized model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(cv_knn_opt), np.std(cv_knn_opt, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f21ca0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:43.436619Z",
     "iopub.status.busy": "2023-01-15T15:25:43.436485Z",
     "iopub.status.idle": "2023-01-15T15:25:43.490493Z",
     "shell.execute_reply": "2023-01-15T15:25:43.490023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optimizedCV_knn_clf.joblib']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn_clf, \"./knn_clf.joblib\")\n",
    "#joblib.dump(optimized_knn, \"./optimized_knn.joblib\")\n",
    "joblib.dump(optimizedCV_knn, \"./optimizedCV_knn_clf.joblib\")\n",
    "#loaded_rf = joblib.load(\"./optimized_rf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb36c6",
   "metadata": {},
   "source": [
    "## Support Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4363225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:25:43.492623Z",
     "iopub.status.busy": "2023-01-15T15:25:43.492438Z",
     "iopub.status.idle": "2023-01-15T15:26:23.527788Z",
     "shell.execute_reply": "2023-01-15T15:26:23.527456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric  Value (average)  Value (std)\n",
      "0                    TP       165.800000     8.093893\n",
      "1                    TN        85.300000     6.000926\n",
      "2                    FP        28.100000     3.247221\n",
      "3                    FN        17.900000     3.725289\n",
      "4              Accuracy         0.845170     0.013838\n",
      "5             Precision         0.854949     0.016387\n",
      "6           Sensitivity         0.902357     0.020730\n",
      "7           Specificity         0.752150     0.025653\n",
      "8              F1 score         0.877850     0.013504\n",
      "9   F1 score (weighted)         0.843590     0.013733\n",
      "10     F1 score (macro)         0.832656     0.013187\n",
      "11    Balanced Accuracy         0.827256     0.012672\n",
      "12                  MCC         0.668273     0.026500\n",
      "13                  NPV         0.827510     0.029490\n",
      "14              ROC_AUC         0.827256     0.012672\n",
      "CPU times: user 37.1 s, sys: 0 ns, total: 37.1 s\n",
      "Wall time: 37.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "TP =np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "Accuracy = np.empty(10)\n",
    "Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores = np.empty(10)\n",
    "f1_scores_W = np.empty(10)\n",
    "f1_scores_M = np.empty(10)\n",
    "BA_scores = np.empty(10)\n",
    "MCC = np.empty(10)\n",
    "NPV = np.empty(10)\n",
    "ROC_AUC= np.empty(10)\n",
    "\n",
    "\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "    svm_clf = SVC()\n",
    "    \n",
    "    svm_clf.fit(X_train, y_train, )\n",
    "\n",
    "    y_pred = svm_clf.predict(X_test) \n",
    "   \n",
    "    #calculate the evaluation results\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TP[idx] = conf_matrix[1][1]\n",
    "    TN[idx] = conf_matrix[0][0]\n",
    "    FP[idx] = conf_matrix[0][1] \n",
    "    FN[idx] = conf_matrix[1][0]\n",
    "    Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "    Precision[idx] = precision_score(y_test, y_pred)\n",
    "    Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "    Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "    f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "    f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "    MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "    NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "    ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       }) \n",
    "    \n",
    "print(mat_met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a0212847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:26:23.529378Z",
     "iopub.status.busy": "2023-01-15T15:26:23.529248Z",
     "iopub.status.idle": "2023-01-15T15:26:23.534274Z",
     "shell.execute_reply": "2023-01-15T15:26:23.533968Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_svm_CV(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \"C\" : trial.suggest_categorical(\"C\", [np.exp2(-7), np.exp2(-6), np.exp2(-5), np.exp2(-4), np.exp2(-3), np.exp2(-2),\n",
    "                                              np.exp2(-1), np.exp2(0), np.exp2(1), np.exp2(2), np.exp2(3), np.exp2(4),\n",
    "                                             np.exp2(5), np.exp2(6), np.exp2(7)]),\n",
    "        \"gamma\" :trial.suggest_categorical(\"gamma\", [np.exp2(-15), np.exp2(-14), np.exp2(-13), np.exp2(-12), np.exp2(-11), \n",
    "                                                     np.exp2(-10),np.exp2(-9), np.exp2(-8), np.exp2(-7), np.exp2(-6), np.exp2(-5), \n",
    "                                                     np.exp2(-4),np.exp2(-3), np.exp2(-2), np.exp2(-1), np.exp2(0), np.exp2(1),\n",
    "                                                     np.exp2(2), np.exp2(3)]),\n",
    "        #\"kernel\" : trial.suggestegorical(\"kernel\", ['linear', 'rbf', 'sigmoid']),\n",
    "        #\"degree\": trial.suggest_int(\"degree\", 3, 10)\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu'])\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "    cv_scores=np.empty(10)\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        svm_model = SVC(**param_grid)\n",
    "        svm_model.fit(X_train,y_train)\n",
    "    \n",
    "        y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "        cv_scores[idx] = f1_score(y_test, y_pred, average='macro')\n",
    "       \n",
    "        \n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d0a2e1c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:26:23.535638Z",
     "iopub.status.busy": "2023-01-15T15:26:23.535524Z",
     "iopub.status.idle": "2023-01-15T15:26:23.544755Z",
     "shell.execute_reply": "2023-01-15T15:26:23.544446Z"
    }
   },
   "outputs": [],
   "source": [
    "def detailed_objective_svm_cv(trial, X, Y, Y_class):\n",
    "    param_grid = {\n",
    "        \"C\" : trial.suggest_categorical(\"C\", [np.exp2(-7), np.exp2(-6), np.exp2(-5), np.exp2(-4), np.exp2(-3), np.exp2(-2),\n",
    "                                              np.exp2(-1), np.exp2(0), np.exp2(1), np.exp2(2), np.exp2(3), np.exp2(4),\n",
    "                                             np.exp2(5), np.exp2(6), np.exp2(7)]),\n",
    "        \"gamma\" :trial.suggest_categorical(\"gamma\", [np.exp2(-15), np.exp2(-14), np.exp2(-13), np.exp2(-12), np.exp2(-11), \n",
    "                                                     np.exp2(-10),np.exp2(-9), np.exp2(-8), np.exp2(-7), np.exp2(-6), np.exp2(-5), \n",
    "                                                     np.exp2(-4),np.exp2(-3), np.exp2(-2), np.exp2(-1), np.exp2(0), np.exp2(1),\n",
    "                                                     np.exp2(2), np.exp2(3)]),\n",
    "        #\"kernel\" : trial.suggestegorical(\"kernel\", ['linear', 'rbf', 'sigmoid']),\n",
    "        #\"degree\": trial.suggest_int(\"degree\", 3, 10)\n",
    "        #\"device_type\": trial.suggestegorical(\"device_type\", ['gpu']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "  \n",
    "    TP =np.empty(10)\n",
    "    TN = np.empty(10)\n",
    "    FP = np.empty(10)\n",
    "    FN = np.empty(10)\n",
    "    Accuracy = np.empty(10)\n",
    "    Precision = np.empty(10) #Also called Positive Predictive Value(PPV)\n",
    "    Sensitivity = np.empty(10) # Also called Recall or True Positive Rate (TPR)\n",
    "    Specificity = np.empty(10) #Also called selectivity or True Negative Rate  (TNR)\n",
    "    f1_scores = np.empty(10)\n",
    "    f1_scores_W = np.empty(10)\n",
    "    f1_scores_M = np.empty(10)\n",
    "    BA_scores = np.empty(10)\n",
    "    MCC = np.empty(10)\n",
    "    NPV = np.empty(10)\n",
    "    ROC_AUC= np.empty(10)\n",
    "\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        svm_model = SVC(**param_grid)\n",
    "        svm_model.fit(X_train,y_train)\n",
    "    \n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        \n",
    "        #calculate the evaluation results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        Accuracy[idx] = accuracy_score(y_test, y_pred)\n",
    "        Precision[idx] = precision_score(y_test, y_pred)\n",
    "        Sensitivity[idx] = recall_score(y_test, y_pred)\n",
    "        Specificity[idx] = round( TN[idx] / (TN[idx]+FP[idx]),4 )\n",
    "        f1_scores[idx] = f1_score(y_test, y_pred)\n",
    "        f1_scores_W[idx] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1_scores_M[idx] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        BA_scores[idx] = balanced_accuracy_score(y_test, y_pred)\n",
    "        MCC[idx] = matthews_corrcoef(y_test, y_pred)\n",
    "        NPV[idx] = round( TN[idx] / (TN[idx]+FN[idx]),4 )\n",
    "        ROC_AUC[idx] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        'Value (std)': [ np.std(TP,ddof=1),np.std(TN,ddof=1),np.std(FP,ddof=1),np.std(FN, ddof=1),\n",
    "                                        np.std(Accuracy, ddof=1),np.std(Precision, ddof=1),\n",
    "                                        np.std(Sensitivity,ddof=1),np.std(Specificity,ddof=1),np.std(f1_scores, ddof=1),\n",
    "                                        np.std(f1_scores_W, ddof=1),np.std(f1_scores_M, ddof=1), np.std(BA_scores, ddof=1), \n",
    "                                        np.std(MCC, ddof=1),np.std(NPV, ddof=1),np.std(ROC_AUC, ddof=1)]\n",
    "                       })  \n",
    "    \n",
    "    return(mat_met)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b7a25cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:26:23.546023Z",
     "iopub.status.busy": "2023-01-15T15:26:23.545909Z",
     "iopub.status.idle": "2023-01-15T15:51:48.897410Z",
     "shell.execute_reply": "2023-01-15T15:51:48.897080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:31:47,005]\u001b[0m A new study created in memory with name: SVM_classifier\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:32:22,165]\u001b[0m Trial 0 finished with value: 0.4538268466761636 and parameters: {'C': 4.0, 'gamma': 0.25}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:32:52,291]\u001b[0m Trial 1 finished with value: 0.38141973614934377 and parameters: {'C': 0.125, 'gamma': 6.103515625e-05}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:33:27,329]\u001b[0m Trial 2 finished with value: 0.4398772108379528 and parameters: {'C': 128.0, 'gamma': 0.5}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:33:57,541]\u001b[0m Trial 3 finished with value: 0.38141973614934377 and parameters: {'C': 0.5, 'gamma': 3.0517578125e-05}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:34:27,726]\u001b[0m Trial 4 finished with value: 0.38141973614934377 and parameters: {'C': 0.25, 'gamma': 6.103515625e-05}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:35:01,568]\u001b[0m Trial 5 finished with value: 0.38658036974612947 and parameters: {'C': 0.5, 'gamma': 0.5}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:35:31,888]\u001b[0m Trial 6 finished with value: 0.38141973614934377 and parameters: {'C': 0.0625, 'gamma': 0.0001220703125}. Best is trial 0 with value: 0.4538268466761636.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:36:06,983]\u001b[0m Trial 7 finished with value: 0.5802246926667 and parameters: {'C': 1.0, 'gamma': 0.125}. Best is trial 7 with value: 0.5802246926667.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:36:42,090]\u001b[0m Trial 8 finished with value: 0.6289409555201058 and parameters: {'C': 4.0, 'gamma': 0.125}. Best is trial 8 with value: 0.6289409555201058.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:37:15,700]\u001b[0m Trial 9 finished with value: 0.38141973614934377 and parameters: {'C': 0.125, 'gamma': 2.0}. Best is trial 8 with value: 0.6289409555201058.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:37:34,495]\u001b[0m Trial 10 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:37:53,318]\u001b[0m Trial 11 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:38:12,101]\u001b[0m Trial 12 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:38:30,961]\u001b[0m Trial 13 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:38:49,758]\u001b[0m Trial 14 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:39:19,441]\u001b[0m Trial 15 finished with value: 0.38141973614934377 and parameters: {'C': 0.015625, 'gamma': 0.000244140625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:39:53,048]\u001b[0m Trial 16 finished with value: 0.38141973614934377 and parameters: {'C': 0.0078125, 'gamma': 4.0}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:40:29,395]\u001b[0m Trial 17 finished with value: 0.4121765148307858 and parameters: {'C': 16.0, 'gamma': 8.0}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:40:55,368]\u001b[0m Trial 18 finished with value: 0.7314977859966165 and parameters: {'C': 2.0, 'gamma': 0.00048828125}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:41:24,884]\u001b[0m Trial 19 finished with value: 0.38141973614934377 and parameters: {'C': 0.03125, 'gamma': 0.0078125}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:41:59,806]\u001b[0m Trial 20 finished with value: 0.4284979947233872 and parameters: {'C': 8.0, 'gamma': 1.0}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:42:18,652]\u001b[0m Trial 21 finished with value: 0.8004920179015125 and parameters: {'C': 32.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:42:36,971]\u001b[0m Trial 22 finished with value: 0.7984239843091108 and parameters: {'C': 64.0, 'gamma': 0.0009765625}. Best is trial 10 with value: 0.8004920179015125.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:43:10,225]\u001b[0m Trial 23 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:43:43,454]\u001b[0m Trial 24 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:44:16,736]\u001b[0m Trial 25 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:44:49,911]\u001b[0m Trial 26 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:45:21,392]\u001b[0m Trial 27 finished with value: 0.38141973614934377 and parameters: {'C': 0.0078125, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:45:52,489]\u001b[0m Trial 28 finished with value: 0.44043951654619795 and parameters: {'C': 0.0625, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:46:27,177]\u001b[0m Trial 29 finished with value: 0.814993400605257 and parameters: {'C': 16.0, 'gamma': 0.0625}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:46:51,464]\u001b[0m Trial 30 finished with value: 0.76977405855711 and parameters: {'C': 1.0, 'gamma': 0.001953125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:47:24,539]\u001b[0m Trial 31 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:47:57,676]\u001b[0m Trial 32 finished with value: 0.8286984031806665 and parameters: {'C': 32.0, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:48:27,292]\u001b[0m Trial 33 finished with value: 0.8214652028298923 and parameters: {'C': 32.0, 'gamma': 0.015625}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:49:02,103]\u001b[0m Trial 34 finished with value: 0.45427271206461084 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:49:32,151]\u001b[0m Trial 35 finished with value: 0.7425585760903796 and parameters: {'C': 0.25, 'gamma': 0.03125}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:49:50,570]\u001b[0m Trial 36 finished with value: 0.7983802982516222 and parameters: {'C': 128.0, 'gamma': 0.00390625}. Best is trial 23 with value: 0.8286984031806665.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:50:24,493]\u001b[0m Trial 37 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:50:48,222]\u001b[0m Trial 38 finished with value: 0.7718910105076844 and parameters: {'C': 64.0, 'gamma': 3.0517578125e-05}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:51:22,046]\u001b[0m Trial 39 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:51:42,657]\u001b[0m Trial 40 finished with value: 0.7973842058800628 and parameters: {'C': 64.0, 'gamma': 0.0001220703125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:52:16,414]\u001b[0m Trial 41 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:52:50,261]\u001b[0m Trial 42 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:53:12,222]\u001b[0m Trial 43 finished with value: 0.789485234146586 and parameters: {'C': 64.0, 'gamma': 6.103515625e-05}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:53:46,926]\u001b[0m Trial 44 finished with value: 0.4398772108379528 and parameters: {'C': 64.0, 'gamma': 0.5}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:54:21,845]\u001b[0m Trial 45 finished with value: 0.4165755689975767 and parameters: {'C': 64.0, 'gamma': 2.0}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:54:55,567]\u001b[0m Trial 46 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:55:29,315]\u001b[0m Trial 47 finished with value: 0.8292393344141649 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:56:04,352]\u001b[0m Trial 48 finished with value: 0.4121765148307858 and parameters: {'C': 4.0, 'gamma': 4.0}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:56:33,805]\u001b[0m Trial 49 finished with value: 0.38141973614934377 and parameters: {'C': 0.5, 'gamma': 0.000244140625}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 50.0\n",
      "\tBest value (f1_score): 0.8292\n",
      "\tBest params:\n",
      "\t\tC: 64.0\n",
      "\t\tgamma: 0.03125\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "study_svm = optuna.create_study(direction='maximize', study_name=\"SVM_classifier\")\n",
    "func_svm_0 = lambda trial: objective_svm_CV(trial, X_trainSet0, Y_trainSet0, Y_trainSet0_class)\n",
    "study_svm.optimize(func_svm_0, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f310e06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:51:48.899096Z",
     "iopub.status.busy": "2023-01-15T15:51:48.898974Z",
     "iopub.status.idle": "2023-01-15T15:51:52.971479Z",
     "shell.execute_reply": "2023-01-15T15:51:52.971117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0\n",
      "0                    TP  328.000000\n",
      "1                    TN  176.000000\n",
      "2                    FP   48.000000\n",
      "3                    FN   43.000000\n",
      "4              Accuracy    0.847059\n",
      "5             Precision    0.872340\n",
      "6           Sensitivity    0.884097\n",
      "7           Specificity    0.785700\n",
      "8              F1 score    0.878179\n",
      "9   F1 score (weighted)    0.846708\n",
      "10     F1 score (macro)    0.836381\n",
      "11    Balanced Accuracy    0.834906\n",
      "12                  MCC    0.672895\n",
      "13                  NPV    0.803700\n",
      "14              ROC_AUC    0.834906\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_0 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_0.fit(X_trainSet0,Y_trainSet0,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_0 = optimized_svm_0.predict(X_testSet0)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet0, y_pred_svm_0)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet0, y_pred_svm_0)\n",
    "Precision = precision_score(Y_testSet0, y_pred_svm_0)\n",
    "Sensitivity = recall_score(Y_testSet0, y_pred_svm_0)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet0, y_pred_svm_0)      \n",
    "f1_scores_W = f1_score(Y_testSet0, y_pred_svm_0, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet0, y_pred_svm_0, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet0, y_pred_svm_0)\n",
    "MCC = matthews_corrcoef(Y_testSet0, y_pred_svm_0)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet0, y_pred_svm_0)\n",
    "    \n",
    "\n",
    "mat_met_svm_test = pd.DataFrame({'Metric':['TP','TN','FP','FN','Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Set0':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })    \n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f70c706f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:51:52.973199Z",
     "iopub.status.busy": "2023-01-15T15:51:52.973080Z",
     "iopub.status.idle": "2023-01-15T16:18:02.358654Z",
     "shell.execute_reply": "2023-01-15T16:18:02.358235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 17:57:13,027]\u001b[0m Trial 50 finished with value: 0.6346265578758455 and parameters: {'C': 64.0, 'gamma': 0.125}. Best is trial 37 with value: 0.8292393344141649.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:57:46,026]\u001b[0m Trial 51 finished with value: 0.8379368086361559 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:58:19,263]\u001b[0m Trial 52 finished with value: 0.8379368086361559 and parameters: {'C': 64.0, 'gamma': 0.03125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:58:54,261]\u001b[0m Trial 53 finished with value: 0.38305499462024917 and parameters: {'C': 0.125, 'gamma': 8.0}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:59:12,649]\u001b[0m Trial 54 finished with value: 0.8189542005343423 and parameters: {'C': 64.0, 'gamma': 0.00048828125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 17:59:43,704]\u001b[0m Trial 55 finished with value: 0.38305499462024917 and parameters: {'C': 0.015625, 'gamma': 0.03125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:00:10,326]\u001b[0m Trial 56 finished with value: 0.8210334587065411 and parameters: {'C': 64.0, 'gamma': 0.0078125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:00:29,833]\u001b[0m Trial 57 finished with value: 0.8242115288117571 and parameters: {'C': 8.0, 'gamma': 0.001953125}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:00:48,075]\u001b[0m Trial 58 finished with value: 0.8101528396412405 and parameters: {'C': 64.0, 'gamma': 0.00390625}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:01:21,641]\u001b[0m Trial 59 finished with value: 0.38305499462024917 and parameters: {'C': 0.03125, 'gamma': 1.0}. Best is trial 51 with value: 0.8379368086361559.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:01:51,929]\u001b[0m Trial 60 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:02:22,257]\u001b[0m Trial 61 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:02:52,643]\u001b[0m Trial 62 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:03:22,950]\u001b[0m Trial 63 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:03:53,437]\u001b[0m Trial 64 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:04:23,792]\u001b[0m Trial 65 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:04:54,303]\u001b[0m Trial 66 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:05:24,758]\u001b[0m Trial 67 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:05:54,995]\u001b[0m Trial 68 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:06:25,316]\u001b[0m Trial 69 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:06:55,699]\u001b[0m Trial 70 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:07:26,075]\u001b[0m Trial 71 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:07:56,626]\u001b[0m Trial 72 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:08:27,146]\u001b[0m Trial 73 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:08:57,561]\u001b[0m Trial 74 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:09:28,009]\u001b[0m Trial 75 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:09:58,494]\u001b[0m Trial 76 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:10:28,962]\u001b[0m Trial 77 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:10:59,326]\u001b[0m Trial 78 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:11:34,294]\u001b[0m Trial 79 finished with value: 0.8130080523491182 and parameters: {'C': 128.0, 'gamma': 0.0625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:11:58,156]\u001b[0m Trial 80 finished with value: 0.8279723275701159 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:12:28,612]\u001b[0m Trial 81 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:12:59,030]\u001b[0m Trial 82 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:13:34,247]\u001b[0m Trial 83 finished with value: 0.4627277142440083 and parameters: {'C': 128.0, 'gamma': 0.25}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:14:03,427]\u001b[0m Trial 84 finished with value: 0.4865135803277223 and parameters: {'C': 0.0625, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:14:30,019]\u001b[0m Trial 85 finished with value: 0.7674959305526331 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:14:51,919]\u001b[0m Trial 86 finished with value: 0.781791527198527 and parameters: {'C': 128.0, 'gamma': 3.0517578125e-05}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:15:11,028]\u001b[0m Trial 87 finished with value: 0.8183449792197172 and parameters: {'C': 128.0, 'gamma': 0.0001220703125}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:15:40,163]\u001b[0m Trial 88 finished with value: 0.38305499462024917 and parameters: {'C': 2.0, 'gamma': 6.103515625e-05}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:16:10,391]\u001b[0m Trial 89 finished with value: 0.38305499462024917 and parameters: {'C': 0.0078125, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:16:39,832]\u001b[0m Trial 90 finished with value: 0.8349862385542348 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:17:10,149]\u001b[0m Trial 91 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:17:45,395]\u001b[0m Trial 92 finished with value: 0.43317717728517796 and parameters: {'C': 128.0, 'gamma': 0.5}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:18:20,690]\u001b[0m Trial 93 finished with value: 0.40637984309164965 and parameters: {'C': 4.0, 'gamma': 2.0}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 18:18:45,723]\u001b[0m Trial 94 finished with value: 0.804019174238406 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:19:20,597]\u001b[0m Trial 95 finished with value: 0.6346265578758455 and parameters: {'C': 128.0, 'gamma': 0.125}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:19:50,371]\u001b[0m Trial 96 finished with value: 0.38305499462024917 and parameters: {'C': 0.125, 'gamma': 0.000244140625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:20:20,623]\u001b[0m Trial 97 finished with value: 0.8380668800853919 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:20:55,924]\u001b[0m Trial 98 finished with value: 0.40536374792921304 and parameters: {'C': 128.0, 'gamma': 4.0}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:21:25,762]\u001b[0m Trial 99 finished with value: 0.38305499462024917 and parameters: {'C': 0.015625, 'gamma': 0.00048828125}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 100.0\n",
      "\tBest value (f1_score): 0.8381\n",
      "\tBest params:\n",
      "\t\tC: 128.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_1 = lambda trial: objective_svm_CV(trial, X_trainSet1, Y_trainSet1, Y_trainSet1_class)\n",
    "study_svm.optimize(func_svm_1, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dbfdb414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T16:18:02.360427Z",
     "iopub.status.busy": "2023-01-15T16:18:02.360323Z",
     "iopub.status.idle": "2023-01-15T16:18:06.148086Z",
     "shell.execute_reply": "2023-01-15T16:18:06.147581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1\n",
      "0                    TP  328.000000  338.000000\n",
      "1                    TN  176.000000  169.000000\n",
      "2                    FP   48.000000   65.000000\n",
      "3                    FN   43.000000   23.000000\n",
      "4              Accuracy    0.847059    0.852101\n",
      "5             Precision    0.872340    0.838710\n",
      "6           Sensitivity    0.884097    0.936288\n",
      "7           Specificity    0.785700    0.722200\n",
      "8              F1 score    0.878179    0.884817\n",
      "9   F1 score (weighted)    0.846708    0.848875\n",
      "10     F1 score (macro)    0.836381    0.839122\n",
      "11    Balanced Accuracy    0.834906    0.829255\n",
      "12                  MCC    0.672895    0.688052\n",
      "13                  NPV    0.803700    0.880200\n",
      "14              ROC_AUC    0.834906    0.829255\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_1 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_1.fit(X_trainSet1,Y_trainSet1,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_1 = optimized_svm_1.predict(X_testSet1)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet1, y_pred_svm_1)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet1, y_pred_svm_1)\n",
    "Precision = precision_score(Y_testSet1, y_pred_svm_1)\n",
    "Sensitivity = recall_score(Y_testSet1, y_pred_svm_1)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet1, y_pred_svm_1)      \n",
    "f1_scores_W = f1_score(Y_testSet1, y_pred_svm_1, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet1, y_pred_svm_1, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet1, y_pred_svm_1)\n",
    "MCC = matthews_corrcoef(Y_testSet1, y_pred_svm_1)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet1, y_pred_svm_1)\n",
    "    \n",
    "\n",
    "set1 = pd.DataFrame({'Set1':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set1'] = set1\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3c802470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T16:18:06.149970Z",
     "iopub.status.busy": "2023-01-15T16:18:06.149697Z",
     "iopub.status.idle": "2023-01-15T16:41:24.997763Z",
     "shell.execute_reply": "2023-01-15T16:41:24.997292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 18:22:04,619]\u001b[0m Trial 100 finished with value: 0.3814109693472025 and parameters: {'C': 0.03125, 'gamma': 8.0}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:22:34,124]\u001b[0m Trial 101 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:23:03,766]\u001b[0m Trial 102 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:23:33,302]\u001b[0m Trial 103 finished with value: 0.8377975832920876 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:24:08,262]\u001b[0m Trial 104 finished with value: 0.4259949099817691 and parameters: {'C': 128.0, 'gamma': 1.0}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:24:34,995]\u001b[0m Trial 105 finished with value: 0.8263801455415063 and parameters: {'C': 128.0, 'gamma': 0.0078125}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:25:04,667]\u001b[0m Trial 106 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:25:22,574]\u001b[0m Trial 107 finished with value: 0.8037563949656048 and parameters: {'C': 128.0, 'gamma': 0.001953125}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:25:52,148]\u001b[0m Trial 108 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:26:16,730]\u001b[0m Trial 109 finished with value: 0.836885090429929 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:26:43,974]\u001b[0m Trial 110 finished with value: 0.7247933182480576 and parameters: {'C': 0.25, 'gamma': 0.00390625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:27:13,634]\u001b[0m Trial 111 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:27:43,275]\u001b[0m Trial 112 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:28:12,878]\u001b[0m Trial 113 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:28:42,257]\u001b[0m Trial 114 finished with value: 0.47887219380480095 and parameters: {'C': 0.0625, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:28:59,908]\u001b[0m Trial 115 finished with value: 0.8097881368130835 and parameters: {'C': 128.0, 'gamma': 0.0009765625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:29:33,919]\u001b[0m Trial 116 finished with value: 0.3814109693472025 and parameters: {'C': 0.0078125, 'gamma': 0.0625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:30:04,334]\u001b[0m Trial 117 finished with value: 0.8365962128654333 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:30:26,223]\u001b[0m Trial 118 finished with value: 0.796862324561999 and parameters: {'C': 128.0, 'gamma': 3.0517578125e-05}. Best is trial 60 with value: 0.8380668800853919.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:30:50,732]\u001b[0m Trial 119 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:31:19,848]\u001b[0m Trial 120 finished with value: 0.4851626701106567 and parameters: {'C': 2.0, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:31:49,436]\u001b[0m Trial 121 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:32:24,591]\u001b[0m Trial 122 finished with value: 0.46364108883892124 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:32:54,272]\u001b[0m Trial 123 finished with value: 0.838029382768379 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:33:22,698]\u001b[0m Trial 124 finished with value: 0.6989140820682194 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:33:51,833]\u001b[0m Trial 125 finished with value: 0.49106687235681673 and parameters: {'C': 4.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:34:16,362]\u001b[0m Trial 126 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:34:41,060]\u001b[0m Trial 127 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:35:15,986]\u001b[0m Trial 128 finished with value: 0.4466721004223074 and parameters: {'C': 2.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:35:40,512]\u001b[0m Trial 129 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:36:05,055]\u001b[0m Trial 130 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:36:29,606]\u001b[0m Trial 131 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:37:04,698]\u001b[0m Trial 132 finished with value: 0.40709611652627603 and parameters: {'C': 2.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:37:29,323]\u001b[0m Trial 133 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:37:53,831]\u001b[0m Trial 134 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:38:18,420]\u001b[0m Trial 135 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:38:46,718]\u001b[0m Trial 136 finished with value: 0.6696539240143199 and parameters: {'C': 2.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:39:21,664]\u001b[0m Trial 137 finished with value: 0.640792410529665 and parameters: {'C': 2.0, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:39:46,214]\u001b[0m Trial 138 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:40:22,769]\u001b[0m Trial 139 finished with value: 0.4060971924287459 and parameters: {'C': 2.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:40:58,016]\u001b[0m Trial 140 finished with value: 0.4060971924287459 and parameters: {'C': 2.0, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:41:22,563]\u001b[0m Trial 141 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:41:47,165]\u001b[0m Trial 142 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:42:11,692]\u001b[0m Trial 143 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 18:42:36,255]\u001b[0m Trial 144 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:43:00,875]\u001b[0m Trial 145 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:43:26,951]\u001b[0m Trial 146 finished with value: 0.7407202535312497 and parameters: {'C': 2.0, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:43:51,548]\u001b[0m Trial 147 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:44:16,130]\u001b[0m Trial 148 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:44:40,703]\u001b[0m Trial 149 finished with value: 0.8464827775814934 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 150.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_2 = lambda trial: objective_svm_CV(trial, X_trainSet2, Y_trainSet2, Y_trainSet2_class)\n",
    "study_svm.optimize(func_svm_2, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b15b0ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T16:41:24.999399Z",
     "iopub.status.busy": "2023-01-15T16:41:24.999292Z",
     "iopub.status.idle": "2023-01-15T16:41:28.685141Z",
     "shell.execute_reply": "2023-01-15T16:41:28.684709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2\n",
      "0                    TP  328.000000  338.000000  322.000000\n",
      "1                    TN  176.000000  169.000000  171.000000\n",
      "2                    FP   48.000000   65.000000   53.000000\n",
      "3                    FN   43.000000   23.000000   49.000000\n",
      "4              Accuracy    0.847059    0.852101    0.828571\n",
      "5             Precision    0.872340    0.838710    0.858667\n",
      "6           Sensitivity    0.884097    0.936288    0.867925\n",
      "7           Specificity    0.785700    0.722200    0.763400\n",
      "8              F1 score    0.878179    0.884817    0.863271\n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259\n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771\n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659\n",
      "12                  MCC    0.672895    0.688052    0.633624\n",
      "13                  NPV    0.803700    0.880200    0.777300\n",
      "14              ROC_AUC    0.834906    0.829255    0.815659\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_2 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_2.fit(X_trainSet2,Y_trainSet2,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_2 = optimized_svm_2.predict(X_testSet2)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet2, y_pred_svm_2)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet2, y_pred_svm_2)\n",
    "Precision = precision_score(Y_testSet2, y_pred_svm_2)\n",
    "Sensitivity = recall_score(Y_testSet2, y_pred_svm_2)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet2, y_pred_svm_2)      \n",
    "f1_scores_W = f1_score(Y_testSet2, y_pred_svm_2, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet2, y_pred_svm_2, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet2, y_pred_svm_2)\n",
    "MCC = matthews_corrcoef(Y_testSet2, y_pred_svm_2)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet2, y_pred_svm_2)\n",
    "    \n",
    "\n",
    "Set2 = pd.DataFrame({'Set2':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set2'] = Set2\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5f35dfc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T16:41:28.686930Z",
     "iopub.status.busy": "2023-01-15T16:41:28.686821Z",
     "iopub.status.idle": "2023-01-15T17:05:00.334152Z",
     "shell.execute_reply": "2023-01-15T17:05:00.333727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 18:45:05,482]\u001b[0m Trial 150 finished with value: 0.8271327456241042 and parameters: {'C': 2.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:45:29,206]\u001b[0m Trial 151 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:45:53,013]\u001b[0m Trial 152 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:46:28,299]\u001b[0m Trial 153 finished with value: 0.4235648043050209 and parameters: {'C': 2.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:46:52,229]\u001b[0m Trial 154 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:47:16,087]\u001b[0m Trial 155 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:47:38,453]\u001b[0m Trial 156 finished with value: 0.7920853723824963 and parameters: {'C': 2.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:48:02,312]\u001b[0m Trial 157 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:48:23,701]\u001b[0m Trial 158 finished with value: 0.8116226889874077 and parameters: {'C': 2.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:48:47,562]\u001b[0m Trial 159 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:49:11,388]\u001b[0m Trial 160 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:49:35,175]\u001b[0m Trial 161 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:49:58,979]\u001b[0m Trial 162 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:50:22,784]\u001b[0m Trial 163 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:50:46,908]\u001b[0m Trial 164 finished with value: 0.7617756639209959 and parameters: {'C': 2.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:51:21,841]\u001b[0m Trial 165 finished with value: 0.7983197076069483 and parameters: {'C': 2.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:51:45,655]\u001b[0m Trial 166 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:52:09,453]\u001b[0m Trial 167 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:52:33,259]\u001b[0m Trial 168 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:53:08,314]\u001b[0m Trial 169 finished with value: 0.4543322120416381 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:53:32,143]\u001b[0m Trial 170 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:53:55,924]\u001b[0m Trial 171 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:54:19,741]\u001b[0m Trial 172 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:54:45,044]\u001b[0m Trial 173 finished with value: 0.8102015012804891 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:55:15,096]\u001b[0m Trial 174 finished with value: 0.38100327888982694 and parameters: {'C': 2.0, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:55:38,853]\u001b[0m Trial 175 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:56:08,154]\u001b[0m Trial 176 finished with value: 0.38100327888982694 and parameters: {'C': 0.015625, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:56:32,076]\u001b[0m Trial 177 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:57:01,559]\u001b[0m Trial 178 finished with value: 0.38100327888982694 and parameters: {'C': 2.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:57:31,192]\u001b[0m Trial 179 finished with value: 0.8216605534378253 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:58:05,000]\u001b[0m Trial 180 finished with value: 0.38100327888982694 and parameters: {'C': 0.03125, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:58:28,804]\u001b[0m Trial 181 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:58:52,629]\u001b[0m Trial 182 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:59:16,471]\u001b[0m Trial 183 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 18:59:40,313]\u001b[0m Trial 184 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:00:15,680]\u001b[0m Trial 185 finished with value: 0.4036423644705587 and parameters: {'C': 2.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:00:42,537]\u001b[0m Trial 186 finished with value: 0.7678553149075008 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:01:10,476]\u001b[0m Trial 187 finished with value: 0.6646522978113572 and parameters: {'C': 2.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:01:34,776]\u001b[0m Trial 188 finished with value: 0.8278416119027415 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:02:09,893]\u001b[0m Trial 189 finished with value: 0.636168843207576 and parameters: {'C': 2.0, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:02:45,592]\u001b[0m Trial 190 finished with value: 0.4036423644705587 and parameters: {'C': 2.0, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:03:09,469]\u001b[0m Trial 191 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:03:40,038]\u001b[0m Trial 192 finished with value: 0.38100327888982694 and parameters: {'C': 0.0078125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:04:09,535]\u001b[0m Trial 193 finished with value: 0.49547253640023026 and parameters: {'C': 0.0625, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:04:33,544]\u001b[0m Trial 194 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:05:03,122]\u001b[0m Trial 195 finished with value: 0.8205414374356839 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:05:23,837]\u001b[0m Trial 196 finished with value: 0.8235112128511842 and parameters: {'C': 4.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:05:47,625]\u001b[0m Trial 197 finished with value: 0.8263519870394699 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:06:17,677]\u001b[0m Trial 198 finished with value: 0.38100327888982694 and parameters: {'C': 0.125, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:06:54,337]\u001b[0m Trial 199 finished with value: 0.4036423644705587 and parameters: {'C': 32.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 200.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_3 = lambda trial: objective_svm_CV(trial, X_trainSet3, Y_trainSet3, Y_trainSet3_class)\n",
    "study_svm.optimize(func_svm_3, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7fb9781c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:05:00.335753Z",
     "iopub.status.busy": "2023-01-15T17:05:00.335644Z",
     "iopub.status.idle": "2023-01-15T17:05:04.108805Z",
     "shell.execute_reply": "2023-01-15T17:05:04.108369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000\n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000\n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000\n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000\n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143\n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155\n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786\n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100\n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039\n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171\n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101\n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459\n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742\n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900\n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459\n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_3 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_3.fit(X_trainSet3,Y_trainSet3,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_3 = optimized_svm_3.predict(X_testSet3)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet3, y_pred_svm_3)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet3, y_pred_svm_3)\n",
    "Precision = precision_score(Y_testSet3, y_pred_svm_3)\n",
    "Sensitivity = recall_score(Y_testSet3, y_pred_svm_3)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet3, y_pred_svm_3)      \n",
    "f1_scores_W = f1_score(Y_testSet3, y_pred_svm_3, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet3, y_pred_svm_3, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet3, y_pred_svm_3)\n",
    "MCC = matthews_corrcoef(Y_testSet3, y_pred_svm_3)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet3, y_pred_svm_3)\n",
    "    \n",
    "\n",
    "Set3 = pd.DataFrame({'Set3':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set3'] = Set3\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4b2acbab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:05:04.110427Z",
     "iopub.status.busy": "2023-01-15T17:05:04.110312Z",
     "iopub.status.idle": "2023-01-15T17:28:20.428889Z",
     "shell.execute_reply": "2023-01-15T17:28:20.428549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:07:21,734]\u001b[0m Trial 200 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:07:45,978]\u001b[0m Trial 201 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:08:11,299]\u001b[0m Trial 202 finished with value: 0.8041578518193064 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:08:35,467]\u001b[0m Trial 203 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:08:58,110]\u001b[0m Trial 204 finished with value: 0.7912527426852288 and parameters: {'C': 2.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:09:33,308]\u001b[0m Trial 205 finished with value: 0.42786331970711533 and parameters: {'C': 2.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:10:03,433]\u001b[0m Trial 206 finished with value: 0.381611529060262 and parameters: {'C': 0.015625, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:10:27,691]\u001b[0m Trial 207 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:10:57,892]\u001b[0m Trial 208 finished with value: 0.8255355388830619 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:11:27,679]\u001b[0m Trial 209 finished with value: 0.381611529060262 and parameters: {'C': 0.03125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:11:51,868]\u001b[0m Trial 210 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:12:15,942]\u001b[0m Trial 211 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:12:37,365]\u001b[0m Trial 212 finished with value: 0.8103149597092095 and parameters: {'C': 2.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:13:01,468]\u001b[0m Trial 213 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:13:25,525]\u001b[0m Trial 214 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:13:59,706]\u001b[0m Trial 215 finished with value: 0.7966668797695671 and parameters: {'C': 1.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:14:23,751]\u001b[0m Trial 216 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:14:53,617]\u001b[0m Trial 217 finished with value: 0.381611529060262 and parameters: {'C': 0.0625, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:15:17,741]\u001b[0m Trial 218 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:15:41,827]\u001b[0m Trial 219 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:16:09,269]\u001b[0m Trial 220 finished with value: 0.381611529060262 and parameters: {'C': 0.0078125, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:16:36,051]\u001b[0m Trial 221 finished with value: 0.7668018739957316 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:17:00,101]\u001b[0m Trial 222 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:17:24,158]\u001b[0m Trial 223 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:17:53,996]\u001b[0m Trial 224 finished with value: 0.8246145854117211 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:18:23,074]\u001b[0m Trial 225 finished with value: 0.504414893029701 and parameters: {'C': 2.0, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:18:58,282]\u001b[0m Trial 226 finished with value: 0.4626327173965037 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:19:26,563]\u001b[0m Trial 227 finished with value: 0.6903196570065553 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:19:55,875]\u001b[0m Trial 228 finished with value: 0.8304297463606671 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:20:19,931]\u001b[0m Trial 229 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:20:55,152]\u001b[0m Trial 230 finished with value: 0.4418984701166509 and parameters: {'C': 32.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:21:25,063]\u001b[0m Trial 231 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:21:54,917]\u001b[0m Trial 232 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:22:24,736]\u001b[0m Trial 233 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:22:48,824]\u001b[0m Trial 234 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:23:12,849]\u001b[0m Trial 235 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:23:47,816]\u001b[0m Trial 236 finished with value: 0.4171829006567741 and parameters: {'C': 128.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:24:17,769]\u001b[0m Trial 237 finished with value: 0.381611529060262 and parameters: {'C': 0.5, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:24:41,738]\u001b[0m Trial 238 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:25:05,678]\u001b[0m Trial 239 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:25:39,311]\u001b[0m Trial 240 finished with value: 0.381611529060262 and parameters: {'C': 0.015625, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:26:08,910]\u001b[0m Trial 241 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:26:38,510]\u001b[0m Trial 242 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:26:56,976]\u001b[0m Trial 243 finished with value: 0.8067462861840993 and parameters: {'C': 128.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:27:26,597]\u001b[0m Trial 244 finished with value: 0.8227273576675234 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:28:01,498]\u001b[0m Trial 245 finished with value: 0.6379012685660982 and parameters: {'C': 2.0, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:28:31,268]\u001b[0m Trial 246 finished with value: 0.8255355388830619 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:29:00,640]\u001b[0m Trial 247 finished with value: 0.381611529060262 and parameters: {'C': 0.03125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:29:24,592]\u001b[0m Trial 248 finished with value: 0.8304526920416141 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:30:01,003]\u001b[0m Trial 249 finished with value: 0.4171829006567741 and parameters: {'C': 128.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 250.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_4 = lambda trial: objective_svm_CV(trial, X_trainSet4, Y_trainSet4, Y_trainSet4_class)\n",
    "study_svm.optimize(func_svm_4, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c80f9415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:28:20.430293Z",
     "iopub.status.busy": "2023-01-15T17:28:20.430185Z",
     "iopub.status.idle": "2023-01-15T17:28:24.107486Z",
     "shell.execute_reply": "2023-01-15T17:28:24.107129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4  \n",
      "0   345.000000  \n",
      "1   166.000000  \n",
      "2    59.000000  \n",
      "3    25.000000  \n",
      "4     0.858824  \n",
      "5     0.853960  \n",
      "6     0.932432  \n",
      "7     0.737800  \n",
      "8     0.891473  \n",
      "9     0.856155  \n",
      "10    0.844775  \n",
      "11    0.835105  \n",
      "12    0.696139  \n",
      "13    0.869100  \n",
      "14    0.835105  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_4 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_4.fit(X_trainSet4,Y_trainSet4,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_4 = optimized_svm_4.predict(X_testSet4)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet4, y_pred_svm_4)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet4, y_pred_svm_4)\n",
    "Precision = precision_score(Y_testSet4, y_pred_svm_4)\n",
    "Sensitivity = recall_score(Y_testSet4, y_pred_svm_4)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet4, y_pred_svm_4)      \n",
    "f1_scores_W = f1_score(Y_testSet4, y_pred_svm_4, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet4, y_pred_svm_4, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet4, y_pred_svm_4)\n",
    "MCC = matthews_corrcoef(Y_testSet4, y_pred_svm_4)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet4, y_pred_svm_4)\n",
    "    \n",
    "\n",
    "Set4 = pd.DataFrame({'Set4':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set4'] = Set4\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92e04028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:28:24.109024Z",
     "iopub.status.busy": "2023-01-15T17:28:24.108915Z",
     "iopub.status.idle": "2023-01-15T17:50:34.895102Z",
     "shell.execute_reply": "2023-01-15T17:50:34.894200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:30:25,911]\u001b[0m Trial 250 finished with value: 0.8161192945751681 and parameters: {'C': 2.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:30:51,855]\u001b[0m Trial 251 finished with value: 0.72196840125225 and parameters: {'C': 2.0, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:31:16,161]\u001b[0m Trial 252 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:31:45,921]\u001b[0m Trial 253 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:32:10,299]\u001b[0m Trial 254 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:32:34,910]\u001b[0m Trial 255 finished with value: 0.8145045337992398 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:32:59,234]\u001b[0m Trial 256 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:33:32,696]\u001b[0m Trial 257 finished with value: 0.3816305977507693 and parameters: {'C': 0.0625, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:33:59,550]\u001b[0m Trial 258 finished with value: 0.7703564714150263 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:34:22,057]\u001b[0m Trial 259 finished with value: 0.7839905531185507 and parameters: {'C': 2.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:34:40,976]\u001b[0m Trial 260 finished with value: 0.7941360451958706 and parameters: {'C': 128.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:35:05,328]\u001b[0m Trial 261 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:35:29,667]\u001b[0m Trial 262 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:35:59,636]\u001b[0m Trial 263 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:36:34,443]\u001b[0m Trial 264 finished with value: 0.8029485883034304 and parameters: {'C': 16.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:36:59,021]\u001b[0m Trial 265 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:37:29,084]\u001b[0m Trial 266 finished with value: 0.3816305977507693 and parameters: {'C': 0.0078125, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:37:53,471]\u001b[0m Trial 267 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:38:17,891]\u001b[0m Trial 268 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:38:47,303]\u001b[0m Trial 269 finished with value: 0.8238455676144147 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:39:16,956]\u001b[0m Trial 270 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:39:46,760]\u001b[0m Trial 271 finished with value: 0.3816305977507693 and parameters: {'C': 0.125, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:40:21,591]\u001b[0m Trial 272 finished with value: 0.4586551903788026 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:40:46,016]\u001b[0m Trial 273 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:41:15,682]\u001b[0m Trial 274 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:41:40,025]\u001b[0m Trial 275 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:42:14,860]\u001b[0m Trial 276 finished with value: 0.44060305233576746 and parameters: {'C': 2.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:42:44,668]\u001b[0m Trial 277 finished with value: 0.3816305977507693 and parameters: {'C': 0.5, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:43:14,339]\u001b[0m Trial 278 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:43:38,215]\u001b[0m Trial 279 finished with value: 0.7573377946949927 and parameters: {'C': 32.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:44:02,575]\u001b[0m Trial 280 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:44:36,084]\u001b[0m Trial 281 finished with value: 0.3816305977507693 and parameters: {'C': 0.015625, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:45:00,511]\u001b[0m Trial 282 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:45:31,057]\u001b[0m Trial 283 finished with value: 0.8222131367719575 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:45:55,406]\u001b[0m Trial 284 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:46:30,135]\u001b[0m Trial 285 finished with value: 0.6252019897590329 and parameters: {'C': 128.0, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:47:03,764]\u001b[0m Trial 286 finished with value: 0.3816305977507693 and parameters: {'C': 0.03125, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:47:28,151]\u001b[0m Trial 287 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:47:52,580]\u001b[0m Trial 288 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:48:22,361]\u001b[0m Trial 289 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:48:55,001]\u001b[0m Trial 290 finished with value: 0.8178953360186998 and parameters: {'C': 2.0, 'gamma': 0.03125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:49:21,024]\u001b[0m Trial 291 finished with value: 0.72196840125225 and parameters: {'C': 2.0, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:49:57,745]\u001b[0m Trial 292 finished with value: 0.41260978254211444 and parameters: {'C': 1.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:50:27,539]\u001b[0m Trial 293 finished with value: 0.8179614419195893 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:50:55,493]\u001b[0m Trial 294 finished with value: 0.6536885249480522 and parameters: {'C': 2.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:51:22,232]\u001b[0m Trial 295 finished with value: 0.7703564714150263 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:51:51,164]\u001b[0m Trial 296 finished with value: 0.4893067658145557 and parameters: {'C': 0.0625, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:52:15,466]\u001b[0m Trial 297 finished with value: 0.8245144738636551 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:52:50,318]\u001b[0m Trial 298 finished with value: 0.4306461685362636 and parameters: {'C': 2.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:53:20,026]\u001b[0m Trial 299 finished with value: 0.8179614419195893 and parameters: {'C': 64.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 300.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_5 = lambda trial: objective_svm_CV(trial, X_trainSet5, Y_trainSet5, Y_trainSet5_class)\n",
    "study_svm.optimize(func_svm_5, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dae92b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:50:34.896960Z",
     "iopub.status.busy": "2023-01-15T17:50:34.896856Z",
     "iopub.status.idle": "2023-01-15T17:50:38.515809Z",
     "shell.execute_reply": "2023-01-15T17:50:38.515456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4        Set5  \n",
      "0   345.000000  343.000000  \n",
      "1   166.000000  171.000000  \n",
      "2    59.000000   54.000000  \n",
      "3    25.000000   27.000000  \n",
      "4     0.858824    0.863866  \n",
      "5     0.853960    0.863980  \n",
      "6     0.932432    0.927027  \n",
      "7     0.737800    0.760000  \n",
      "8     0.891473    0.894394  \n",
      "9     0.856155    0.861917  \n",
      "10    0.844775    0.851452  \n",
      "11    0.835105    0.843514  \n",
      "12    0.696139    0.707030  \n",
      "13    0.869100    0.863600  \n",
      "14    0.835105    0.843514  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_5 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_5.fit(X_trainSet5,Y_trainSet5,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_5 = optimized_svm_5.predict(X_testSet5)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet5, y_pred_svm_5)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet5, y_pred_svm_5)\n",
    "Precision = precision_score(Y_testSet5, y_pred_svm_5)\n",
    "Sensitivity = recall_score(Y_testSet5, y_pred_svm_5)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet5, y_pred_svm_5)      \n",
    "f1_scores_W = f1_score(Y_testSet5, y_pred_svm_5, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet5, y_pred_svm_5, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet5, y_pred_svm_5)\n",
    "MCC = matthews_corrcoef(Y_testSet5, y_pred_svm_5)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet5, y_pred_svm_5)\n",
    "    \n",
    "\n",
    "Set5 = pd.DataFrame({'Set5':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set5'] = Set5\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b346e27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T17:50:38.517355Z",
     "iopub.status.busy": "2023-01-15T17:50:38.517249Z",
     "iopub.status.idle": "2023-01-15T18:13:42.502968Z",
     "shell.execute_reply": "2023-01-15T18:13:42.502624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 19:53:52,946]\u001b[0m Trial 300 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:54:22,897]\u001b[0m Trial 301 finished with value: 0.38275376827529983 and parameters: {'C': 0.0078125, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:54:46,772]\u001b[0m Trial 302 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:55:10,596]\u001b[0m Trial 303 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:55:40,349]\u001b[0m Trial 304 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:56:01,553]\u001b[0m Trial 305 finished with value: 0.8099488434432311 and parameters: {'C': 2.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:56:33,106]\u001b[0m Trial 306 finished with value: 0.8300927605032878 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:57:07,802]\u001b[0m Trial 307 finished with value: 0.8062152490673828 and parameters: {'C': 2.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:57:36,963]\u001b[0m Trial 308 finished with value: 0.828524377993473 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:58:05,071]\u001b[0m Trial 309 finished with value: 0.6842749468239582 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:58:23,150]\u001b[0m Trial 310 finished with value: 0.8026939600750428 and parameters: {'C': 128.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:58:47,075]\u001b[0m Trial 311 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:59:22,158]\u001b[0m Trial 312 finished with value: 0.4556265848475561 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 19:59:46,046]\u001b[0m Trial 313 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:00:15,741]\u001b[0m Trial 314 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:00:46,396]\u001b[0m Trial 315 finished with value: 0.8267160558986166 and parameters: {'C': 32.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:01:10,309]\u001b[0m Trial 316 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:01:39,985]\u001b[0m Trial 317 finished with value: 0.38275376827529983 and parameters: {'C': 0.5, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:02:03,886]\u001b[0m Trial 318 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:02:37,482]\u001b[0m Trial 319 finished with value: 0.38275376827529983 and parameters: {'C': 0.015625, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:03:07,155]\u001b[0m Trial 320 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:03:36,794]\u001b[0m Trial 321 finished with value: 0.38275376827529983 and parameters: {'C': 2.0, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:04:04,566]\u001b[0m Trial 322 finished with value: 0.6667995259436232 and parameters: {'C': 8.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:04:28,463]\u001b[0m Trial 323 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:04:52,314]\u001b[0m Trial 324 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:05:22,039]\u001b[0m Trial 325 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:05:45,817]\u001b[0m Trial 326 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:06:19,186]\u001b[0m Trial 327 finished with value: 0.38275376827529983 and parameters: {'C': 0.03125, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:06:43,068]\u001b[0m Trial 328 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:07:01,534]\u001b[0m Trial 329 finished with value: 0.8230099161013479 and parameters: {'C': 128.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:07:36,423]\u001b[0m Trial 330 finished with value: 0.41013197362318865 and parameters: {'C': 2.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:08:00,132]\u001b[0m Trial 331 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:08:35,237]\u001b[0m Trial 332 finished with value: 0.40556579601916243 and parameters: {'C': 128.0, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:09:06,389]\u001b[0m Trial 333 finished with value: 0.8209885783364426 and parameters: {'C': 1.0, 'gamma': 0.03125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:09:41,204]\u001b[0m Trial 334 finished with value: 0.38275376827529983 and parameters: {'C': 0.25, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:10:10,979]\u001b[0m Trial 335 finished with value: 0.38275376827529983 and parameters: {'C': 0.0625, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:10:34,610]\u001b[0m Trial 336 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:10:58,294]\u001b[0m Trial 337 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:11:22,167]\u001b[0m Trial 338 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:11:52,524]\u001b[0m Trial 339 finished with value: 0.8258952950436376 and parameters: {'C': 64.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:12:22,465]\u001b[0m Trial 340 finished with value: 0.38275376827529983 and parameters: {'C': 0.0078125, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:12:57,479]\u001b[0m Trial 341 finished with value: 0.42302334888380566 and parameters: {'C': 128.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:13:28,787]\u001b[0m Trial 342 finished with value: 0.8300927605032878 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:13:50,996]\u001b[0m Trial 343 finished with value: 0.7925885754357582 and parameters: {'C': 2.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 20:14:14,800]\u001b[0m Trial 344 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:14:44,418]\u001b[0m Trial 345 finished with value: 0.8239530785298204 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:15:13,438]\u001b[0m Trial 346 finished with value: 0.828524377993473 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:15:37,270]\u001b[0m Trial 347 finished with value: 0.8368090520808777 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:15:58,497]\u001b[0m Trial 348 finished with value: 0.8099488434432311 and parameters: {'C': 2.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:16:26,477]\u001b[0m Trial 349 finished with value: 0.6842749468239582 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 350.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_6 = lambda trial: objective_svm_CV(trial, X_trainSet6, Y_trainSet6, Y_trainSet6_class)\n",
    "study_svm.optimize(func_svm_6, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ed5a900c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:13:42.504649Z",
     "iopub.status.busy": "2023-01-15T18:13:42.504541Z",
     "iopub.status.idle": "2023-01-15T18:13:46.216083Z",
     "shell.execute_reply": "2023-01-15T18:13:46.215726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4        Set5        Set6  \n",
      "0   345.000000  343.000000  328.000000  \n",
      "1   166.000000  171.000000  175.000000  \n",
      "2    59.000000   54.000000   57.000000  \n",
      "3    25.000000   27.000000   35.000000  \n",
      "4     0.858824    0.863866    0.845378  \n",
      "5     0.853960    0.863980    0.851948  \n",
      "6     0.932432    0.927027    0.903581  \n",
      "7     0.737800    0.760000    0.754300  \n",
      "8     0.891473    0.894394    0.877005  \n",
      "9     0.856155    0.861917    0.843804  \n",
      "10    0.844775    0.851452    0.834430  \n",
      "11    0.835105    0.843514    0.828946  \n",
      "12    0.696139    0.707030    0.671447  \n",
      "13    0.869100    0.863600    0.833300  \n",
      "14    0.835105    0.843514    0.828946  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_6 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_6.fit(X_trainSet6,Y_trainSet6,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_6 = optimized_svm_6.predict(X_testSet6)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet6, y_pred_svm_6)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet6, y_pred_svm_6)\n",
    "Precision = precision_score(Y_testSet6, y_pred_svm_6)\n",
    "Sensitivity = recall_score(Y_testSet6, y_pred_svm_6)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet6, y_pred_svm_6)      \n",
    "f1_scores_W = f1_score(Y_testSet6, y_pred_svm_6, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet6, y_pred_svm_6, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet6, y_pred_svm_6)\n",
    "MCC = matthews_corrcoef(Y_testSet6, y_pred_svm_6)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet6, y_pred_svm_6)\n",
    "    \n",
    "\n",
    "Set6 = pd.DataFrame({'Set6':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set6'] = Set6\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "165e2c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:13:46.217679Z",
     "iopub.status.busy": "2023-01-15T18:13:46.217564Z",
     "iopub.status.idle": "2023-01-15T18:36:45.530059Z",
     "shell.execute_reply": "2023-01-15T18:36:45.529717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 20:17:04,562]\u001b[0m Trial 350 finished with value: 0.8054750882939151 and parameters: {'C': 128.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:17:28,750]\u001b[0m Trial 351 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:17:52,994]\u001b[0m Trial 352 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:18:17,423]\u001b[0m Trial 353 finished with value: 0.7721281447163518 and parameters: {'C': 2.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:18:47,001]\u001b[0m Trial 354 finished with value: 0.8177498239827672 and parameters: {'C': 32.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:19:22,074]\u001b[0m Trial 355 finished with value: 0.4659705708609157 and parameters: {'C': 128.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:19:47,731]\u001b[0m Trial 356 finished with value: 0.8087351494975865 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:20:11,947]\u001b[0m Trial 357 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:20:40,049]\u001b[0m Trial 358 finished with value: 0.38099875219444457 and parameters: {'C': 0.015625, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:21:04,242]\u001b[0m Trial 359 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:21:33,852]\u001b[0m Trial 360 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:22:03,568]\u001b[0m Trial 361 finished with value: 0.8208111047668949 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:22:38,578]\u001b[0m Trial 362 finished with value: 0.4424969986437497 and parameters: {'C': 2.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:23:08,499]\u001b[0m Trial 363 finished with value: 0.38099875219444457 and parameters: {'C': 0.03125, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:23:38,016]\u001b[0m Trial 364 finished with value: 0.38099875219444457 and parameters: {'C': 2.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:24:07,552]\u001b[0m Trial 365 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:24:31,797]\u001b[0m Trial 366 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:24:56,024]\u001b[0m Trial 367 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:25:20,256]\u001b[0m Trial 368 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:25:49,757]\u001b[0m Trial 369 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:26:24,880]\u001b[0m Trial 370 finished with value: 0.40894672681326816 and parameters: {'C': 1.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:26:53,195]\u001b[0m Trial 371 finished with value: 0.6462026397791482 and parameters: {'C': 2.0, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:27:26,825]\u001b[0m Trial 372 finished with value: 0.38099875219444457 and parameters: {'C': 0.25, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:28:00,252]\u001b[0m Trial 373 finished with value: 0.38099875219444457 and parameters: {'C': 0.0625, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:28:24,480]\u001b[0m Trial 374 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:28:54,014]\u001b[0m Trial 375 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:29:23,497]\u001b[0m Trial 376 finished with value: 0.8153341175100544 and parameters: {'C': 64.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:29:59,921]\u001b[0m Trial 377 finished with value: 0.40894672681326816 and parameters: {'C': 2.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:30:29,696]\u001b[0m Trial 378 finished with value: 0.38099875219444457 and parameters: {'C': 0.0078125, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:31:02,210]\u001b[0m Trial 379 finished with value: 0.821102670666418 and parameters: {'C': 2.0, 'gamma': 0.03125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:31:31,755]\u001b[0m Trial 380 finished with value: 0.8201561275750103 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:31:53,398]\u001b[0m Trial 381 finished with value: 0.8258865121138651 and parameters: {'C': 2.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:32:22,976]\u001b[0m Trial 382 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:32:47,048]\u001b[0m Trial 383 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:33:22,003]\u001b[0m Trial 384 finished with value: 0.43037531991731964 and parameters: {'C': 2.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:33:51,110]\u001b[0m Trial 385 finished with value: 0.8203573815113924 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:34:08,967]\u001b[0m Trial 386 finished with value: 0.7890609488271768 and parameters: {'C': 128.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:34:37,425]\u001b[0m Trial 387 finished with value: 0.6678839791514055 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:35:01,633]\u001b[0m Trial 388 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:35:25,846]\u001b[0m Trial 389 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:35:44,157]\u001b[0m Trial 390 finished with value: 0.7974904003456217 and parameters: {'C': 128.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:36:08,368]\u001b[0m Trial 391 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:36:37,973]\u001b[0m Trial 392 finished with value: 0.8177498239827672 and parameters: {'C': 32.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:37:12,498]\u001b[0m Trial 393 finished with value: 0.8048233148473518 and parameters: {'C': 2.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 20:37:38,155]\u001b[0m Trial 394 finished with value: 0.8087351494975865 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:38:02,541]\u001b[0m Trial 395 finished with value: 0.7721281447163518 and parameters: {'C': 2.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:38:32,047]\u001b[0m Trial 396 finished with value: 0.815763079948832 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:38:56,254]\u001b[0m Trial 397 finished with value: 0.8306608052438843 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:39:26,149]\u001b[0m Trial 398 finished with value: 0.38099875219444457 and parameters: {'C': 0.015625, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:39:55,997]\u001b[0m Trial 399 finished with value: 0.38099875219444457 and parameters: {'C': 2.0, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 400.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_7 = lambda trial: objective_svm_CV(trial, X_trainSet7, Y_trainSet7, Y_trainSet7_class)\n",
    "study_svm.optimize(func_svm_7, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3eeb8064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:36:45.531763Z",
     "iopub.status.busy": "2023-01-15T18:36:45.531656Z",
     "iopub.status.idle": "2023-01-15T18:36:49.182009Z",
     "shell.execute_reply": "2023-01-15T18:36:49.181657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4        Set5        Set6        Set7  \n",
      "0   345.000000  343.000000  328.000000  344.000000  \n",
      "1   166.000000  171.000000  175.000000  173.000000  \n",
      "2    59.000000   54.000000   57.000000   48.000000  \n",
      "3    25.000000   27.000000   35.000000   30.000000  \n",
      "4     0.858824    0.863866    0.845378    0.868908  \n",
      "5     0.853960    0.863980    0.851948    0.877551  \n",
      "6     0.932432    0.927027    0.903581    0.919786  \n",
      "7     0.737800    0.760000    0.754300    0.782800  \n",
      "8     0.891473    0.894394    0.877005    0.898172  \n",
      "9     0.856155    0.861917    0.843804    0.867665  \n",
      "10    0.844775    0.851452    0.834430    0.857105  \n",
      "11    0.835105    0.843514    0.828946    0.851296  \n",
      "12    0.696139    0.707030    0.671447    0.716051  \n",
      "13    0.869100    0.863600    0.833300    0.852200  \n",
      "14    0.835105    0.843514    0.828946    0.851296  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_7 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_7.fit(X_trainSet7,Y_trainSet7,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_7 = optimized_svm_7.predict(X_testSet7)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet7, y_pred_svm_7)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet7, y_pred_svm_7)\n",
    "Precision = precision_score(Y_testSet7, y_pred_svm_7)\n",
    "Sensitivity = recall_score(Y_testSet7, y_pred_svm_7)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet7, y_pred_svm_7)      \n",
    "f1_scores_W = f1_score(Y_testSet7, y_pred_svm_7, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet7, y_pred_svm_7, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet7, y_pred_svm_7)\n",
    "MCC = matthews_corrcoef(Y_testSet7, y_pred_svm_7)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet7, y_pred_svm_7)\n",
    "    \n",
    "\n",
    "Set7 = pd.DataFrame({'Set7':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set7'] = Set7\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92faaf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:36:49.183547Z",
     "iopub.status.busy": "2023-01-15T18:36:49.183439Z",
     "iopub.status.idle": "2023-01-15T18:59:07.025494Z",
     "shell.execute_reply": "2023-01-15T18:59:07.025150Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 20:40:28,423]\u001b[0m Trial 400 finished with value: 0.8256214657736445 and parameters: {'C': 8.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:41:03,254]\u001b[0m Trial 401 finished with value: 0.4591197278199374 and parameters: {'C': 128.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:41:32,686]\u001b[0m Trial 402 finished with value: 0.38198555429042685 and parameters: {'C': 0.03125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:41:56,501]\u001b[0m Trial 403 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:42:25,249]\u001b[0m Trial 404 finished with value: 0.5092066194969794 and parameters: {'C': 2.0, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:42:54,334]\u001b[0m Trial 405 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:43:18,087]\u001b[0m Trial 406 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:43:41,945]\u001b[0m Trial 407 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:44:16,857]\u001b[0m Trial 408 finished with value: 0.40266358843027605 and parameters: {'C': 1.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:44:51,643]\u001b[0m Trial 409 finished with value: 0.4328106203007689 and parameters: {'C': 2.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:45:11,881]\u001b[0m Trial 410 finished with value: 0.8057814764989357 and parameters: {'C': 128.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:45:35,586]\u001b[0m Trial 411 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:46:02,201]\u001b[0m Trial 412 finished with value: 0.7712694485362999 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:46:36,935]\u001b[0m Trial 413 finished with value: 0.6355173010871781 and parameters: {'C': 64.0, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:47:00,717]\u001b[0m Trial 414 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:47:30,750]\u001b[0m Trial 415 finished with value: 0.38198555429042685 and parameters: {'C': 0.0625, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:48:00,085]\u001b[0m Trial 416 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:48:31,366]\u001b[0m Trial 417 finished with value: 0.38198555429042685 and parameters: {'C': 0.0078125, 'gamma': 0.03125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:48:55,421]\u001b[0m Trial 418 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:49:30,651]\u001b[0m Trial 419 finished with value: 0.40266358843027605 and parameters: {'C': 2.0, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:49:59,859]\u001b[0m Trial 420 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:50:36,278]\u001b[0m Trial 421 finished with value: 0.40266358843027605 and parameters: {'C': 2.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:51:00,051]\u001b[0m Trial 422 finished with value: 0.7695079257599164 and parameters: {'C': 4.0, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:51:23,979]\u001b[0m Trial 423 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:51:53,211]\u001b[0m Trial 424 finished with value: 0.8247331188498028 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:52:21,410]\u001b[0m Trial 425 finished with value: 0.6868734251945678 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:52:42,614]\u001b[0m Trial 426 finished with value: 0.8186011120462423 and parameters: {'C': 2.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:53:11,967]\u001b[0m Trial 427 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:53:46,959]\u001b[0m Trial 428 finished with value: 0.41723913278422575 and parameters: {'C': 2.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:54:05,212]\u001b[0m Trial 429 finished with value: 0.8157553288418894 and parameters: {'C': 32.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:54:29,325]\u001b[0m Trial 430 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:54:58,589]\u001b[0m Trial 431 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:55:23,538]\u001b[0m Trial 432 finished with value: 0.8110004559278737 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:55:47,468]\u001b[0m Trial 433 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:56:08,778]\u001b[0m Trial 434 finished with value: 0.8077049782410137 and parameters: {'C': 2.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:56:37,938]\u001b[0m Trial 435 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:57:11,823]\u001b[0m Trial 436 finished with value: 0.38198555429042685 and parameters: {'C': 0.015625, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:57:35,714]\u001b[0m Trial 437 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:57:56,108]\u001b[0m Trial 438 finished with value: 0.8087673837082985 and parameters: {'C': 8.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:58:19,972]\u001b[0m Trial 439 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:58:43,846]\u001b[0m Trial 440 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:59:18,755]\u001b[0m Trial 441 finished with value: 0.4591197278199374 and parameters: {'C': 128.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 20:59:42,732]\u001b[0m Trial 442 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:00:11,244]\u001b[0m Trial 443 finished with value: 0.38198555429042685 and parameters: {'C': 0.03125, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 21:00:35,101]\u001b[0m Trial 444 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:01:04,383]\u001b[0m Trial 445 finished with value: 0.8265671977763256 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:01:33,197]\u001b[0m Trial 446 finished with value: 0.5092066194969794 and parameters: {'C': 2.0, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:01:57,020]\u001b[0m Trial 447 finished with value: 0.8313256792618462 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:02:21,065]\u001b[0m Trial 448 finished with value: 0.8210536055757881 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:02:54,711]\u001b[0m Trial 449 finished with value: 0.38198555429042685 and parameters: {'C': 0.25, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 450.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_8 = lambda trial: objective_svm_CV(trial, X_trainSet8, Y_trainSet8, Y_trainSet8_class)\n",
    "study_svm.optimize(func_svm_8, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "361958ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:59:07.027076Z",
     "iopub.status.busy": "2023-01-15T18:59:07.026968Z",
     "iopub.status.idle": "2023-01-15T18:59:10.733077Z",
     "shell.execute_reply": "2023-01-15T18:59:10.732729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8  \n",
      "0   345.000000  343.000000  328.000000  344.000000  342.000000  \n",
      "1   166.000000  171.000000  175.000000  173.000000  159.000000  \n",
      "2    59.000000   54.000000   57.000000   48.000000   68.000000  \n",
      "3    25.000000   27.000000   35.000000   30.000000   26.000000  \n",
      "4     0.858824    0.863866    0.845378    0.868908    0.842017  \n",
      "5     0.853960    0.863980    0.851948    0.877551    0.834146  \n",
      "6     0.932432    0.927027    0.903581    0.919786    0.929348  \n",
      "7     0.737800    0.760000    0.754300    0.782800    0.700400  \n",
      "8     0.891473    0.894394    0.877005    0.898172    0.879177  \n",
      "9     0.856155    0.861917    0.843804    0.867665    0.838229  \n",
      "10    0.844775    0.851452    0.834430    0.857105    0.825511  \n",
      "11    0.835105    0.843514    0.828946    0.851296    0.814894  \n",
      "12    0.696139    0.707030    0.671447    0.716051    0.660927  \n",
      "13    0.869100    0.863600    0.833300    0.852200    0.859500  \n",
      "14    0.835105    0.843514    0.828946    0.851296    0.814894  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_8 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_8.fit(X_trainSet8,Y_trainSet8,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_8 = optimized_svm_8.predict(X_testSet8)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet8, y_pred_svm_8)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet8, y_pred_svm_8)\n",
    "Precision = precision_score(Y_testSet8, y_pred_svm_8)\n",
    "Sensitivity = recall_score(Y_testSet8, y_pred_svm_8)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet8, y_pred_svm_8)      \n",
    "f1_scores_W = f1_score(Y_testSet8, y_pred_svm_8, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet8, y_pred_svm_8, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet8, y_pred_svm_8)\n",
    "MCC = matthews_corrcoef(Y_testSet8, y_pred_svm_8)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet8, y_pred_svm_8)\n",
    "    \n",
    "\n",
    "Set8 = pd.DataFrame({'Set8':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set8'] = Set8\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d15fe2a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T18:59:10.734596Z",
     "iopub.status.busy": "2023-01-15T18:59:10.734475Z",
     "iopub.status.idle": "2023-01-15T19:21:39.497762Z",
     "shell.execute_reply": "2023-01-15T19:21:39.497418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 21:03:27,821]\u001b[0m Trial 450 finished with value: 0.37885438617570827 and parameters: {'C': 2.0, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:03:57,255]\u001b[0m Trial 451 finished with value: 0.8254943468030342 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:04:21,265]\u001b[0m Trial 452 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:04:45,143]\u001b[0m Trial 453 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:05:19,995]\u001b[0m Trial 454 finished with value: 0.4160921839212398 and parameters: {'C': 128.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:05:43,849]\u001b[0m Trial 455 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:06:17,337]\u001b[0m Trial 456 finished with value: 0.37885438617570827 and parameters: {'C': 0.0625, 'gamma': 0.125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:06:47,147]\u001b[0m Trial 457 finished with value: 0.37885438617570827 and parameters: {'C': 0.0078125, 'gamma': 0.000244140625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:07:11,260]\u001b[0m Trial 458 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:07:46,286]\u001b[0m Trial 459 finished with value: 0.4113533303768159 and parameters: {'C': 64.0, 'gamma': 4.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:08:15,900]\u001b[0m Trial 460 finished with value: 0.8259064896910097 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:08:49,575]\u001b[0m Trial 461 finished with value: 0.8259302112296775 and parameters: {'C': 128.0, 'gamma': 0.03125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:09:13,479]\u001b[0m Trial 462 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:09:49,762]\u001b[0m Trial 463 finished with value: 0.4113533303768159 and parameters: {'C': 2.0, 'gamma': 8.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:10:18,238]\u001b[0m Trial 464 finished with value: 0.6900238524225786 and parameters: {'C': 0.125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:10:47,411]\u001b[0m Trial 465 finished with value: 0.8300603081354225 and parameters: {'C': 4.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:11:13,534]\u001b[0m Trial 466 finished with value: 0.7277016076453992 and parameters: {'C': 2.0, 'gamma': 0.00048828125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:11:43,068]\u001b[0m Trial 467 finished with value: 0.8254943468030342 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:12:09,925]\u001b[0m Trial 468 finished with value: 0.8198537141341242 and parameters: {'C': 32.0, 'gamma': 0.0078125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:12:33,899]\u001b[0m Trial 469 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:12:59,437]\u001b[0m Trial 470 finished with value: 0.812997671871815 and parameters: {'C': 0.5, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:13:22,096]\u001b[0m Trial 471 finished with value: 0.7961521929039056 and parameters: {'C': 2.0, 'gamma': 0.001953125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:13:57,084]\u001b[0m Trial 472 finished with value: 0.4268128958129716 and parameters: {'C': 128.0, 'gamma': 1.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:14:21,039]\u001b[0m Trial 473 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:14:51,278]\u001b[0m Trial 474 finished with value: 0.37885438617570827 and parameters: {'C': 0.015625, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:15:15,172]\u001b[0m Trial 475 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:15:44,739]\u001b[0m Trial 476 finished with value: 0.8254943468030342 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:16:04,411]\u001b[0m Trial 477 finished with value: 0.823849155431685 and parameters: {'C': 8.0, 'gamma': 0.00390625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:16:38,987]\u001b[0m Trial 478 finished with value: 0.8063324828454336 and parameters: {'C': 2.0, 'gamma': 0.0625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:17:03,014]\u001b[0m Trial 479 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:17:26,901]\u001b[0m Trial 480 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:17:56,695]\u001b[0m Trial 481 finished with value: 0.37885438617570827 and parameters: {'C': 0.03125, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:18:14,481]\u001b[0m Trial 482 finished with value: 0.7962443516909383 and parameters: {'C': 128.0, 'gamma': 0.0009765625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:18:38,508]\u001b[0m Trial 483 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:19:13,372]\u001b[0m Trial 484 finished with value: 0.4623676870303224 and parameters: {'C': 2.0, 'gamma': 0.25}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:19:37,683]\u001b[0m Trial 485 finished with value: 0.8286077914820315 and parameters: {'C': 1.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:20:07,213]\u001b[0m Trial 486 finished with value: 0.8254943468030342 and parameters: {'C': 128.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:20:37,390]\u001b[0m Trial 487 finished with value: 0.37885438617570827 and parameters: {'C': 2.0, 'gamma': 3.0517578125e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:21:04,411]\u001b[0m Trial 488 finished with value: 0.7760959442637 and parameters: {'C': 0.25, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:21:28,335]\u001b[0m Trial 489 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:21:49,062]\u001b[0m Trial 490 finished with value: 0.8027093197556538 and parameters: {'C': 64.0, 'gamma': 0.0001220703125}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:22:13,051]\u001b[0m Trial 491 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:22:48,092]\u001b[0m Trial 492 finished with value: 0.4366826978263493 and parameters: {'C': 128.0, 'gamma': 0.5}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:23:16,528]\u001b[0m Trial 493 finished with value: 0.37885438617570827 and parameters: {'C': 0.0078125, 'gamma': 6.103515625e-05}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-20 21:23:40,378]\u001b[0m Trial 494 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:24:10,057]\u001b[0m Trial 495 finished with value: 0.4853618458682714 and parameters: {'C': 0.0625, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:24:34,095]\u001b[0m Trial 496 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:25:09,020]\u001b[0m Trial 497 finished with value: 0.4160921839212398 and parameters: {'C': 128.0, 'gamma': 2.0}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:25:33,015]\u001b[0m Trial 498 finished with value: 0.8292360722785809 and parameters: {'C': 2.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n",
      "\u001b[32m[I 2023-02-20 21:26:02,688]\u001b[0m Trial 499 finished with value: 0.8259064896910097 and parameters: {'C': 16.0, 'gamma': 0.015625}. Best is trial 119 with value: 0.8464827775814934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of trials: 500.0\n",
      "\tBest value (f1_score): 0.8465\n",
      "\tBest params:\n",
      "\t\tC: 2.0\n",
      "\t\tgamma: 0.015625\n"
     ]
    }
   ],
   "source": [
    "#Execute optuna and set hyperparameters\n",
    "func_svm_9 = lambda trial: objective_svm_CV(trial, X_trainSet9, Y_trainSet9, Y_trainSet9_class)\n",
    "study_svm.optimize(func_svm_9, n_trials=50)\n",
    "print(f\"\\tNumber of trials: {len(study_svm.trials):.1f}\")\n",
    "print(f\"\\tBest value (f1_score): {study_svm.best_value:.4f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_svm.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3def860a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:21:39.499247Z",
     "iopub.status.busy": "2023-01-15T19:21:39.499113Z",
     "iopub.status.idle": "2023-01-15T19:21:43.227274Z",
     "shell.execute_reply": "2023-01-15T19:21:43.226916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric        Set0        Set1        Set2        Set3  \\\n",
      "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
      "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
      "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
      "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
      "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
      "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
      "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
      "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
      "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
      "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
      "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
      "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
      "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
      "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
      "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
      "\n",
      "          Set4        Set5        Set6        Set7        Set8        Set9  \n",
      "0   345.000000  343.000000  328.000000  344.000000  342.000000  341.000000  \n",
      "1   166.000000  171.000000  175.000000  173.000000  159.000000  160.000000  \n",
      "2    59.000000   54.000000   57.000000   48.000000   68.000000   49.000000  \n",
      "3    25.000000   27.000000   35.000000   30.000000   26.000000   45.000000  \n",
      "4     0.858824    0.863866    0.845378    0.868908    0.842017    0.842017  \n",
      "5     0.853960    0.863980    0.851948    0.877551    0.834146    0.874359  \n",
      "6     0.932432    0.927027    0.903581    0.919786    0.929348    0.883420  \n",
      "7     0.737800    0.760000    0.754300    0.782800    0.700400    0.765600  \n",
      "8     0.891473    0.894394    0.877005    0.898172    0.879177    0.878866  \n",
      "9     0.856155    0.861917    0.843804    0.867665    0.838229    0.841661  \n",
      "10    0.844775    0.851452    0.834430    0.857105    0.825511    0.825906  \n",
      "11    0.835105    0.843514    0.828946    0.851296    0.814894    0.824485  \n",
      "12    0.696139    0.707030    0.671447    0.716051    0.660927    0.651902  \n",
      "13    0.869100    0.863600    0.833300    0.852200    0.859500    0.780500  \n",
      "14    0.835105    0.843514    0.828946    0.851296    0.814894    0.824485  \n"
     ]
    }
   ],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "\n",
    "optimized_svm_9 = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "#learn\n",
    "optimized_svm_9.fit(X_trainSet9,Y_trainSet9,)\n",
    "\n",
    "# predict\n",
    "y_pred_svm_9 = optimized_svm_9.predict(X_testSet9)\n",
    "\n",
    "#calculate the evaluation results\n",
    "conf_matrix = confusion_matrix(Y_testSet9, y_pred_svm_9)\n",
    "TP = conf_matrix[1][1]\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1] \n",
    "FN = conf_matrix[1][0]\n",
    "Accuracy = accuracy_score(Y_testSet9, y_pred_svm_9)\n",
    "Precision = precision_score(Y_testSet9, y_pred_svm_9)\n",
    "Sensitivity = recall_score(Y_testSet9, y_pred_svm_9)\n",
    "Specificity = round( TN / (TN+FP),4 )\n",
    "f1_scores = f1_score(Y_testSet9, y_pred_svm_9)      \n",
    "f1_scores_W = f1_score(Y_testSet9, y_pred_svm_9, average=\"weighted\")\n",
    "f1_scores_M = f1_score(Y_testSet9, y_pred_svm_9, average=\"macro\")\n",
    "BA_scores = balanced_accuracy_score(Y_testSet9, y_pred_svm_9)\n",
    "MCC = matthews_corrcoef(Y_testSet9, y_pred_svm_9)\n",
    "NPV = round( TN / (TN+FN),4 )\n",
    "ROC_AUC = roc_auc_score(Y_testSet9, y_pred_svm_9)\n",
    "    \n",
    "\n",
    "Set9 = pd.DataFrame({'Set9':[np.mean(TP),np.mean(TN),np.mean(FP),np.mean(FN),np.mean(Accuracy),np.mean(Precision),\n",
    "                                           np.mean(Sensitivity),np.mean(Specificity),np.mean(f1_scores),\n",
    "                                            np.mean(f1_scores_W), np.mean(f1_scores_M), np.mean(BA_scores), \n",
    "                                           np.mean(MCC),np.mean(NPV),np.mean(ROC_AUC)],\n",
    "                        \n",
    "                       })\n",
    "\n",
    "mat_met_svm_test['Set9'] = Set9\n",
    "print(mat_met_svm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "95aa0f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:21:43.228734Z",
     "iopub.status.busy": "2023-01-15T19:21:43.228605Z",
     "iopub.status.idle": "2023-01-15T19:21:43.372930Z",
     "shell.execute_reply": "2023-01-15T19:21:43.372679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study_svm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24970ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:21:43.374255Z",
     "iopub.status.busy": "2023-01-15T19:21:43.374127Z",
     "iopub.status.idle": "2023-01-15T19:21:43.375712Z",
     "shell.execute_reply": "2023-01-15T19:21:43.375486Z"
    }
   },
   "outputs": [],
   "source": [
    "#from optuna.visualization.matplotlib import plot_param_importances\n",
    "\n",
    "#plot_param_importances(study_svm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f8f09d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:21:43.376762Z",
     "iopub.status.busy": "2023-01-15T19:21:43.376663Z",
     "iopub.status.idle": "2023-01-15T19:22:25.425056Z",
     "shell.execute_reply": "2023-01-15T19:22:25.424624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value (average)</th>\n",
       "      <th>Value (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>166.200000</td>\n",
       "      <td>7.871185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>5.168279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>3.552777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>3.836955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.850904</td>\n",
       "      <td>0.019053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.860885</td>\n",
       "      <td>0.019969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.021097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.764030</td>\n",
       "      <td>0.025161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.882076</td>\n",
       "      <td>0.017169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.849582</td>\n",
       "      <td>0.019037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.839270</td>\n",
       "      <td>0.018832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.834318</td>\n",
       "      <td>0.018204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.680887</td>\n",
       "      <td>0.038214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.832540</td>\n",
       "      <td>0.032679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.834318</td>\n",
       "      <td>0.018204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value (average)  Value (std)\n",
       "0                    TP       166.200000     7.871185\n",
       "1                    TN        86.600000     5.168279\n",
       "2                    FP        26.800000     3.552777\n",
       "3                    FN        17.500000     3.836955\n",
       "4              Accuracy         0.850904     0.019053\n",
       "5             Precision         0.860885     0.019969\n",
       "6           Sensitivity         0.904600     0.021097\n",
       "7           Specificity         0.764030     0.025161\n",
       "8              F1 score         0.882076     0.017169\n",
       "9   F1 score (weighted)         0.849582     0.019037\n",
       "10     F1 score (macro)         0.839270     0.018832\n",
       "11    Balanced Accuracy         0.834318     0.018204\n",
       "12                  MCC         0.680887     0.038214\n",
       "13                  NPV         0.832540     0.032679\n",
       "14              ROC_AUC         0.834318     0.018204"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objective_svm_cv(study_svm.best_trial, X, Y, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b1e849c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:22:25.427011Z",
     "iopub.status.busy": "2023-01-15T19:22:25.426907Z",
     "iopub.status.idle": "2023-01-15T19:22:25.436791Z",
     "shell.execute_reply": "2023-01-15T19:22:25.436498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Set0</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Set3</th>\n",
       "      <th>Set4</th>\n",
       "      <th>Set5</th>\n",
       "      <th>Set6</th>\n",
       "      <th>Set7</th>\n",
       "      <th>Set8</th>\n",
       "      <th>Set9</th>\n",
       "      <th>ave</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>337.500000</td>\n",
       "      <td>8.329999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>168.600000</td>\n",
       "      <td>5.834762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>6.866990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>9.250225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.863866</td>\n",
       "      <td>0.845378</td>\n",
       "      <td>0.868908</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>0.850588</td>\n",
       "      <td>0.012001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.862155</td>\n",
       "      <td>0.853960</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.851948</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.874359</td>\n",
       "      <td>0.858782</td>\n",
       "      <td>0.014518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.936288</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.903581</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.883420</td>\n",
       "      <td>0.910369</td>\n",
       "      <td>0.024124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.785700</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>0.763400</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>0.737800</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.752330</td>\n",
       "      <td>0.026290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.878179</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.863271</td>\n",
       "      <td>0.890039</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.894394</td>\n",
       "      <td>0.877005</td>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.879177</td>\n",
       "      <td>0.878866</td>\n",
       "      <td>0.883539</td>\n",
       "      <td>0.010338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 score (weighted)</td>\n",
       "      <td>0.846708</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>0.828259</td>\n",
       "      <td>0.855171</td>\n",
       "      <td>0.856155</td>\n",
       "      <td>0.861917</td>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.867665</td>\n",
       "      <td>0.838229</td>\n",
       "      <td>0.841661</td>\n",
       "      <td>0.848844</td>\n",
       "      <td>0.011722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 score (macro)</td>\n",
       "      <td>0.836381</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>0.816771</td>\n",
       "      <td>0.843101</td>\n",
       "      <td>0.844775</td>\n",
       "      <td>0.851452</td>\n",
       "      <td>0.834430</td>\n",
       "      <td>0.857105</td>\n",
       "      <td>0.825511</td>\n",
       "      <td>0.825906</td>\n",
       "      <td>0.837455</td>\n",
       "      <td>0.012403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.829255</td>\n",
       "      <td>0.815659</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.835105</td>\n",
       "      <td>0.843514</td>\n",
       "      <td>0.828946</td>\n",
       "      <td>0.851296</td>\n",
       "      <td>0.814894</td>\n",
       "      <td>0.824485</td>\n",
       "      <td>0.831352</td>\n",
       "      <td>0.011371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.672895</td>\n",
       "      <td>0.688052</td>\n",
       "      <td>0.633624</td>\n",
       "      <td>0.689742</td>\n",
       "      <td>0.696139</td>\n",
       "      <td>0.707030</td>\n",
       "      <td>0.671447</td>\n",
       "      <td>0.716051</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>0.651902</td>\n",
       "      <td>0.678781</td>\n",
       "      <td>0.025524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NPV</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.880200</td>\n",
       "      <td>0.777300</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>0.869100</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.833300</td>\n",
       "      <td>0.852200</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>0.836630</td>\n",
       "      <td>0.036994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC_AUC</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.829255</td>\n",
       "      <td>0.815659</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.835105</td>\n",
       "      <td>0.843514</td>\n",
       "      <td>0.828946</td>\n",
       "      <td>0.851296</td>\n",
       "      <td>0.814894</td>\n",
       "      <td>0.824485</td>\n",
       "      <td>0.831352</td>\n",
       "      <td>0.011371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric        Set0        Set1        Set2        Set3  \\\n",
       "0                    TP  328.000000  338.000000  322.000000  344.000000   \n",
       "1                    TN  176.000000  169.000000  171.000000  166.000000   \n",
       "2                    FP   48.000000   65.000000   53.000000   55.000000   \n",
       "3                    FN   43.000000   23.000000   49.000000   30.000000   \n",
       "4              Accuracy    0.847059    0.852101    0.828571    0.857143   \n",
       "5             Precision    0.872340    0.838710    0.858667    0.862155   \n",
       "6           Sensitivity    0.884097    0.936288    0.867925    0.919786   \n",
       "7           Specificity    0.785700    0.722200    0.763400    0.751100   \n",
       "8              F1 score    0.878179    0.884817    0.863271    0.890039   \n",
       "9   F1 score (weighted)    0.846708    0.848875    0.828259    0.855171   \n",
       "10     F1 score (macro)    0.836381    0.839122    0.816771    0.843101   \n",
       "11    Balanced Accuracy    0.834906    0.829255    0.815659    0.835459   \n",
       "12                  MCC    0.672895    0.688052    0.633624    0.689742   \n",
       "13                  NPV    0.803700    0.880200    0.777300    0.846900   \n",
       "14              ROC_AUC    0.834906    0.829255    0.815659    0.835459   \n",
       "\n",
       "          Set4        Set5        Set6        Set7        Set8        Set9  \\\n",
       "0   345.000000  343.000000  328.000000  344.000000  342.000000  341.000000   \n",
       "1   166.000000  171.000000  175.000000  173.000000  159.000000  160.000000   \n",
       "2    59.000000   54.000000   57.000000   48.000000   68.000000   49.000000   \n",
       "3    25.000000   27.000000   35.000000   30.000000   26.000000   45.000000   \n",
       "4     0.858824    0.863866    0.845378    0.868908    0.842017    0.842017   \n",
       "5     0.853960    0.863980    0.851948    0.877551    0.834146    0.874359   \n",
       "6     0.932432    0.927027    0.903581    0.919786    0.929348    0.883420   \n",
       "7     0.737800    0.760000    0.754300    0.782800    0.700400    0.765600   \n",
       "8     0.891473    0.894394    0.877005    0.898172    0.879177    0.878866   \n",
       "9     0.856155    0.861917    0.843804    0.867665    0.838229    0.841661   \n",
       "10    0.844775    0.851452    0.834430    0.857105    0.825511    0.825906   \n",
       "11    0.835105    0.843514    0.828946    0.851296    0.814894    0.824485   \n",
       "12    0.696139    0.707030    0.671447    0.716051    0.660927    0.651902   \n",
       "13    0.869100    0.863600    0.833300    0.852200    0.859500    0.780500   \n",
       "14    0.835105    0.843514    0.828946    0.851296    0.814894    0.824485   \n",
       "\n",
       "           ave       std  \n",
       "0   337.500000  8.329999  \n",
       "1   168.600000  5.834762  \n",
       "2    55.600000  6.866990  \n",
       "3    33.300000  9.250225  \n",
       "4     0.850588  0.012001  \n",
       "5     0.858782  0.014518  \n",
       "6     0.910369  0.024124  \n",
       "7     0.752330  0.026290  \n",
       "8     0.883539  0.010338  \n",
       "9     0.848844  0.011722  \n",
       "10    0.837455  0.012403  \n",
       "11    0.831352  0.011371  \n",
       "12    0.678781  0.025524  \n",
       "13    0.836630  0.036994  \n",
       "14    0.831352  0.011371  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_met_svm_test['ave'] = mat_met_svm_test.iloc[:,1:11].mean(axis='columns', numeric_only=True)\n",
    "mat_met_svm_test['std'] = mat_met_svm_test.iloc[:,1:11].std(axis='columns', numeric_only=True)\n",
    "mat_met_svm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "297d96eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:22:25.438173Z",
     "iopub.status.busy": "2023-01-15T19:22:25.438045Z",
     "iopub.status.idle": "2023-01-15T19:25:57.266560Z",
     "shell.execute_reply": "2023-01-15T19:25:57.266209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test_idx0</th>\n",
       "      <th>y_test0</th>\n",
       "      <th>y_pred_svm0</th>\n",
       "      <th>y_pred_svm1</th>\n",
       "      <th>y_pred_svm2</th>\n",
       "      <th>y_pred_svm3</th>\n",
       "      <th>y_pred_svm4</th>\n",
       "      <th>y_pred_svm_ave</th>\n",
       "      <th>y_pred_svm_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>2966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>2967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2971 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test_idx0  y_test0  y_pred_svm0  y_pred_svm1  y_pred_svm2  \\\n",
       "0               0      1.0          1.0          1.0          1.0   \n",
       "1               1      1.0          1.0          1.0          1.0   \n",
       "2               2      0.0          0.0          0.0          0.0   \n",
       "3               3      0.0          1.0          1.0          1.0   \n",
       "4               4      0.0          1.0          1.0          1.0   \n",
       "...           ...      ...          ...          ...          ...   \n",
       "2966         2966      1.0          1.0          1.0          1.0   \n",
       "2967         2967      1.0          1.0          1.0          1.0   \n",
       "2968         2968      0.0          1.0          1.0          1.0   \n",
       "2969         2969      1.0          1.0          0.0          0.0   \n",
       "2970         2970      1.0          0.0          0.0          0.0   \n",
       "\n",
       "      y_pred_svm3  y_pred_svm4  y_pred_svm_ave  y_pred_svm_std  \n",
       "0             1.0          1.0             1.0             0.0  \n",
       "1             1.0          1.0             1.0             0.0  \n",
       "2             0.0          0.0             0.0             0.0  \n",
       "3             1.0          1.0             1.0             0.0  \n",
       "4             1.0          1.0             1.0             0.0  \n",
       "...           ...          ...             ...             ...  \n",
       "2966          1.0          1.0             1.0             0.0  \n",
       "2967          1.0          1.0             1.0             0.0  \n",
       "2968          1.0          1.0             1.0             0.0  \n",
       "2969          0.0          0.0             0.2             0.4  \n",
       "2970          0.0          0.0             0.0             0.0  \n",
       "\n",
       "[2971 rows x 9 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to fit into these X values \n",
    "\n",
    "TP = np.empty(10)\n",
    "FP = np.empty(10)\n",
    "TN = np.empty(10)\n",
    "FN = np.empty(10)\n",
    "\n",
    "\n",
    "Accuracy_outer = []\n",
    "Precision_outer = [] #Also called Positive Predictive Value(PPV)\n",
    "Sensitivity_outer = [] # Also called Recall or True Positive Rate (TPR)\n",
    "Specificity_outer = [] #Also called selectivity or True Negative Rate  (TNR)\n",
    "f1_scores_outer = []\n",
    "f1_scores_W_outer = []\n",
    "f1_scores_M_outer = []\n",
    "BA_scores_outer = []\n",
    "MCC_outer = []\n",
    "NPV_outer = []\n",
    "ROC_AUC_outer = []\n",
    "\n",
    "NUM_TRIALS = 5\n",
    "random_state= [687266, 98656, 56, 280189, 76543] # \n",
    "data_svm=pd.DataFrame()\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    cv_change = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state[i])\n",
    "    data_inner = pd.DataFrame({'y_test_idx': pd.Series(dtype='int'),\n",
    "                   'y_test': pd.Series(dtype='float'),\n",
    "                   'y_pred': pd.Series(dtype='float')})\n",
    "    \n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv_change.split(X, Y_class)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "        optimizedCV_svm = SVC(C = study_svm.best_params['C'], \n",
    "                        gamma=study_svm.best_params[\"gamma\"],\n",
    "                        )\n",
    "\n",
    "\n",
    "        #learn\n",
    "        \n",
    "        optimizedCV_svm.fit(X_train,y_train)\n",
    "                          \n",
    "                  \n",
    "        #print(test_idx)\n",
    "        y_pred_optimized_svm = optimizedCV_svm.predict(X_test) \n",
    "        data_inner = data_inner.append(pd.DataFrame({'y_test_idx': test_idx, 'y_test': y_test, 'y_pred_svm': y_pred_optimized_svm } ), )\n",
    "        data_inner.reset_index(inplace=True, drop=True) \n",
    "        data_inner.sort_values(by='y_test_idx', inplace=True) \n",
    "        \n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimized_svm)\n",
    "        TP[idx] = conf_matrix[1][1]\n",
    "        TN[idx] = conf_matrix[0][0]\n",
    "        FP[idx] = conf_matrix[0][1] \n",
    "        FN[idx] = conf_matrix[1][0]\n",
    "        \n",
    "        Accuracy_outer.append(accuracy_score(y_test, y_pred_optimized_svm))\n",
    "        Precision_outer.append(precision_score(y_test, y_pred_optimized_svm))\n",
    "        Sensitivity_outer.append(recall_score(y_test, y_pred_optimized_svm))\n",
    "        Specificity_outer.append(round( TN[idx] / (TN[idx]+FP[idx]),4 ))\n",
    "        f1_scores_outer.append(f1_score(y_test, y_pred_optimized_svm))\n",
    "        f1_scores_W_outer.append(f1_score(y_test, y_pred_optimized_svm, average=\"weighted\"))\n",
    "        f1_scores_M_outer.append(f1_score(y_test, y_pred_optimized_svm, average=\"macro\"))\n",
    "        BA_scores_outer.append(balanced_accuracy_score(y_test, y_pred_optimized_svm))\n",
    "        MCC_outer.append(matthews_corrcoef(y_test, y_pred_optimized_svm))\n",
    "        NPV_outer.append(round( TN[idx] / (TN[idx]+FN[idx]),4 ))\n",
    "        ROC_AUC_outer.append(roc_auc_score(y_test, y_pred_optimized_svm))\n",
    "        \n",
    "    data_svm['y_test_idx' + str(i)] = data_inner['y_test_idx']\n",
    "    data_svm['y_test' + str(i)] = data_inner['y_test']\n",
    "    data_svm['y_pred_svm' + str(i)] = data_inner['y_pred_svm']\n",
    "   # data_svm['correct' + str(i)] = correct_value\n",
    "   # data_svm['pred' + str(i)] = y_pred_optimized_svm\n",
    "\n",
    "mat_met_optimized_svm = pd.DataFrame({'Metric':['Accuracy','Precision','Sensitivity','Specificity','F1 score','F1 score (weighted)','F1 score (macro)','Balanced Accuracy','MCC','NPV','ROC_AUC'],     \n",
    "                        'Value (average)':[ np.mean(Accuracy_outer),np.mean(Precision_outer),\n",
    "                                           np.mean(Sensitivity_outer),np.mean(Specificity_outer),np.mean(f1_scores_outer),\n",
    "                                           np.mean(f1_scores_W_outer), np.mean(f1_scores_M_outer), np.mean(BA_scores_outer), \n",
    "                                           np.mean(MCC_outer),np.mean(NPV_outer),np.mean(ROC_AUC_outer)],\n",
    "                        'Value (std)': [ np.std(Accuracy_outer, ddof=1),np.std(Precision_outer, ddof=1),\n",
    "                                        np.std(Sensitivity_outer,ddof=1),np.std(Specificity_outer,ddof=1),np.std(f1_scores_outer, ddof=1),\n",
    "                                        np.std(f1_scores_W_outer, ddof=1),np.std(f1_scores_M_outer, ddof=1), np.std(BA_scores_outer, ddof=1), \n",
    "                                        np.std(MCC_outer, ddof=1),np.std(NPV_outer, ddof=1),np.std(ROC_AUC_outer, ddof=1)]\n",
    "                       }) \n",
    "\n",
    "\n",
    "svm_run0 = data_svm[['y_test_idx0', 'y_test0', 'y_pred_svm0']]\n",
    "svm_run0.sort_values(by='y_test_idx0', inplace=True)\n",
    "svm_run0.reset_index(inplace=True, drop=True)\n",
    "svm_run1 = data_svm[['y_test_idx1', 'y_test1', 'y_pred_svm1']]\n",
    "svm_run1.sort_values(by='y_test_idx1', inplace=True)\n",
    "svm_run1.reset_index(inplace=True, drop=True)\n",
    "svm_run2 = data_svm[['y_test_idx2', 'y_test2', 'y_pred_svm2']]\n",
    "svm_run2.sort_values(by='y_test_idx2', inplace=True)\n",
    "svm_run2.reset_index(inplace=True, drop=True)\n",
    "svm_run3 = data_svm[['y_test_idx3', 'y_test3', 'y_pred_svm3']]\n",
    "svm_run3.sort_values(by='y_test_idx3', inplace=True)\n",
    "svm_run3.reset_index(inplace=True, drop=True)\n",
    "svm_run4 = data_svm[['y_test_idx4', 'y_test4', 'y_pred_svm4']]\n",
    "svm_run4.sort_values(by='y_test_idx4', inplace=True)\n",
    "svm_run4.reset_index(inplace=True, drop=True)\n",
    "svm_5preds = pd.concat([svm_run0, svm_run1, svm_run2, svm_run3, svm_run4], axis=1)\n",
    "svm_5preds = svm_5preds[['y_test_idx0', 'y_test0', 'y_pred_svm0', 'y_pred_svm1', 'y_pred_svm2', 'y_pred_svm3', 'y_pred_svm4']]\n",
    "svm_5preds['y_pred_svm_ave'] = svm_5preds.iloc[:,2:11].mean(axis='columns', numeric_only=True)\n",
    "svm_5preds['y_pred_svm_std'] = svm_5preds.iloc[:,2:].std(axis='columns', numeric_only=True)\n",
    "# maybe also calculate the std for each value\n",
    "svm_5preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6394fe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:25:57.268119Z",
     "iopub.status.busy": "2023-01-15T19:25:57.268011Z",
     "iopub.status.idle": "2023-01-15T19:25:57.277470Z",
     "shell.execute_reply": "2023-01-15T19:25:57.277222Z"
    }
   },
   "outputs": [],
   "source": [
    "mat_met_optimized_svm.to_csv('mat_met_svm_opt.csv')\n",
    "svm_5preds.to_csv('svm_5test_CV_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d226e7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:25:57.279188Z",
     "iopub.status.busy": "2023-01-15T19:25:57.279085Z",
     "iopub.status.idle": "2023-01-15T19:27:13.929879Z",
     "shell.execute_reply": "2023-01-15T19:27:13.929527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline model f1_score 0.8293 with a standard deviation of 0.0224\n",
      "SVM optimized model f1_score 0.8383 with a standard deviation of 0.0240\n"
     ]
    }
   ],
   "source": [
    "#cross valide using this optimized SVC \n",
    "svm_baseline_CVscore = cross_val_score(svm_clf, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "#cv_svm_opt_testSet = cross_val_score(optimized_svm, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "cv_svm_opt = cross_val_score(optimizedCV_svm, X, Y, cv=10, scoring=\"f1_macro\")\n",
    "print(\"SVM baseline model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(svm_baseline_CVscore), np.std(svm_baseline_CVscore, ddof=1)))\n",
    "#print(\"SVM optimized model (tested on Y_te) f1_score %0.4f with a standard deviation of %0.4f\" % (svm_baseline_CVscore.mean(), svm_baseline_CVscore.std()))\n",
    "print(\"SVM optimized model f1_score %0.4f with a standard deviation of %0.4f\" % (np.mean(cv_svm_opt), np.std(cv_svm_opt, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "515bb7de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T19:27:13.931434Z",
     "iopub.status.busy": "2023-01-15T19:27:13.931327Z",
     "iopub.status.idle": "2023-01-15T19:27:13.945269Z",
     "shell.execute_reply": "2023-01-15T19:27:13.944982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optimizedCV_svm_clf.joblib']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_clf, \"./svm_clf.joblib\")\n",
    "#joblib.dump(optimized_svm, \"./optimized_svm.joblib\")\n",
    "joblib.dump(optimizedCV_svm, \"./optimizedCV_svm_clf.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
